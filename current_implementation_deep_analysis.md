# InsiteChart í˜„ì¬ êµ¬í˜„ ì‹¬ì¸µ ë¶„ì„ ë° ê³ ë„í™” ê¸°íšŒ ì‹ë³„

## 1. ë¶„ì„ ê°œìš”

ë³¸ ë¬¸ì„œëŠ” InsiteChart í”„ë¡œì íŠ¸ì˜ í˜„ì¬ êµ¬í˜„ëœ ê¸°ëŠ¥ë“¤ì„ ì‹¬ì¸µì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬, ê³ ë„í™” ê¸°íšŒì™€ ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ì„ ì‹ë³„í•©ë‹ˆë‹¤. ì¶”ê°€ ê¸°ëŠ¥ ì—°ë™ ì—†ì´ í˜„ì¬ êµ¬í˜„ì˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤.

## 2. í•µì‹¬ êµ¬ì„± ìš”ì†Œ ë¶„ì„

### 2.1 ì•„í‚¤í…ì²˜ ë° ì„¤ê³„ íŒ¨í„´

#### 2.1.1 í˜„ì¬ ìƒíƒœ ë¶„ì„
**ê°•ì :**
- **ê³„ì¸µì  ì•„í‚¤í…ì²˜**: ëª…í™•í•œ ë¶„ë¦¬ (API ë ˆì´ì–´, ì„œë¹„ìŠ¤ ë ˆì´ì–´, ë°ì´í„° ë ˆì´ì–´)
- **ì˜ì¡´ì„± ì£¼ì…**: FastAPIì˜ ì˜ì¡´ì„± ì£¼ì… ì‹œìŠ¤í…œ ì ê·¹ í™œìš©
- **ë¯¸ë“¤ì›¨ì–´ íŒ¨í„´**: ë³´ì•ˆ, ë¡œê¹…, ì†ë„ ì œí•œ ë“± ë¯¸ë“¤ì›¨ì–´ ì²´ê³„ì ìœ¼ë¡œ êµ¬í˜„
- **ì„œë¹„ìŠ¤ ë¶„ë¦¬**: StockService, SentimentService, UnifiedService ë“± ëª…í™•í•œ ì—­í•  ë¶„ë‹´

**ê°œì„  ê¸°íšŒ:**
1. **ì„œë¹„ìŠ¤ ê°„ ê²°í•©ë„ ê°ì†Œ**: í˜„ì¬ UnifiedServiceê°€ ë‹¤ë¥¸ ì„œë¹„ìŠ¤ë“¤ê³¼ ê°•í•˜ê²Œ ê²°í•©ë¨
2. **ì¸í„°í˜ì´ìŠ¤ ì¶”ìƒí™”**: êµ¬ì²´ í´ë˜ìŠ¤ ëŒ€ì‹  ì¸í„°í˜ì´ìŠ¤/í”„ë¡œí† ì½œ ì‚¬ìš© í•„ìš”
3. **ì„¤ì • ê´€ë¦¬**: í•˜ë“œì½”ë”©ëœ ì„¤ì • ê°’ë“¤ì„ í™˜ê²½ ë³€ìˆ˜ë‚˜ ì„¤ì • íŒŒì¼ë¡œ ë¶„ë¦¬

#### 2.1.2 ê³ ë„í™” ë°©ì•ˆ
```python
# 1. ì¸í„°í˜ì´ìŠ¤ ì¶”ìƒí™” ë„ì…
from abc import ABC, abstractmethod

class StockServiceInterface(ABC):
    @abstractmethod
    async def get_stock_info(self, symbol: str) -> Optional[Dict[str, Any]]:
        pass

class SentimentServiceInterface(ABC):
    @abstractmethod
    async def get_sentiment_data(self, symbol: str) -> Optional[Dict[str, Any]]:
        pass

# 2. íŒ©í† ë¦¬ íŒ¨í„´ ë„ì…
class ServiceFactory:
    @staticmethod
    def create_stock_service(config: Dict[str, Any]) -> StockServiceInterface:
        if config.get('use_mock', False):
            return MockStockService()
        return YahooFinanceStockService()

# 3. ì„¤ì • ê´€ë¦¬ ê°œì„ 
from pydantic import BaseSettings

class CacheSettings(BaseSettings):
    redis_url: str = "redis://localhost:6379"
    ttl_stock_data: int = 300
    ttl_sentiment_data: int = 120
    
    class Config:
        env_file = ".env"
        env_prefix = "CACHE_"
```

### 2.2 ë°ì´í„° ëª¨ë¸ ë° ë°ì´í„°ë² ì´ìŠ¤

#### 2.2.1 í˜„ì¬ ìƒíƒœ ë¶„ì„
**ê°•ì :**
- **ì™„ì „í•œ ë°ì´í„° ëª¨ë¸**: User, Stock, SentimentData, WatchlistItem ë“± í¬ê´„ì  ëª¨ë¸
- **ì ì ˆí•œ ì¸ë±ì‹±**: ì„±ëŠ¥ì„ ìœ„í•œ ì¸ë±ìŠ¤ ì „ëµì  ë°°ì¹˜
- **ê´€ê³„í˜• ëª¨ë¸ë§**: ì™¸ë˜ í‚¤ ê´€ê³„ ëª…í™•í•˜ê²Œ ì •ì˜
- **ê°ì‚¬ ì¶”ì **: SystemLog, UserActivity ë“± ì¶”ì  ê¸°ëŠ¥

**ê°œì„  ê¸°íšŒ:**
1. **ë°ì´í„° ì •í•©ì„± ì œì•½ ì¡°ê±´**: ì™¸ë˜ í‚¤ ì œì•½ ì¡°ê±´ ê°•í™” í•„ìš”
2. **íŒŒí‹°ì…”ë‹ ì „ëµ**: ëŒ€ìš©ëŸ‰ í…Œì´ë¸”(StockPrice, SentimentData) íŒŒí‹°ì…”ë‹
3. **ë°ì´í„° ì•„ì¹´ì´ë¹™**: ì˜¤ë˜ëœ ë°ì´í„° ì•„ì¹´ì´ë¹™ ì „ëµ ë¶€ì¬
4. **ì†Œí”„íŠ¸ ì‚­ì œ**: ì‹¤ì œ ì‚­ì œ ëŒ€ì‹  ì†Œí”„íŠ¸ ì‚­ì œ êµ¬í˜„

#### 2.2.2 ê³ ë„í™” ë°©ì•ˆ
```sql
-- 1. ë°ì´í„° ì •í•©ì„± ì œì•½ ì¡°ê±´ ê°•í™”
ALTER TABLE stock_prices 
ADD CONSTRAINT chk_price_positive 
CHECK (price > 0 AND open_price > 0 AND high_price > 0 AND low_price > 0);

ALTER TABLE stock_prices 
ADD CONSTRAINT chk_high_low_relationship 
CHECK (high_price >= low_price AND close_price BETWEEN low_price AND high_price);

-- 2. íŒŒí‹°ì…”ë‹ ì „ëµ (ì‹œê°„ ê¸°ë°˜)
CREATE TABLE stock_prices_partitioned (
    LIKE stock_prices INCLUDING ALL
) PARTITION BY RANGE (timestamp);

CREATE TABLE stock_prices_2024_q1 PARTITION OF stock_prices_partitioned
FOR VALUES FROM ('2024-01-01') TO ('2024-04-01');

-- 3. ì†Œí”„íŠ¸ ì‚­ì œ êµ¬í˜„
ALTER TABLE stocks ADD COLUMN deleted_at TIMESTAMP NULL;
ALTER TABLE users ADD COLUMN deleted_at TIMESTAMP NULL;

-- ë³µí•© ì¸ë±ìŠ¤ ìµœì í™”
CREATE INDEX idx_stock_symbol_active 
ON stocks(symbol) WHERE deleted_at IS NULL;
```

### 2.3 ìºì‹œ ì‹œìŠ¤í…œ

#### 2.3.1 í˜„ì¬ ìƒíƒœ ë¶„ì„
**ê°•ì :**
- **í†µí•© ìºì‹œ ê´€ë¦¬ì**: UnifiedCacheManagerì—ì„œ ëª¨ë“  ìºì‹œ ì‘ì—… í†µí•©
- **ë‹¤ì¤‘ ë ˆë²¨ ìºì‹±**: ë¡œì»¬ ìºì‹œ + ë°±ì—”ë“œ ìºì‹œ 2ë‹¨ê³„ êµ¬ì¡°
- **TTL ê´€ë¦¬**: ë°ì´í„° ìœ í˜•ë³„ TTL ì„¤ì •
- **ìºì‹œ í†µê³„**: íˆíŠ¸ìœ¨, ë¯¸ìŠ¤ìœ¨ ë“± í†µê³„ ì œê³µ

**ê°œì„  ê¸°íšŒ:**
1. **ìºì‹œ ì¼ê´€ì„±**: ë¶„ì‚° í™˜ê²½ì—ì„œì˜ ìºì‹œ ì¼ê´€ì„± ë¬¸ì œ
2. **ìºì‹œ ì›Œë°**: ì‹œìŠ¤í…œ ì‹œì‘ ì‹œ í•« ë°ì´í„° ì„ ë¡œë”© ë¶€ì¬
3. **ìºì‹œ ì „ëµ**: Write-through, Write-behind ë“± ì „ëµì  ìºì‹± ë¶€ì¬
4. **ë©”ëª¨ë¦¬ ê´€ë¦¬**: ë¡œì»¬ ìºì‹œ í¬ê¸° ê³ ì •ìœ¼ë¡œ ì¸í•œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ì €í•˜

#### 2.3.2 ê³ ë„í™” ë°©ì•ˆ
```python
# 1. ìºì‹œ ì¼ê´€ì„± ê°œì„ 
class ConsistentCacheManager(UnifiedCacheManager):
    async def set_with_consistency(self, key: str, value: Any, ttl: int):
        # ë¶„ì‚° ë½ íšë“
        lock_key = f"lock:{key}"
        lock_acquired = await self.acquire_lock(lock_key, timeout=5)
        
        if lock_acquired:
            try:
                # ìºì‹œ ì„¤ì •
                await self.set(key, value, ttl)
                # ì´ë²¤íŠ¸ ë°œí–‰ (ë‹¤ë¥¸ ë…¸ë“œì— ì•Œë¦¼)
                await self.publish_invalidation_event(key)
            finally:
                await self.release_lock(lock_key)
        else:
            # ë½ íšë“ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„
            await asyncio.sleep(0.1)
            return await self.set_with_consistency(key, value, ttl)

# 2. ìºì‹œ ì›Œë° ì „ëµ
class CacheWarmupService:
    async def warmup_popular_data(self):
        # ì¸ê¸° ì£¼ì‹ ì‹¬ë³¼ ëª©ë¡
        popular_symbols = await self.get_trending_symbols(limit=50)
        
        # ë³‘ë ¬ë¡œ ë°ì´í„° í”„ë¦¬ë¡œë“œ
        tasks = [
            self.stock_service.get_stock_info(symbol)
            for symbol in popular_symbols
        ]
        await asyncio.gather(*tasks, return_exceptions=True)

# 3. ë™ì  ìºì‹œ í¬ê¸° ê´€ë¦¬
class AdaptiveCacheManager(UnifiedCacheManager):
    def __init__(self):
        super().__init__()
        self.memory_threshold = 0.8  # 80% ë©”ëª¨ë¦¬ ì‚¬ìš© ì‹œ ì¶•ì†Œ
        self.min_cache_size = 50
        self.max_cache_size = 500
    
    def _adjust_cache_size(self):
        import psutil
        memory_usage = psutil.virtual_memory().percent / 100
        
        if memory_usage > self.memory_threshold:
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìœ¼ë©´ ìºì‹œ í¬ê¸° ì¶•ì†Œ
            new_size = max(self.min_cache_size, int(self._local_cache_max_size * 0.7))
        else:
            # ë©”ëª¨ë¦¬ ì—¬ìœ ê°€ ìˆìœ¼ë©´ ìºì‹œ íê¸° í™•ì¥
            new_size = min(self.max_cache_size, int(self._local_cache_max_size * 1.2))
        
        self._local_cache_max_size = new_size
```

### 2.4 API ì—”ë“œí¬ì¸íŠ¸ ë° ë¼ìš°íŒ…

#### 2.4.1 í˜„ì¬ ìƒíƒœ ë¶„ì„
**ê°•ì :**
- **RESTful ì„¤ê³„**: í‘œì¤€ HTTP ë©”ì„œë“œì™€ ìƒíƒœ ì½”ë“œ ì ì ˆíˆ ì‚¬ìš©
- **ì¼ê´€ëœ ì‘ë‹µ í˜•ì‹**: success, data, timestamp êµ¬ì¡° ì¼ê´€ì„±
- **ì ì ˆí•œ HTTP ìƒíƒœ ì½”ë“œ**: 200, 404, 500 ë“± ì ì ˆí•œ ìƒíƒœ ì½”ë“œ ì‚¬ìš©
- **API ë²„ì „ ê´€ë¦¬**: /api/v1 ê²½ë¡œë¡œ ë²„ì „ ê´€ë¦¬

**ê°œì„  ê¸°íšŒ:**
1. **API ì‘ë‹µ ìµœì í™”**: ë¶ˆí•„ìš”í•œ ë°ì´í„° ì¤‘ë³µ ë° ê³¼ë„í•œ ì‘ë‹µ í¬ê¸°
2. **í˜ì´ì§€ë„¤ì´ì…˜**: ëŒ€ìš©ëŸ‰ ë°ì´í„°ì— ëŒ€í•œ í˜ì´ì§€ë„¤ì´ì…˜ ë¶€ì¬
3. **í•„í„°ë§ ë° ì •ë ¬**: ë™ì  í•„í„°ë§ê³¼ ì •ë ¬ ê¸°ëŠ¥ ì œí•œì 
4. **API ë¬¸ì„œí™”**: OpenAPI ìŠ¤í‚¤ë§ˆ ìë™í™” ë¶€ì¡±

#### 2.4.2 ê³ ë„í™” ë°©ì•ˆ
```python
# 1. API ì‘ë‹µ ìµœì í™”
class OptimizedResponseModel(BaseModel):
    success: bool
    data: Optional[Any] = None
    pagination: Optional[Dict[str, Any]] = None
    metadata: Optional[Dict[str, Any]] = None
    timestamp: str
    
    class Config:
        # ì‘ë‹µ ì§ë ¬í™” ìµœì í™”
        json_encoders = {
            datetime: lambda v: v.isoformat(),
            Decimal: lambda v: float(v)
        }

# 2. í˜ì´ì§€ë„¤ì´ì…˜ êµ¬í˜„
class PaginationParams(BaseModel):
    page: int = Field(1, ge=1)
    size: int = Field(20, ge=1, le=100)
    sort_by: Optional[str] = None
    sort_order: Optional[str] = Field("asc", regex="^(asc|desc)$")

@router.get("/stocks")
async def get_stocks_paginated(
    pagination: PaginationParams = Depends(),
    filters: Dict[str, Any] = Depends()
):
    offset = (pagination.page - 1) * pagination.size
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ì— í˜ì´ì§€ë„¤ì´ì…˜ ì ìš©
    stocks = await stock_service.get_stocks(
        filters=filters,
        offset=offset,
        limit=pagination.size,
        sort_by=pagination.sort_by,
        sort_order=pagination.sort_order
    )
    
    total_count = await stock_service.count_stocks(filters)
    
    return OptimizedResponseModel(
        success=True,
        data=stocks,
        pagination={
            "page": pagination.page,
            "size": pagination.size,
            "total": total_count,
            "pages": (total_count + pagination.size - 1) // pagination.size
        }
    )

# 3. ë™ì  í•„í„°ë§ ë° ì •ë ¬
class AdvancedFilterParams(BaseModel):
    symbols: Optional[List[str]] = None
    sectors: Optional[List[str]] = None
    market_cap_min: Optional[float] = None
    market_cap_max: Optional[float] = None
    price_min: Optional[float] = None
    price_max: Optional[float] = None
    sentiment_range: Optional[Tuple[float, float]] = None
```

### 2.5 ë³´ì•ˆ ë° ì¸ì¦

#### 2.5.1 í˜„ì¬ ìƒíƒœ ë¶„ì„
**ê°•ì :**
- **JWT ê¸°ë°˜ ì¸ì¦**: í‘œì¤€ JWT í† í° ê¸°ë°˜ ì¸ì¦ êµ¬í˜„
- **ê¶Œí•œ ë¶€ì—¬ ì‹œìŠ¤í…œ**: ì—­í•  ê¸°ë°˜ ê¶Œí•œ ê´€ë¦¬
- **ë³´ì•ˆ í—¤ë”**: CSP, XSS ë³´í˜¸ ë“± ë³´ì•ˆ í—¤ë” ì„¤ì •
- **ì†ë„ ì œí•œ**: ê¸°ë³¸ì ì¸ ì†ë„ ì œí•œ êµ¬í˜„

**ê°œì„  ê¸°íšŒ:**
1. **í† í° ê´€ë¦¬**: ë¦¬í”„ë ˆì‹œ í† í° ê´€ë¦¬ ë° ë¸”ë™ë¦¬ìŠ¤íŒ… ë¶€ì¡±
2. **ì„¸ì…˜ ê´€ë¦¬**: ë™ì‹œ ì„¸ì…˜ ì œí•œ ë° ì„¸ì…˜ í•˜ì´ì¬í‚¹ ë°©ì–´
3. **ì…ë ¥ ê²€ì¦**: SQL ì¸ì ì…˜, XSS ë“±ì— ëŒ€í•œ ì…ë ¥ ê²€ì¦ ê°•í™”
4. **ë³´ì•ˆ ë¡œê¹…**: ë³´ì•ˆ ì´ë²¤íŠ¸ ìƒì„¸ ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ë¶€ì¡±

#### 2.5.2 ê³ ë„í™” ë°©ì•ˆ
```python
# 1. í† í° ê´€ë¦¬ ê°•í™”
class EnhancedJWTAuthMiddleware(JWTAuthMiddleware):
    def __init__(self):
        super().__init__()
        self.blacklisted_tokens = set()
        self.active_sessions = {}  # user_id -> set of session_ids
    
    async def revoke_token(self, token: str):
        """í† í° ë¸”ë™ë¦¬ìŠ¤íŒ…"""
        try:
            payload = jwt.decode(token, self.secret_key, algorithms=[self.algorithm])
            jti = payload.get('jti')
            if jti:
                self.blacklisted_tokens.add(jti)
                await self.cache_manager.set(f"blacklist:{jti}", True, ttl=86400)
        except:
            pass
    
    async def check_concurrent_sessions(self, user_id: str, max_sessions: int = 3):
        """ë™ì‹œ ì„¸ì…˜ ì œí•œ"""
        active_sessions = self.active_sessions.get(user_id, set())
        return len(active_sessions) < max_sessions

# 2. ì…ë ¥ ê²€ì¦ ê°•í™”
class SecurityValidator:
    @staticmethod
    def validate_stock_symbol(symbol: str) -> bool:
        """ì£¼ì‹ ì‹¬ë³¼ ê²€ì¦"""
        # ì•ŒíŒŒë²³ê³¼ ìˆ«ìë§Œ í—ˆìš©, ê¸¸ì´ ì œí•œ
        import re
        pattern = r'^[A-Z]{1,5}$'
        return bool(re.match(pattern, symbol.upper()))
    
    @staticmethod
    def sanitize_input(input_str: str) -> str:
        """ì…ë ¥ê°’ ì‚´ê·¹í™”"""
        import html
        # HTML íƒœê·¸ ì œê±°
        sanitized = html.escape(input_str)
        # SQL ì¸ì ì…˜ íŒ¨í„´ ì œê±°
        dangerous_patterns = [
            r"(\b(SELECT|INSERT|UPDATE|DELETE|DROP|CREATE|ALTER)\b)",
            r"(\b(OR|AND)\s+\w+\s*=\s*\w+)",
            r"([;'\"])"
        ]
        
        for pattern in dangerous_patterns:
            sanitized = re.sub(pattern, "", sanitized, flags=re.IGNORECASE)
        
        return sanitized.strip()

# 3. ë³´ì•ˆ ë¡œê¹… ê°•í™”
class SecurityLogger:
    def __init__(self):
        self.logger = logging.getLogger("security")
    
    async def log_security_event(self, event_type: str, details: Dict[str, Any]):
        """ë³´ì•ˆ ì´ë²¤íŠ¸ ë¡œê¹…"""
        security_event = {
            "timestamp": datetime.utcnow().isoformat(),
            "event_type": event_type,
            "details": details,
            "severity": self._determine_severity(event_type)
        }
        
        self.logger.warning(f"Security Event: {json.dumps(security_event)}")
        
        # ë†’ì€ ì‹¬ê°ë„ ì´ë²¤íŠ¸ëŠ” ê´€ë¦¬ìì—ê²Œ ì•Œë¦¼
        if security_event["severity"] >= 7:
            await self._notify_admins(security_event)
```

### 2.6 ì„±ëŠ¥ ë° ìµœì í™”

#### 2.6.1 í˜„ì¬ ìƒíƒœ ë¶„ì„
**ê°•ì :**
- **ë¹„ë™ê¸° ì²˜ë¦¬**: asyncioë¥¼ í†µí•œ ë¹„ë™ê¸° ì²˜ë¦¬
- **ìºì‹± ì „ëµ**: ë‹¤ë‹¨ê³„ ìºì‹± êµ¬í˜„
- **ë³‘ë ¬ ì²˜ë¦¬**: asyncio.gatherë¥¼ í†µí•œ ë³‘ë ¬ API í˜¸ì¶œ
- **ìŠ¤ë ˆë“œ í’€**: ì°¨ë‹¨ ì‘ì—…ì„ ìœ„í•œ ìŠ¤ë ˆë“œ í’€ ì‚¬ìš©

**ê°œì„  ê¸°íšŒ:**
1. **ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ìµœì í™”**: N+1 ë¬¸ì œ, ì¸ë±ìŠ¤ ë¯¸ì‚¬ìš© ë“±
2. **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
3. **ë„¤íŠ¸ì›Œí¬ í˜¸ì¶œ ìµœì í™”**: ë¶ˆí•„ìš”í•œ API í˜¸ì¶œ ì¤‘ë³µ ì œê±°
4. **ë¦¬ì†ŒìŠ¤ í’€ ê´€ë¦¬**: ì»¤ë„¥ì…˜ í’€, ìŠ¤ë ˆë“œ í’€ í¬ê¸° ë™ì  ì¡°ì •

#### 2.6.2 ê³ ë„í™” ë°©ì•ˆ
```python
# 1. ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ìµœì í™”
class OptimizedStockService(StockService):
    async def get_stock_with_sentiment(self, symbol: str):
        """ì¡°ì¸ ì¿¼ë¦¬ë¥¼ í†µí•œ N+1 ë¬¸ì œ í•´ê²°"""
        query = """
        SELECT 
            s.*,
            sd.compound_score,
            sd.mention_count_24h,
            sd.positive_mentions,
            sd.negative_mentions
        FROM stocks s
        LEFT JOIN LATERAL (
            SELECT *
            FROM sentiment_data sd
            WHERE sd.stock_id = s.id
            AND sd.timestamp >= NOW() - INTERVAL '24 hours'
            ORDER BY sd.timestamp DESC
            LIMIT 1
        ) sd ON true
        WHERE s.symbol = :symbol
        """
        
        result = await self.db.fetch_one(query, {"symbol": symbol})
        return result

# 2. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
class MemoryOptimizedProcessor:
    def __init__(self):
        self.batch_size = 1000
        self.memory_threshold = 0.8
    
    async def process_large_dataset(self, data_stream):
        """ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ë°°ì¹˜ë¡œ ì²˜ë¦¬í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”"""
        batch = []
        async for item in data_stream:
            batch.append(item)
            
            if len(batch) >= self.batch_size:
                await self._process_batch(batch)
                batch.clear()
                
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
                if self._check_memory_usage() > self.memory_threshold:
                    await self._force_garbage_collection()
        
        # ë‚¨ì€ ë°ì´í„° ì²˜ë¦¬
        if batch:
            await self._process_batch(batch)

# 3. ë¦¬ì†ŒìŠ¤ í’€ ë™ì  ê´€ë¦¬
class AdaptiveResourcePool:
    def __init__(self):
        self.min_connections = 5
        self.max_connections = 50
        self.current_connections = self.min_connections
        self.response_times = deque(maxlen=100)
    
    async def adjust_pool_size(self):
        """ì‘ë‹µ ì‹œê°„ ê¸°ë°˜ìœ¼ë¡œ í’€ í¬ê¸° ë™ì  ì¡°ì •"""
        avg_response_time = sum(self.response_times) / len(self.response_times)
        
        if avg_response_time > 1.0 and self.current_connections < self.max_connections:
            # ì‘ë‹µ ì‹œê°„ì´ ê¸¸ë©´ ì—°ê²° ìˆ˜ ì¦ê°€
            await self._add_connections(5)
        elif avg_response_time < 0.2 and self.current_connections > self.min_connections:
            # ì‘ë‹µ ì‹œê°„ì´ ì§§ìœ¼ë©´ ì—°ê²° ìˆ˜ ê°ì†Œ
            await self._remove_connections(5)
```

### 2.7 í…ŒìŠ¤íŠ¸ ë° í’ˆì§ˆ ë³´ì¦

#### 2.7.1 í˜„ì¬ ìƒíƒœ ë¶„ì„
**ê°•ì :**
- **í†µí•© í…ŒìŠ¤íŠ¸**: API ì—”ë“œí¬ì¸íŠ¸ì— ëŒ€í•œ í†µí•© í…ŒìŠ¤íŠ¸ êµ¬í˜„
- **ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸**: ë‹¤ì–‘í•œ ì˜¤ë¥˜ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
- **ì„±ëŠ¥ í…ŒìŠ¤íŠ¸**: ê¸°ë³¸ì ì¸ ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸
- **ë™ì‹œì„± í…ŒìŠ¤íŠ¸**: ì—¬ëŸ¬ ìš”ì²­ ë™ì‹œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸

**ê°œì„  ê¸°íšŒ:**
1. **í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€**: í˜„ì¬ ì•½ 60-70% ì»¤ë²„ë¦¬ì§€
2. **ë‹¨ìœ„ í…ŒìŠ¤íŠ¸**: ê°œë³„ ëª¨ë“ˆ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ë¶€ì¡±
3. **ë¶€í•˜ í…ŒìŠ¤íŠ¸**: ì‹¤ì œ ë¶€í•˜ ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ í…ŒìŠ¤íŠ¸ ë¶€ì¡±
4. **í…ŒìŠ¤íŠ¸ ë°ì´í„° ê´€ë¦¬**: í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± ë° ì •ë¦¬ ìë™í™” ë¶€ì¡±

#### 2.7.2 ê³ ë„í™” ë°©ì•ˆ
```python
# 1. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ê°•í™”
class TestStockService(unittest.TestCase):
    def setUp(self):
        self.mock_cache = MockCacheManager()
        self.stock_service = StockService(self.mock_cache)
    
    @patch('yfinance.Ticker')
    async def test_get_stock_info_success(self, mock_ticker):
        """ì£¼ì‹ ì •ë³´ ì¡°íšŒ ì„±ê³µ í…ŒìŠ¤íŠ¸"""
        mock_ticker.return_value.info = {
            'symbol': 'AAPL',
            'regularMarketPrice': 150.0,
            'previousClose': 145.0
        }
        
        result = await self.stock_service.get_stock_info('AAPL')
        
        self.assertIsNotNone(result)
        self.assertEqual(result['symbol'], 'AAPL')
        self.assertEqual(result['current_price'], 150.0)
        
        # ìºì‹œ í˜¸ì¶œ í™•ì¸
        self.mock_cache.get_stock_data.assert_called_once_with('AAPL')

# 2. ë¶€í•˜ í…ŒìŠ¤íŠ¸ ê°•í™”
class LoadTestSuite:
    async def test_concurrent_stock_requests(self):
        """ë™ì‹œ ì£¼ì‹ ìš”ì²­ ë¶€í•˜ í…ŒìŠ¤íŠ¸"""
        import asyncio
        import aiohttp
        
        base_url = "http://localhost:8000/api/v1"
        symbols = ['AAPL', 'MSFT', 'GOOGL', 'TSLA', 'AMZN']
        
        async def make_request(session, symbol):
            start_time = time.time()
            async with session.get(f"{base_url}/stock", params={"symbol": symbol}) as response:
                await response.json()
                return time.time() - start_time
        
        # 100ê°œì˜ ë™ì‹œ ìš”ì²­ ìƒì„±
        tasks = []
        async with aiohttp.ClientSession() as session:
            for _ in range(100):
                symbol = random.choice(symbols)
                tasks.append(make_request(session, symbol))
            
            response_times = await asyncio.gather(*tasks)
        
        # ì„±ëŠ¥ ê¸°ì¤€ í™•ì¸
        avg_response_time = sum(response_times) / len(response_times)
        max_response_time = max(response_times)
        p95_response_time = sorted(response_times)[int(len(response_times) * 0.95)]
        
        self.assertLess(avg_response_time, 2.0, "í‰ê·  ì‘ë‹µ ì‹œê°„ì´ 2ì´ˆë¥¼ ì´ˆê³¼")
        self.assertLess(max_response_time, 5.0, "ìµœëŒ€ ì‘ë‹µ ì‹œê°„ì´ 5ì´ˆë¥¼ ì´ˆê³¼")
        self.assertLess(p95_response_time, 3.0, "95% ì‘ë‹µ ì‹œê°„ì´ 3ì´ˆë¥¼ ì´ˆê³¼")

# 3. í…ŒìŠ¤íŠ¸ ë°ì´í„° ê´€ë¦¬ ìë™í™”
class TestDataManager:
    def __init__(self):
        self.test_data = {}
    
    async def setup_test_data(self):
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ìë™ ìƒì„±"""
        # í…ŒìŠ¤íŠ¸ìš© ì‚¬ìš©ì ìƒì„±
        test_users = [
            {"user_id": f"test_user_{i}", "email": f"test{i}@example.com"}
            for i in range(10)
        ]
        
        for user in test_users:
            await self.db.execute(
                "INSERT INTO users (user_id, email) VALUES (:user_id, :email)",
                user
            )
        
        # í…ŒìŠ¤íŠ¸ìš© ì£¼ì‹ ë°ì´í„° ìƒì„±
        test_stocks = [
            {"symbol": "TEST1", "company_name": "Test Company 1"},
            {"symbol": "TEST2", "company_name": "Test Company 2"}
        ]
        
        for stock in test_stocks:
            await self.db.execute(
                "INSERT INTO stocks (symbol, company_name) VALUES (:symbol, :company_name)",
                stock
            )
    
    async def cleanup_test_data(self):
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ìë™ ì •ë¦¬"""
        await self.db.execute("DELETE FROM users WHERE user_id LIKE 'test_user_%'")
        await self.db.execute("DELETE FROM stocks WHERE symbol LIKE 'TEST%'")
```

## 3. ì‚¬ìš©ì ê²½í—˜ ë° UI/UX ë¶„ì„

### 3.1 í˜„ì¬ ìƒíƒœ ë¶„ì„
**ê°•ì :**
- **ë°˜ì‘í˜• ë””ìì¸**: ë‹¤ì–‘í•œ í™”ë©´ í¬ê¸°ì— ëŒ€ì‘
- **ì‹¤ì‹œê°„ ì°¨íŠ¸**: Plotlyë¥¼ í†µí•œ ì¸í„°ë™í‹°ë¸Œ ì°¨íŠ¸
- **ë‹¤ì–‘í•œ ê¸°ìˆ  ì§€í‘œ**: RSI, MACD, ë³¼ë¦°ì € ë°´ë“œ ë“±
- **ë°ì´í„° ë‚´ë³´ë‚´ê¸°**: CSV ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥

**ê°œì„  ê¸°íšŒ:**
1. **ë¡œë”© ìƒíƒœ í‘œì‹œ**: ë°ì´í„° ë¡œë”© ì‹œ ì‚¬ìš©ì í”¼ë“œë°± ë¶€ì¡±
2. **ì˜¤ë¥˜ ì²˜ë¦¬**: ì‚¬ìš©ì ì¹œí™”ì ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€ ë¶€ì¡±
3. **ì ‘ê·¼ì„±**: í‚¤ë³´ë“œ ë‚´ë¹„ê²Œì´ì…˜, ìŠ¤í¬ë¦° ë¦¬ë” ì§€ì› ê°•í™”
4. **ì„±ëŠ¥ ìµœì í™”**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ë Œë”ë§ ì‹œ ì„±ëŠ¥ ì €í•˜

### 3.2 ê³ ë„í™” ë°©ì•ˆ
```python
# 1. ë¡œë”© ìƒíƒœ í‘œì‹œ ê°œì„ 
class LoadingStateManager:
    def __init__(self):
        self.loading_states = {}
    
    def show_loading(self, component_id: str, message: str = "ë¡œë”© ì¤‘..."):
        """ë¡œë”© ìƒíƒœ í‘œì‹œ"""
        self.loading_states[component_id] = {
            "message": message,
            "start_time": time.time(),
            "progress": 0
        }
        
        # ìŠ¤í”¼ë„ˆì™€ ë©”ì‹œì§€ í‘œì‹œ
        st.spinner(f"{message} ({component_id})")
    
    def update_progress(self, component_id: str, progress: int):
        """ì§„í–‰ë¥  ì—…ë°ì´íŠ¸"""
        if component_id in self.loading_states:
            self.loading_states[component_id]["progress"] = progress
            elapsed = time.time() - self.loading_states[component_id]["start_time"]
            
            # ì§„í–‰ë¥  ë°” í‘œì‹œ
            st.progress(progress / 100)
            st.caption(f"{progress}% ì™„ë£Œ (ê²½ê³¼ ì‹œê°„: {elapsed:.1f}ì´ˆ)")

# 2. ì˜¤ë¥˜ ì²˜ë¦¬ ê°œì„ 
class ErrorHandler:
    def __init__(self):
        self.error_messages = {
            "network_error": "ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.",
            "data_not_found": "ìš”ì²­í•œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "rate_limit": "ìš”ì²­ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            "server_error": "ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        }
    
    def handle_error(self, error_type: str, details: str = None):
        """ì‚¬ìš©ì ì¹œí™”ì ì¸ ì˜¤ë¥˜ ì²˜ë¦¬"""
        message = self.error_messages.get(error_type, "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        
        if details:
            message += f"\n\nìƒì„¸ ì •ë³´: {details}"
        
        # ì˜¤ë¥˜ ìœ í˜•ë³„ ì•„ì´ì½˜ê³¼ ìƒ‰ìƒ
        error_config = {
            "icon": "âš ï¸" if error_type in ["network_error", "data_not_found"] else "âŒ",
            "color": "orange" if error_type in ["network_error", "rate_limit"] else "red"
        }
        
        st.error(f"{error_config['icon']} {message}")

# 3. ì ‘ê·¼ì„± ê°•í™”
class AccessibilityEnhancer:
    def __init__(self):
        self.keyboard_shortcuts = {
            "search": "Ctrl+K",
            "refresh": "F5",
            "help": "F1"
        }
    
    def add_keyboard_navigation(self):
        """í‚¤ë³´ë“œ ë‚´ë¹„ê²Œì´ì…˜ ì¶”ê°€"""
        st.markdown("""
        <script>
        document.addEventListener('keydown', function(e) {
            // Ctrl+Kë¡œ ê²€ìƒ‰ì°½ í¬ì»¤ìŠ¤
            if (e.ctrlKey && e.key === 'k') {
                e.preventDefault();
                document.querySelector('[data-testid="stTextInput"]').focus();
            }
        });
        </script>
        """, unsafe_allow_html=True)
    
    def add_screen_reader_support(self):
        """ìŠ¤í¬ë¦° ë¦¬ë” ì§€ì› ì¶”ê°€"""
        st.markdown("""
        <div role="status" aria-live="polite" id="screen-reader-status">
            ë°ì´í„° ë¡œë”©ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.
        </div>
        <script>
        function updateScreenReader(message) {
            document.getElementById('screen-reader-status').textContent = message;
        }
        </script>
        """, unsafe_allow_html=True)

# 4. ì„±ëŠ¥ ìµœì í™”
class PerformanceOptimizer:
    def __init__(self):
        self.data_cache = {}
        self.render_cache = {}
    
    def optimize_chart_rendering(self, data: pd.DataFrame, max_points: int = 1000):
        """ì°¨íŠ¸ ë Œë”ë§ ì„±ëŠ¥ ìµœì í™”"""
        if len(data) > max_points:
            # ë°ì´í„° ë‹¤ìš´ìƒ˜í”Œë§
            step = len(data) // max_points
            downsampled_data = data.iloc[::step]
            return downsampled_data
        return data
    
    def lazy_load_data(self, data_source: str, chunk_size: int = 1000):
        """ëŒ€ìš©ëŸ‰ ë°ì´í„° ì§€ì—° ë¡œë”©"""
        def data_generator():
            offset = 0
            while True:
                chunk = self._get_data_chunk(data_source, offset, chunk_size)
                if not chunk:
                    break
                
                yield chunk
                offset += chunk_size
        
        return data_generator()
```

## 4. ëª¨ë‹ˆí„°ë§ ë° ìš´ì˜

### 4.1 í˜„ì¬ ìƒíƒœ ë¶„ì„
**ê°•ì :**
- **ê¸°ë³¸ ë¡œê¹…**: êµ¬ì¡°í™”ëœ ë¡œê¹… ì‹œìŠ¤í…œ
- **í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸**: ê¸°ë³¸ì ì¸ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
- **ìºì‹œ í†µê³„**: ìºì‹œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- **ì—ëŸ¬ í•¸ë“¤ë§**: ì „ì—­ ì˜ˆì™¸ í•¸ë“¤ëŸ¬

**ê°œì„  ê¸°íšŒ:**
1. **ë©”íŠ¸ë¦­ ìˆ˜ì§‘**: ìƒì„¸í•œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë¶€ì¡±
2. **ì•Œë¦¼ ì‹œìŠ¤í…œ**: ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ìë™ ì•Œë¦¼ ë¶€ì¡±
3. **ë¡œê·¸ ë¶„ì„**: ë¡œê·¸ íŒ¨í„´ ë¶„ì„ ë° ì´ìƒ ê°ì§€ ë¶€ì¡±
4. **ëŒ€ì‹œë³´ë“œ**: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ë¶€ì¡±

### 4.2 ê³ ë„í™” ë°©ì•ˆ
```python
# 1. ìƒì„¸ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
class MetricsCollector:
    def __init__(self):
        self.metrics = {
            "api_requests": defaultdict(int),
            "response_times": defaultdict(list),
            "error_rates": defaultdict(float),
            "cache_hit_rates": defaultdict(float),
            "database_query_times": defaultdict(list)
        }
    
    async def record_api_request(self, endpoint: str, response_time: float, status_code: int):
        """API ìš”ì²­ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        self.metrics["api_requests"][endpoint] += 1
        self.metrics["response_times"][endpoint].append(response_time)
        
        if status_code >= 400:
            self.metrics["error_rates"][endpoint] += 1
    
    def get_metrics_summary(self) -> Dict[str, Any]:
        """ë©”íŠ¸ë¦­ ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        summary = {}
        
        for endpoint in self.metrics["api_requests"]:
            response_times = self.metrics["response_times"][endpoint]
            if response_times:
                summary[endpoint] = {
                    "total_requests": self.metrics["api_requests"][endpoint],
                    "avg_response_time": sum(response_times) / len(response_times),
                    "p95_response_time": sorted(response_times)[int(len(response_times) * 0.95)],
                    "p99_response_time": sorted(response_times)[int(len(response_times) * 0.99)],
                    "error_rate": self.metrics["error_rates"][endpoint] / self.metrics["api_requests"][endpoint]
                }
        
        return summary

# 2. ì•Œë¦¼ ì‹œìŠ¤í…œ
class AlertManager:
    def __init__(self):
        self.alert_thresholds = {
            "response_time_p95": 2.0,  # 95% ì‘ë‹µ ì‹œê°„ 2ì´ˆ ì´ˆê³¼
            "error_rate": 0.05,      # ì—ëŸ¬ìœ¨ 5% ì´ˆê³¼
            "cache_hit_rate": 0.8,   # ìºì‹œ íˆíŠ¸ìœ¨ 80% ë¯¸ë§Œ
            "memory_usage": 0.85,     # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 85% ì´ˆê³¼
            "cpu_usage": 0.80        # CPU ì‚¬ìš©ëŸ‰ 80% ì´ˆê³¼
        }
    
    async def check_alerts(self, metrics: Dict[str, Any]):
        """ì„ê³„ê°’ í™•ì¸ ë° ì•Œë¦¼ ë°œì†¡"""
        alerts = []
        
        for endpoint, metric in metrics.items():
            if metric["p95_response_time"] > self.alert_thresholds["response_time_p95"]:
                alerts.append({
                    "type": "performance",
                    "severity": "warning",
                    "message": f"{endpoint} ì—”ë“œí¬ì¸íŠ¸ ì‘ë‹µ ì‹œê°„ì´ ì„ê³„ê°’ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤: {metric['p95_response_time']:.2f}s"
                })
            
            if metric["error_rate"] > self.alert_thresholds["error_rate"]:
                alerts.append({
                    "type": "error",
                    "severity": "critical",
                    "message": f"{endpoint} ì—”ë“œí¬ì¸íŠ¸ ì—ëŸ¬ìœ¨ì´ ì„ê³„ê°’ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤: {metric['error_rate']:.2%}"
                })
        
        # ì•Œë¦¼ ë°œì†¡
        for alert in alerts:
            await self._send_alert(alert)
    
    async def _send_alert(self, alert: Dict[str, Any]):
        """ì•Œë¦¼ ë°œì†¡ (ìŠ¬ë™, ì´ë©”ì¼ ë“±)"""
        if alert["severity"] == "critical":
            # ì¦‰ì‹œ ì•Œë¦¼
            await self._send_slack_notification(alert)
            await self._send_email_notification(alert)
        else:
            # ì¼ì¼ ìš”ì•½ ì•Œë¦¼
            await self._queue_daily_summary(alert)

# 3. ë¡œê·¸ ë¶„ì„ ë° ì´ìƒ ê°ì§€
class LogAnalyzer:
    def __init__(self):
        self.log_patterns = {
            "error_spike": r"ERROR.*\{timestamp\}",
            "slow_query": r"Slow query.*\{duration\}",
            "memory_leak": r"Memory usage.*\{usage\}",
            "connection_timeout": r"Connection timeout"
        }
    
    async def analyze_logs(self, log_file: str, time_window: int = 3600):
        """ë¡œê·¸ íŒŒì¼ ë¶„ì„ ë° ì´ìƒ ê°ì§€"""
        current_time = time.time()
        start_time = current_time - time_window
        
        anomalies = []
        
        with open(log_file, 'r') as f:
            for line in f:
                log_entry = json.loads(line)
                log_time = log_entry.get('timestamp')
                
                if log_time and log_time >= start_time:
                    # ì—ëŸ¬ íŒ¨í„´ ë¶„ì„
                    for pattern_name, pattern in self.log_patterns.items():
                        if re.search(pattern, line):
                            anomalies.append({
                                "type": pattern_name,
                                "timestamp": log_time,
                                "details": log_entry
                            })
        
        return anomalies

# 4. ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
class MonitoringDashboard:
    def __init__(self):
        self.metrics_collector = MetricsCollector()
        self.alert_manager = AlertManager()
        self.log_analyzer = LogAnalyzer()
    
    def create_dashboard(self):
        """ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ìƒì„±"""
        st.title("ğŸ” InsiteChart ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ")
        
        # ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ í‘œì‹œ
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("API ìš”ì²­/ë¶„", self._get_api_requests_per_minute())
        
        with col2:
            st.metric("í‰ê·  ì‘ë‹µ ì‹œê°„", f"{self._get_avg_response_time():.3f}s")
        
        with col3:
            st.metric("ì—ëŸ¬ìœ¨", f"{self._get_error_rate():.2%}")
        
        with col4:
            st.metric("ìºì‹œ íˆíŠ¸ìœ¨", f"{self._get_cache_hit_rate():.2%}")
        
        # ì‹¤ì‹œê°„ ì°¨íŠ¸
        st.subheader("ğŸ“ˆ ì‹¤ì‹œê°„ ì„±ëŠ¥ ì°¨íŠ¸")
        
        # ì‘ë‹µ ì‹œê°„ íˆìŠ¤í† ë¦¬
        response_time_chart = self._create_response_time_chart()
        st.plotly_chart(response_time_chart)
        
        # ì—ëŸ¬ìœ¨ íˆìŠ¤í† ë¦¬
        error_rate_chart = self._create_error_rate_chart()
        st.plotly_chart(error_rate_chart)
        
        # ìµœê·¼ ì•Œë¦¼
        st.subheader("ğŸš¨ ìµœê·¼ ì•Œë¦¼")
        recent_alerts = self._get_recent_alerts()
        
        for alert in recent_alerts:
            severity_color = "red" if alert["severity"] == "critical" else "orange"
            st.markdown(f"""
            <div style="background-color: {severity_color}20; padding: 10px; border-radius: 5px; margin: 5px 0;">
                <strong>{alert['severity'].upper()}</strong>: {alert['message']}
                <br><small>{alert['timestamp']}</small>
            </div>
            """, unsafe_allow_html=True)
```

## 5. ìš°ì„ ìˆœìœ„ë³„ ê³ ë„í™” ì¶”ì²œ

### 5.1 ì¦‰ì‹œ ì‹¤í–‰ í•„ìš” (1-2ì£¼ ë‚´)

#### 5.1.1 ì„±ëŠ¥ ìµœì í™”
1. **ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ìµœì í™”**
   - N+1 ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì¡°ì¸ ì¿¼ë¦¬ êµ¬í˜„
   - ì¸ë±ìŠ¤ ìµœì í™” ë° ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš ë¶„ì„
   - ë°°ì¹˜ ì²˜ë¦¬ë¥¼ í†µí•œ ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œ ê°ì†Œ

2. **ìºì‹œ ì „ëµ ê°œì„ **
   - ìºì‹œ ì¼ê´€ì„± ë¬¸ì œ í•´ê²°
   - ë™ì  ìºì‹œ í¬ê¸° ê´€ë¦¬
   - ìºì‹œ ì›Œë° ì „ëµ êµ¬í˜„

3. **API ì‘ë‹µ ìµœì í™”**
   - ë¶ˆí•„ìš”í•œ ë°ì´í„° ì¤‘ë³µ ì œê±°
   - í˜ì´ì§€ë„¤ì´ì…˜ êµ¬í˜„
   - ì‘ë‹µ ì••ì¶• ì¶”ê°€

#### 5.1.2 ë³´ì•ˆ ê°•í™”
1. **ì…ë ¥ ê²€ì¦ ê°•í™”**
   - SQL ì¸ì ì…˜ ë°©ì–´ë¥¼ ìœ„í•œ ì…ë ¥ ì‚´ê·¹í™”
   - XSS ë°©ì–´ë¥¼ ìœ„í•œ ì¶œë ¥ ì¸ì½”ë”©
   - íŒŒì¼ ì—…ë¡œë“œ ë³´ì•ˆ ê°•í™”

2. **ì„¸ì…˜ ê´€ë¦¬ ê°œì„ **
   - ë™ì‹œ ì„¸ì…˜ ì œí•œ êµ¬í˜„
   - ì„¸ì…˜ í•˜ì´ì¬í‚¹ ë°©ì–´
   - í† í° ë¸”ë™ë¦¬ìŠ¤íŒ…

### 5.2 ë‹¨ê¸° ì‹¤í–‰ (2-4ì£¼ ë‚´)

#### 5.2.1 í…ŒìŠ¤íŠ¸ í’ˆì§ˆ í–¥ìƒ
1. **í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ í™•ëŒ€**
   - ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ 90% ì´ìƒ ë‹¬ì„±
   - í†µí•© í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ í™•ëŒ€
   - ì—ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸ ì¶”ê°€

2. **ë¶€í•˜ í…ŒìŠ¤íŠ¸ ê°•í™”**
   - ì‹¤ì œ ì‚¬ìš© íŒ¨í„´ ê¸°ë°˜ ë¶€í•˜ í…ŒìŠ¤íŠ¸
   - ë™ì‹œ ì‚¬ìš©ì 1000ëª… ì´ìƒ í…ŒìŠ¤íŠ¸
   - ì¥ì‹œê°„ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸

#### 5.2.2 ëª¨ë‹ˆí„°ë§ ê°•í™”
1. **ìƒì„¸ ë©”íŠ¸ë¦­ ìˆ˜ì§‘**
   - API ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìƒì„¸í™”
   - ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
   - ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§

2. **ìë™ ì•Œë¦¼ ì‹œìŠ¤í…œ**
   - ì„ê³„ê°’ ê¸°ë°˜ ìë™ ì•Œë¦¼
   - ì´ìƒ íŒ¨í„´ ê°ì§€
   - ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ êµ¬í˜„

### 5.3 ì¤‘ì¥ê¸° ì‹¤í–‰ (1-2ê°œì›” ë‚´)

#### 5.3.1 ì•„í‚¤í…ì²˜ ê°œì„ 
1. **ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì „í™˜ ì¤€ë¹„**
   - ì„œë¹„ìŠ¤ ê²½ê³„ ëª…í™•í™”
   - API ê²Œì´íŠ¸ì›¨ì´ êµ¬í˜„
   - ì„œë¹„ìŠ¤ ê°„ í†µì‹  í”„ë¡œí† ì½œ ì •ì˜

2. **ë°ì´í„° ì•„í‚¤í…ì²˜ ìµœì í™”**
   - íŒŒí‹°ì…”ë‹ ì „ëµ êµ¬í˜„
   - ë°ì´í„° ì•„ì¹´ì´ë¹™ ì‹œìŠ¤í…œ
   - ì½ê¸° ì „ìš© ë³µì œë³¸ êµ¬í˜„

#### 5.3.2 ì‚¬ìš©ì ê²½í—˜ ê°œì„ 
1. **UI/UX ê³ ë„í™”**
   - ë¡œë”© ìƒíƒœ í‘œì‹œ ê°œì„ 
   - ì˜¤ë¥˜ ì²˜ë¦¬ ì‚¬ìš©ì ì¹œí™”ì  ê°œì„ 
   - ì ‘ê·¼ì„± ê¸°ëŠ¥ ê°•í™”

2. **ì„±ëŠ¥ ìµœì í™”**
   - í´ë¼ì´ì–¸íŠ¸ ì¸¡ ìºì‹±
   - ë°ì´í„° ì§€ì—° ë¡œë”©
   - ì°¨íŠ¸ ë Œë”ë§ ìµœì í™”

## 6. ê²°ë¡ 

InsiteChart í”„ë¡œì íŠ¸ëŠ” í˜„ì¬ **ê¸°ìˆ ì ìœ¼ë¡œ ì•ˆì •ì ì¸ ê¸°ë°˜**ì„ ê°–ì¶”ê³  ìˆìœ¼ë©°, **í•µì‹¬ ê¸°ëŠ¥ë“¤ì´ ëŒ€ë¶€ë¶„ êµ¬í˜„**ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ìœ„ì—ì„œ ì‹ë³„ëœ ê³ ë„í™” ê¸°íšŒë“¤ì„ í†µí•´ **ìƒì‚°ì„±, ì•ˆì •ì„±, ì‚¬ìš©ì ê²½í—˜**ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ê°€ì¥ ì‹œê¸‰í•œ ê°œì„  ì‚¬í•­:**
1. **ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ìµœì í™”**ë¥¼ í†µí•œ ì„±ëŠ¥ í–¥ìƒ
2. **ë³´ì•ˆ ê°•í™”**ë¥¼ í†µí•œ ì‹œìŠ¤í…œ ì•ˆì •ì„± í™•ë³´
3. **í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ í™•ëŒ€**ë¥¼ í†µí•œ í’ˆì§ˆ ë³´ì¦ ê°•í™”

**ì¤‘ì¥ê¸° ê°œì„  ë°©í–¥:**
1. **ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜**ë¡œì˜ ì ì§„ì  ì „í™˜
2. **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë° ìë™í™”** ì‹œìŠ¤í…œ êµ¬ì¶•
3. **ì‚¬ìš©ì ê²½í—˜**ì˜ ì§€ì†ì ì¸ ê°œì„ 

ì´ëŸ¬í•œ ê³ ë„í™” ë°©ì•ˆë“¤ì„ ë‹¨ê³„ì ìœ¼ë¡œ êµ¬í˜„í•¨ìœ¼ë¡œì¨, InsiteChartëŠ” **ì—”í„°í”„ë¼ì´ì¦ˆ ìˆ˜ì¤€**ì˜ ê¸ˆìœµ ë¶„ì„ í”Œë«í¼ìœ¼ë¡œ ë°œì „í•  ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.