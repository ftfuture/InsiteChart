# ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼ ì‹œìŠ¤í…œ ì„¤ê³„

## 1. ê°œìš”

### 1.1 ëª¨ë‹ˆí„°ë§ì˜ ì¤‘ìš”ì„±

InsiteChart í”Œë«í¼ì€ ì‹¤ì‹œê°„ ê¸ˆìœµ ë°ì´í„°, ì‚¬ìš©ì í™œë™, ì‹œìŠ¤í…œ ì„±ëŠ¥ ë“± ë‹¤ì–‘í•œ ìš”ì†Œë¥¼ ëª¨ë‹ˆí„°ë§í•´ì•¼ í•©ë‹ˆë‹¤. í¬ê´„ì ì¸ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì€ ì‹œìŠ¤í…œ ì•ˆì •ì„±, ì„±ëŠ¥ ìµœì í™”, ì‚¬ì „ ì¥ì•  ê°ì§€, ì‚¬ìš©ì ê²½í—˜ ê°œì„ ì— í•„ìˆ˜ì ì…ë‹ˆë‹¤.

### 1.2 ëª¨ë‹ˆí„°ë§ ëª©í‘œ

1. **ì‹œìŠ¤í…œ ê°€ìš©ì„±**: 99.9% ì´ìƒ ì„œë¹„ìŠ¤ ê°€ìš©ì„± ë³´ì¥
2. **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: ì‘ë‹µ ì‹œê°„, ì²˜ë¦¬ëŸ‰, ìì› ì‚¬ìš©ë¥  ì¶”ì 
3. **ì‚¬ìš©ì ê²½í—˜**: ì‹¤ì œ ì‚¬ìš©ì ê²½í—˜ ê¸°ë°˜ ëª¨ë‹ˆí„°ë§
4. **ì‚¬ì „ ì¥ì•  ê°ì§€**: ì ì¬ì  ë¬¸ì œ ì¡°ê¸° ë°œê²¬ ë° ì•Œë¦¼
5. **ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸**: ì‚¬ìš©ì í–‰ë™, ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­ ë¶„ì„

## 2. ëª¨ë‹ˆí„°ë§ ì•„í‚¤í…ì²˜

### 2.1 ë‹¤ê³„ì¸µ ëª¨ë‹ˆí„°ë§ êµ¬ì¡°

```python
# monitoring/monitoring_manager.py
import asyncio
import time
import psutil
import json
from typing import Dict, List, Optional, Any, Callable
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from enum import Enum
import logging
import aiohttp
import redis.asyncio as redis

class MetricType(Enum):
    """ë©”íŠ¸ë¦­ íƒ€ì…"""
    COUNTER = "counter"       # ì¹´ìš´í„° (ëˆ„ì )
    GAUGE = "gauge"          # ê²Œì´ì§€ (í˜„ì¬ê°’)
    HISTOGRAM = "histogram"   # íˆìŠ¤í† ê·¸ë¨ (ë¶„í¬)
    SUMMARY = "summary"       # ìš”ì•½ (í†µê³„)

class MetricUnit(Enum):
    """ë©”íŠ¸ë¦­ ë‹¨ìœ„"""
    COUNT = "count"          # ê°œìˆ˜
    BYTES = "bytes"          # ë°”ì´íŠ¸
    SECONDS = "seconds"      # ì´ˆ
    MILLISECONDS = "ms"      # ë°€ë¦¬ì´ˆ
    PERCENT = "percent"      # ë°±ë¶„ìœ¨
    REQUESTS_PER_SECOND = "rps"  # ì´ˆë‹¹ ìš”ì²­ìˆ˜

@dataclass
class MetricDefinition:
    """ë©”íŠ¸ë¦­ ì •ì˜"""
    name: str
    metric_type: MetricType
    unit: MetricUnit
    description: str
    labels: List[str] = None
    enabled: bool = True

@dataclass
class MetricValue:
    """ë©”íŠ¸ë¦­ ê°’"""
    name: str
    value: float
    timestamp: datetime
    labels: Dict[str, str] = None
    metric_type: MetricType = MetricType.GAUGE

class MonitoringManager:
    """ëª¨ë‹ˆí„°ë§ ê´€ë¦¬ì"""
    
    def __init__(self, redis_url: str):
        self.redis = redis.from_url(redis_url)
        self.logger = logging.getLogger(__name__)
        
        # ë©”íŠ¸ë¦­ ì •ì˜
        self.metric_definitions = {
            # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
            'system_cpu_usage': MetricDefinition(
                name='system_cpu_usage',
                metric_type=MetricType.GAUGE,
                unit=MetricUnit.PERCENT,
                description='System CPU usage percentage',
                labels=['host', 'core']
            ),
            'system_memory_usage': MetricDefinition(
                name='system_memory_usage',
                metric_type=MetricType.GAUGE,
                unit=MetricUnit.PERCENT,
                description='System memory usage percentage',
                labels=['host']
            ),
            'system_disk_usage': MetricDefinition(
                name='system_disk_usage',
                metric_type=MetricType.GAUGE,
                unit=MetricUnit.PERCENT,
                description='System disk usage percentage',
                labels=['host', 'mount_point']
            ),
            
            # ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”íŠ¸ë¦­
            'http_requests_total': MetricDefinition(
                name='http_requests_total',
                metric_type=MetricType.COUNTER,
                unit=MetricUnit.COUNT,
                description='Total HTTP requests',
                labels=['method', 'endpoint', 'status_code']
            ),
            'http_request_duration': MetricDefinition(
                name='http_request_duration',
                metric_type=MetricType.HISTOGRAM,
                unit=MetricUnit.MILLISECONDS,
                description='HTTP request duration in milliseconds',
                labels=['method', 'endpoint']
            ),
            'active_connections': MetricDefinition(
                name='active_connections',
                metric_type=MetricType.GAUGE,
                unit=MetricUnit.COUNT,
                description='Number of active connections',
                labels=['service']
            ),
            
            # ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­
            'users_active': MetricDefinition(
                name='users_active',
                metric_type=MetricType.GAUGE,
                unit=MetricUnit.COUNT,
                description='Number of active users',
                labels=['time_window']
            ),
            'stock_searches_total': MetricDefinition(
                name='stock_searches_total',
                metric_type=MetricType.COUNTER,
                unit=MetricUnit.COUNT,
                description='Total stock searches',
                labels=['symbol', 'source']
            ),
            'sentiment_analyses_total': MetricDefinition(
                name='sentiment_analyses_total',
                metric_type=MetricType.COUNTER,
                unit=MetricUnit.COUNT,
                description='Total sentiment analyses',
                labels=['symbol', 'source', 'sentiment']
            ),
            
            # ë°ì´í„°ë² ì´ìŠ¤ ë©”íŠ¸ë¦­
            'db_connections_active': MetricDefinition(
                name='db_connections_active',
                metric_type=MetricType.GAUGE,
                unit=MetricUnit.COUNT,
                description='Active database connections',
                labels=['database']
            ),
            'db_query_duration': MetricDefinition(
                name='db_query_duration',
                metric_type=MetricType.HISTOGRAM,
                unit=MetricUnit.MILLISECONDS,
                description='Database query duration',
                labels=['database', 'query_type']
            ),
            
            # ìºì‹œ ë©”íŠ¸ë¦­
            'cache_hits_total': MetricDefinition(
                name='cache_hits_total',
                metric_type=MetricType.COUNTER,
                unit=MetricUnit.COUNT,
                description='Total cache hits',
                labels=['cache_type', 'key_prefix']
            ),
            'cache_misses_total': MetricDefinition(
                name='cache_misses_total',
                metric_type=MetricType.COUNTER,
                unit=MetricUnit.COUNT,
                description='Total cache misses',
                labels=['cache_type', 'key_prefix']
            ),
            
            # ì™¸ë¶€ API ë©”íŠ¸ë¦­
            'external_api_requests_total': MetricDefinition(
                name='external_api_requests_total',
                metric_type=MetricType.COUNTER,
                unit=MetricUnit.COUNT,
                description='Total external API requests',
                labels=['api_provider', 'endpoint', 'status']
            ),
            'external_api_response_time': MetricDefinition(
                name='external_api_response_time',
                metric_type=MetricType.HISTOGRAM,
                unit=MetricUnit.MILLISECONDS,
                description='External API response time',
                labels=['api_provider', 'endpoint']
            )
        }
        
        # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ë“±ë¡
        self.collectors = {
            'system': SystemMetricsCollector(),
            'application': ApplicationMetricsCollector(),
            'business': BusinessMetricsCollector(),
            'database': DatabaseMetricsCollector(),
            'cache': CacheMetricsCollector(),
            'external_api': ExternalAPIMetricsCollector()
        }
        
        # ë©”íŠ¸ë¦­ ì €ì¥ì†Œ
        self.metrics_store = MetricsStore(self.redis)
        
        # ìˆ˜ì§‘ ì‘ì—… ìƒíƒœ
        self.collection_tasks = {}
        self.collection_intervals = {
            'system': 30,      # 30ì´ˆ
            'application': 15,  # 15ì´ˆ
            'business': 60,      # 1ë¶„
            'database': 30,      # 30ì´ˆ
            'cache': 30,         # 30ì´ˆ
            'external_api': 60   # 1ë¶„
        }
    
    async def start_collection(self):
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œì‘"""
        
        self.logger.info("Starting metrics collection")
        
        for collector_name, collector in self.collectors.items():
            interval = self.collection_intervals.get(collector_name, 60)
            
            task = asyncio.create_task(
                self._collect_metrics_loop(collector_name, collector, interval)
            )
            
            self.collection_tasks[collector_name] = task
    
    async def stop_collection(self):
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì¤‘ì§€"""
        
        self.logger.info("Stopping metrics collection")
        
        for task in self.collection_tasks.values():
            task.cancel()
        
        # ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
        await asyncio.gather(*self.collection_tasks.values(), return_exceptions=True)
        
        self.collection_tasks.clear()
    
    async def _collect_metrics_loop(self, 
                                   collector_name: str, 
                                   collector, 
                                   interval: int):
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë£¨í”„"""
        
        while True:
            try:
                # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                metrics = await collector.collect_metrics()
                
                # ë©”íŠ¸ë¦­ ì €ì¥
                for metric in metrics:
                    await self.metrics_store.store_metric(metric)
                
                self.logger.debug(f"Collected {len(metrics)} metrics from {collector_name}")
                
            except Exception as e:
                self.logger.error(f"Error collecting metrics from {collector_name}: {str(e)}")
            
            # ë‹¤ìŒ ìˆ˜ì§‘ê¹Œì§€ ëŒ€ê¸°
            await asyncio.sleep(interval)
    
    def record_metric(self, 
                     name: str, 
                     value: float, 
                     labels: Dict[str, str] = None,
                     timestamp: datetime = None):
        """ë©”íŠ¸ë¦­ ê¸°ë¡"""
        
        if timestamp is None:
            timestamp = datetime.now()
        
        metric = MetricValue(
            name=name,
            value=value,
            timestamp=timestamp,
            labels=labels or {}
        )
        
        asyncio.create_task(self.metrics_store.store_metric(metric))
    
    def increment_counter(self, 
                        name: str, 
                        value: float = 1.0, 
                        labels: Dict[str, str] = None):
        """ì¹´ìš´í„° ì¦ê°€"""
        
        self.record_metric(name, value, labels)
    
    def set_gauge(self, 
                  name: str, 
                  value: float, 
                  labels: Dict[str, str] = None):
        """ê²Œì´ì§€ ì„¤ì •"""
        
        self.record_metric(name, value, labels)
    
    def record_histogram(self, 
                       name: str, 
                       value: float, 
                       labels: Dict[str, str] = None):
        """íˆìŠ¤í† ê·¸ë¨ ê¸°ë¡"""
        
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë²„í‚·ì— ê°’ ë¶„ë°°
        self.record_metric(name, value, labels)
    
    async def get_metrics(self, 
                        name: str, 
                        start_time: datetime, 
                        end_time: datetime,
                        labels: Dict[str, str] = None) -> List[MetricValue]:
        """ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        
        return await self.metrics_store.get_metrics(name, start_time, end_time, labels)
    
    async def get_metric_summary(self, 
                               name: str, 
                               start_time: datetime, 
                               end_time: datetime,
                               aggregation: str = 'avg') -> Dict[str, Any]:
        """ë©”íŠ¸ë¦­ ìš”ì•½ ì¡°íšŒ"""
        
        metrics = await self.get_metrics(name, start_time, end_time)
        
        if not metrics:
            return {}
        
        values = [m.value for m in metrics]
        
        if aggregation == 'avg':
            return {'value': sum(values) / len(values), 'count': len(values)}
        elif aggregation == 'min':
            return {'value': min(values), 'count': len(values)}
        elif aggregation == 'max':
            return {'value': max(values), 'count': len(values)}
        elif aggregation == 'sum':
            return {'value': sum(values), 'count': len(values)}
        else:
            return {'value': sum(values) / len(values), 'count': len(values)}

class MetricsStore:
    """ë©”íŠ¸ë¦­ ì €ì¥ì†Œ"""
    
    def __init__(self, redis_client):
        self.redis = redis_client
        self.logger = logging.getLogger(__name__)
        
        # ë©”íŠ¸ë¦­ ë³´ê´€ ê¸°ê°„ (ì´ˆ)
        self.retention_periods = {
            'system': 7 * 24 * 3600,      # 7ì¼
            'application': 30 * 24 * 3600,  # 30ì¼
            'business': 90 * 24 * 3600,    # 90ì¼
            'database': 30 * 24 * 3600,    # 30ì¼
            'cache': 7 * 24 * 3600,        # 7ì¼
            'external_api': 30 * 24 * 3600  # 30ì¼
        }
    
    async def store_metric(self, metric: MetricValue):
        """ë©”íŠ¸ë¦­ ì €ì¥"""
        
        try:
            # ë©”íŠ¸ë¦­ íƒ€ì… ê²°ì •
            metric_type = self._determine_metric_type(metric.name)
            
            # í‚¤ ìƒì„±
            key = f"metrics:{metric_type}:{metric.name}"
            
            # ë ˆì´ë¸” í¬í•¨ í‚¤ ìƒì„±
            if metric.labels:
                label_str = ','.join(f"{k}={v}" for k, v in sorted(metric.labels.items()))
                key += f":{label_str}"
            
            # Redisì— ì €ì¥
            await self.redis.zadd(
                key,
                {str(metric.value): metric.timestamp.timestamp()}
            )
            
            # ë§Œë£Œ ì‹œê°„ ì„¤ì •
            retention = self.retention_periods.get(metric_type, 7 * 24 * 3600)
            await self.redis.expire(key, retention)
            
        except Exception as e:
            self.logger.error(f"Error storing metric {metric.name}: {str(e)}")
    
    def _determine_metric_type(self, metric_name: str) -> str:
        """ë©”íŠ¸ë¦­ íƒ€ì… ê²°ì •"""
        
        if 'system_' in metric_name:
            return 'system'
        elif 'http_' in metric_name or 'active_connections' in metric_name:
            return 'application'
        elif 'users_' in metric_name or 'stock_' in metric_name or 'sentiment_' in metric_name:
            return 'business'
        elif 'db_' in metric_name:
            return 'database'
        elif 'cache_' in metric_name:
            return 'cache'
        elif 'external_api_' in metric_name:
            return 'external_api'
        
        return 'application'  # ê¸°ë³¸ê°’
    
    async def get_metrics(self, 
                        name: str, 
                        start_time: datetime, 
                        end_time: datetime,
                        labels: Dict[str, str] = None) -> List[MetricValue]:
        """ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        
        try:
            # ë©”íŠ¸ë¦­ íƒ€ì… ê²°ì •
            metric_type = self._determine_metric_type(name)
            
            # í‚¤ ìƒì„±
            key = f"metrics:{metric_type}:{name}"
            
            # ë ˆì´ë¸” í¬í•¨ í‚¤ ìƒì„±
            if labels:
                label_str = ','.join(f"{k}={v}" for k, v in sorted(labels.items()))
                key += f":{label_str}"
            
            # ì‹œê°„ ë²”ìœ„ë¡œ ë©”íŠ¸ë¦­ ì¡°íšŒ
            start_timestamp = start_time.timestamp()
            end_timestamp = end_time.timestamp()
            
            results = await self.redis.zrangebyscore(
                key, 
                start_timestamp, 
                end_timestamp, 
                withscores=True
            )
            
            # MetricValue ê°ì²´ë¡œ ë³€í™˜
            metrics = []
            for value_str, timestamp in results:
                try:
                    value = float(value_str)
                    metric_time = datetime.fromtimestamp(timestamp)
                    
                    metric = MetricValue(
                        name=name,
                        value=value,
                        timestamp=metric_time,
                        labels=labels or {}
                    )
                    
                    metrics.append(metric)
                except (ValueError, TypeError):
                    continue
            
            return sorted(metrics, key=lambda x: x.timestamp)
            
        except Exception as e:
            self.logger.error(f"Error retrieving metrics {name}: {str(e)}")
            return []

class SystemMetricsCollector:
    """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°"""
    
    async def collect_metrics(self) -> List[MetricValue]:
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        
        metrics = []
        hostname = psutil.os.uname().nodename
        timestamp = datetime.now()
        
        try:
            # CPU ì‚¬ìš©ë¥ 
            cpu_percent = psutil.cpu_percent(interval=1)
            metrics.append(MetricValue(
                name='system_cpu_usage',
                value=cpu_percent,
                timestamp=timestamp,
                labels={'host': hostname}
            ))
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
            memory = psutil.virtual_memory()
            metrics.append(MetricValue(
                name='system_memory_usage',
                value=memory.percent,
                timestamp=timestamp,
                labels={'host': hostname}
            ))
            
            # ë””ìŠ¤í¬ ì‚¬ìš©ë¥ 
            disk_partitions = psutil.disk_partitions()
            for partition in disk_partitions:
                try:
                    disk_usage = psutil.disk_usage(partition.mountpoint)
                    metrics.append(MetricValue(
                        name='system_disk_usage',
                        value=(disk_usage.used / disk_usage.total) * 100,
                        timestamp=timestamp,
                        labels={
                            'host': hostname,
                            'mount_point': partition.mountpoint
                        }
                    ))
                except (PermissionError, OSError):
                    continue
            
            # ë„¤íŠ¸ì›Œí¬ I/O
            network_io = psutil.net_io_counters()
            metrics.append(MetricValue(
                name='system_network_bytes_sent',
                value=network_io.bytes_sent,
                timestamp=timestamp,
                labels={'host': hostname}
            ))
            metrics.append(MetricValue(
                name='system_network_bytes_recv',
                value=network_io.bytes_recv,
                timestamp=timestamp,
                labels={'host': hostname}
            ))
            
        except Exception as e:
            logging.getLogger(__name__).error(f"Error collecting system metrics: {str(e)}")
        
        return metrics

class ApplicationMetricsCollector:
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.request_count = 0
        self.request_durations = []
        self.active_connections = 0
    
    async def collect_metrics(self) -> List[MetricValue]:
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        
        metrics = []
        timestamp = datetime.now()
        
        # ìš”ì²­ ì¹´ìš´í„°
        metrics.append(MetricValue(
            name='http_requests_total',
            value=self.request_count,
            timestamp=timestamp
        ))
        
        # í™œì„± ì—°ê²° ìˆ˜
        metrics.append(MetricValue(
            name='active_connections',
            value=self.active_connections,
            timestamp=timestamp,
            labels={'service': 'api_gateway'}
        ))
        
        # ìš”ì²­ ì§€ì—° ì‹œê°„ íˆìŠ¤í† ê·¸ë¨
        if self.request_durations:
            avg_duration = sum(self.request_durations) / len(self.request_durations)
            metrics.append(MetricValue(
                name='http_request_duration',
                value=avg_duration,
                timestamp=timestamp,
                labels={'method': 'ALL', 'endpoint': 'ALL'}
            ))
            
            # íˆìŠ¤í† ê·¸ë¨ ë°ì´í„° ì´ˆê¸°í™”
            self.request_durations = []
        
        return metrics
    
    def record_request(self, method: str, endpoint: str, status_code: int, duration: float):
        """ìš”ì²­ ê¸°ë¡"""
        
        self.request_count += 1
        self.request_durations.append(duration)
    
    def increment_connections(self):
        """ì—°ê²° ì¦ê°€"""
        self.active_connections += 1
    
    def decrement_connections(self):
        """ì—°ê²° ê°ì†Œ"""
        self.active_connections = max(0, self.active_connections - 1)

class BusinessMetricsCollector:
    """ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.active_users = set()
        self.stock_searches = {}
        self.sentiment_analyses = {}
    
    async def collect_metrics(self) -> List[MetricValue]:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        
        metrics = []
        timestamp = datetime.now()
        
        # í™œì„± ì‚¬ìš©ì ìˆ˜
        metrics.append(MetricValue(
            name='users_active',
            value=len(self.active_users),
            timestamp=timestamp,
            labels={'time_window': 'current'}
        ))
        
        # ì£¼ì‹ ê²€ìƒ‰ ìˆ˜
        total_searches = sum(self.stock_searches.values())
        metrics.append(MetricValue(
            name='stock_searches_total',
            value=total_searches,
            timestamp=timestamp
        ))
        
        # ê°ì„± ë¶„ì„ ìˆ˜
        total_analyses = sum(self.sentiment_analyses.values())
        metrics.append(MetricValue(
            name='sentiment_analyses_total',
            value=total_analyses,
            timestamp=timestamp
        ))
        
        return metrics
    
    def record_user_activity(self, user_id: str):
        """ì‚¬ìš©ì í™œë™ ê¸°ë¡"""
        self.active_users.add(user_id)
    
    def record_stock_search(self, symbol: str, source: str = 'api'):
        """ì£¼ì‹ ê²€ìƒ‰ ê¸°ë¡"""
        key = f"{symbol}:{source}"
        self.stock_searches[key] = self.stock_searches.get(key, 0) + 1
    
    def record_sentiment_analysis(self, symbol: str, source: str, sentiment: str):
        """ê°ì„± ë¶„ì„ ê¸°ë¡"""
        key = f"{symbol}:{source}:{sentiment}"
        self.sentiment_analyses[key] = self.sentiment_analyses.get(key, 0) + 1

class DatabaseMetricsCollector:
    """ë°ì´í„°ë² ì´ìŠ¤ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.connection_pool = None
    
    async def collect_metrics(self) -> List[MetricValue]:
        """ë°ì´í„°ë² ì´ìŠ¤ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        
        metrics = []
        timestamp = datetime.now()
        
        try:
            if self.connection_pool:
                # í™œì„± ì—°ê²° ìˆ˜
                active_connections = len(self.connection_pool._pool)
                metrics.append(MetricValue(
                    name='db_connections_active',
                    value=active_connections,
                    timestamp=timestamp,
                    labels={'database': 'postgresql'}
                ))
                
                # ì—°ê²° í’€ ìƒíƒœ
                pool_size = self.connection_pool.size
                metrics.append(MetricValue(
                    name='db_connection_pool_size',
                    value=pool_size,
                    timestamp=timestamp,
                    labels={'database': 'postgresql'}
                ))
        
        except Exception as e:
            self.logger.error(f"Error collecting database metrics: {str(e)}")
        
        return metrics

class CacheMetricsCollector:
    """ìºì‹œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.redis_client = None
        self.cache_hits = 0
        self.cache_misses = 0
    
    async def collect_metrics(self) -> List[MetricValue]:
        """ìºì‹œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        
        metrics = []
        timestamp = datetime.now()
        
        try:
            if self.redis_client:
                # Redis ì •ë³´ ì¡°íšŒ
                info = await self.redis_client.info()
                
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
                used_memory = info.get('used_memory', 0)
                metrics.append(MetricValue(
                    name='cache_memory_usage_bytes',
                    value=used_memory,
                    timestamp=timestamp,
                    labels={'cache_type': 'redis'}
                ))
                
                # ì—°ê²° ìˆ˜
                connected_clients = info.get('connected_clients', 0)
                metrics.append(MetricValue(
                    name='cache_connections',
                    value=connected_clients,
                    timestamp=timestamp,
                    labels={'cache_type': 'redis'}
                ))
                
                # ìºì‹œ ì ì¤‘ë¥ 
                total_requests = self.cache_hits + self.cache_misses
                if total_requests > 0:
                    hit_rate = (self.cache_hits / total_requests) * 100
                    metrics.append(MetricValue(
                        name='cache_hit_rate',
                        value=hit_rate,
                        timestamp=timestamp,
                        labels={'cache_type': 'redis'}
                    ))
        
        except Exception as e:
            self.logger.error(f"Error collecting cache metrics: {str(e)}")
        
        return metrics
    
    def record_cache_hit(self, key_prefix: str = 'default'):
        """ìºì‹œ ì ì¤‘ ê¸°ë¡"""
        self.cache_hits += 1
    
    def record_cache_miss(self, key_prefix: str = 'default'):
        """ìºì‹œ ë¯¸ìŠ¤ ê¸°ë¡"""
        self.cache_misses += 1

class ExternalAPIMetricsCollector:
    """ì™¸ë¶€ API ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.api_requests = {}
        self.api_response_times = {}
    
    async def collect_metrics(self) -> List[MetricValue]:
        """ì™¸ë¶€ API ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        
        metrics = []
        timestamp = datetime.now()
        
        # APIë³„ ìš”ì²­ ìˆ˜
        for api_key, count in self.api_requests.items():
            api_provider, endpoint = api_key.split(':', 1)
            metrics.append(MetricValue(
                name='external_api_requests_total',
                value=count,
                timestamp=timestamp,
                labels={
                    'api_provider': api_provider,
                    'endpoint': endpoint
                }
            ))
        
        # APIë³„ ì‘ë‹µ ì‹œê°„
        for api_key, times in self.api_response_times.items():
            if times:
                api_provider, endpoint = api_key.split(':', 1)
                avg_time = sum(times) / len(times)
                metrics.append(MetricValue(
                    name='external_api_response_time',
                    value=avg_time,
                    timestamp=timestamp,
                    labels={
                        'api_provider': api_provider,
                        'endpoint': endpoint
                    }
                ))
        
        return metrics
    
    def record_api_request(self, api_provider: str, endpoint: str, status: str, response_time: float):
        """API ìš”ì²­ ê¸°ë¡"""
        
        key = f"{api_provider}:{endpoint}"
        
        # ìš”ì²­ ìˆ˜ ì¦ê°€
        self.api_requests[key] = self.api_requests.get(key, 0) + 1
        
        # ì‘ë‹µ ì‹œê°„ ê¸°ë¡
        if key not in self.api_response_times:
            self.api_response_times[key] = []
        
        self.api_response_times[key].append(response_time)
        
        # ìµœê·¼ 100ê°œë§Œ ìœ ì§€
        if len(self.api_response_times[key]) > 100:
            self.api_response_times[key] = self.api_response_times[key][-100:]
```

### 2.2 ì•Œë¦¼ ì‹œìŠ¤í…œ

```python
# monitoring/alerting_system.py
import asyncio
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from typing import Dict, List, Optional, Any, Callable
from datetime import datetime, timedelta
from dataclasses import dataclass
from enum import Enum
import logging
import json
import aiohttp

class AlertSeverity(Enum):
    """ì•Œë¦¼ ì‹¬ê°ë„"""
    INFO = "info"           # ì •ë³´
    WARNING = "warning"       # ê²½ê³ 
    ERROR = "error"          # ì—ëŸ¬
    CRITICAL = "critical"    # ì¹˜ëª…ì 

class AlertStatus(Enum):
    """ì•Œë¦¼ ìƒíƒœ"""
    FIRING = "firing"        # ë°œìƒ ì¤‘
    RESOLVED = "resolved"    # í•´ê²°ë¨

@dataclass
class AlertRule:
    """ì•Œë¦¼ ê·œì¹™"""
    name: str
    description: str
    metric_name: str
    condition: str  # ì¡°ê±´ í‘œí˜„ì‹
    threshold: float
    severity: AlertSeverity
    duration: int  # ì§€ì† ì‹œê°„ (ì´ˆ)
    enabled: bool = True
    labels: Dict[str, str] = None
    annotations: Dict[str, str] = None

@dataclass
class Alert:
    """ì•Œë¦¼"""
    id: str
    rule_name: str
    status: AlertStatus
    severity: AlertSeverity
    message: str
    labels: Dict[str, str]
    annotations: Dict[str, str]
    start_time: datetime
    end_time: Optional[datetime] = None
    fingerprint: str = None

@dataclass
class NotificationChannel:
    """ì•Œë¦¼ ì±„ë„"""
    name: str
    type: str  # email, slack, webhook, sms
    config: Dict[str, Any]
    enabled: bool = True

class AlertManager:
    """ì•Œë¦¼ ê´€ë¦¬ì"""
    
    def __init__(self, monitoring_manager):
        self.monitoring_manager = monitoring_manager
        self.logger = logging.getLogger(__name__)
        
        # ì•Œë¦¼ ê·œì¹™
        self.alert_rules: Dict[str, AlertRule] = {}
        
        # í™œì„± ì•Œë¦¼
        self.active_alerts: Dict[str, Alert] = {}
        
        # ì•Œë¦¼ ì±„ë„
        self.notification_channels: Dict[str, NotificationChannel] = {}
        
        # ì•Œë¦¼ í•¸ë“¤ëŸ¬
        self.notification_handlers = {
            'email': EmailNotificationHandler(),
            'slack': SlackNotificationHandler(),
            'webhook': WebhookNotificationHandler(),
            'sms': SMSNotificationHandler()
        }
        
        # ì•Œë¦¼ ìƒíƒœ ì¶”ì 
        self.alert_states: Dict[str, Dict] = {}
        
        # ê¸°ë³¸ ê·œì¹™ ì´ˆê¸°í™”
        self._initialize_default_rules()
        
        # ê¸°ë³¸ ì•Œë¦¼ ì±„ë„ ì´ˆê¸°í™”
        self._initialize_default_channels()
    
    def _initialize_default_rules(self):
        """ê¸°ë³¸ ì•Œë¦¼ ê·œì¹™ ì´ˆê¸°í™”"""
        
        # ì‹œìŠ¤í…œ CPU ì‚¬ìš©ë¥  ì•Œë¦¼
        cpu_rule = AlertRule(
            name="high_cpu_usage",
            description="High CPU usage detected",
            metric_name="system_cpu_usage",
            condition=">=",
            threshold=80.0,
            severity=AlertSeverity.WARNING,
            duration=300,  # 5ë¶„
            labels={'component': 'system'},
            annotations={'summary': 'CPU usage is above 80% for 5 minutes'}
        )
        
        # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì•Œë¦¼
        memory_rule = AlertRule(
            name="high_memory_usage",
            description="High memory usage detected",
            metric_name="system_memory_usage",
            condition=">=",
            threshold=85.0,
            severity=AlertSeverity.WARNING,
            duration=300,  # 5ë¶„
            labels={'component': 'system'},
            annotations={'summary': 'Memory usage is above 85% for 5 minutes'}
        )
        
        # ë””ìŠ¤í¬ ì‚¬ìš©ë¥  ì•Œë¦¼
        disk_rule = AlertRule(
            name="high_disk_usage",
            description="High disk usage detected",
            metric_name="system_disk_usage",
            condition=">=",
            threshold=90.0,
            severity=AlertSeverity.CRITICAL,
            duration=600,  # 10ë¶„
            labels={'component': 'system'},
            annotations={'summary': 'Disk usage is above 90% for 10 minutes'}
        )
        
        # HTTP ì—ëŸ¬ìœ¨ ì•Œë¦¼
        http_error_rule = AlertRule(
            name="high_http_error_rate",
            description="High HTTP error rate detected",
            metric_name="http_requests_total",
            condition=">=",
            threshold=100.0,  # 5ë¶„ ë™ì•ˆ 100ê°œ ì´ìƒì˜ 5xx ì—ëŸ¬
            severity=AlertSeverity.ERROR,
            duration=300,  # 5ë¶„
            labels={'component': 'application'},
            annotations={'summary': 'HTTP error rate is high'}
        )
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì•Œë¦¼
        db_connection_rule = AlertRule(
            name="database_connection_failure",
            description="Database connection failure",
            metric_name="db_connections_active",
            condition="==",
            threshold=0.0,
            severity=AlertSeverity.CRITICAL,
            duration=60,  # 1ë¶„
            labels={'component': 'database'},
            annotations={'summary': 'No active database connections'}
        )
        
        # ìºì‹œ ì ì¤‘ë¥  ì•Œë¦¼
        cache_hit_rate_rule = AlertRule(
            name="low_cache_hit_rate",
            description="Low cache hit rate detected",
            metric_name="cache_hit_rate",
            condition="<=",
            threshold=70.0,
            severity=AlertSeverity.WARNING,
            duration=600,  # 10ë¶„
            labels={'component': 'cache'},
            annotations={'summary': 'Cache hit rate is below 70%'}
        )
        
        # ì™¸ë¶€ API ì‘ë‹µ ì‹œê°„ ì•Œë¦¼
        api_response_time_rule = AlertRule(
            name="slow_external_api",
            description="Slow external API response",
            metric_name="external_api_response_time",
            condition=">=",
            threshold=5000.0,  # 5ì´ˆ
            severity=AlertSeverity.WARNING,
            duration=300,  # 5ë¶„
            labels={'component': 'external_api'},
            annotations={'summary': 'External API response time is above 5 seconds'}
        )
        
        self.alert_rules = {
            "high_cpu_usage": cpu_rule,
            "high_memory_usage": memory_rule,
            "high_disk_usage": disk_rule,
            "high_http_error_rate": http_error_rule,
            "database_connection_failure": db_connection_rule,
            "low_cache_hit_rate": cache_hit_rate_rule,
            "slow_external_api": api_response_time_rule
        }
    
    def _initialize_default_channels(self):
        """ê¸°ë³¸ ì•Œë¦¼ ì±„ë„ ì´ˆê¸°í™”"""
        
        # ì´ë©”ì¼ ì±„ë„
        email_channel = NotificationChannel(
            name="email",
            type="email",
            config={
                "smtp_server": "smtp.gmail.com",
                "smtp_port": 587,
                "username": "alerts@insitechart.com",
                "password": "password",
                "from_address": "alerts@insitechart.com",
                "to_addresses": ["admin@insitechart.com", "devops@insitechart.com"]
            }
        )
        
        # Slack ì±„ë„
        slack_channel = NotificationChannel(
            name="slack",
            type="slack",
            config={
                "webhook_url": "https://hooks.slack.com/services/...",
                "channel": "#alerts",
                "username": "InsiteChart Bot"
            }
        )
        
        # ì›¹í›… ì±„ë„
        webhook_channel = NotificationChannel(
            name="webhook",
            type="webhook",
            config={
                "url": "https://api.insitechart.com/webhooks/alerts",
                "headers": {"Authorization": "Bearer token"}
            }
        )
        
        self.notification_channels = {
            "email": email_channel,
            "slack": slack_channel,
            "webhook": webhook_channel
        }
    
    async def start_monitoring(self):
        """ì•Œë¦¼ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        
        self.logger.info("Starting alert monitoring")
        
        # ì•Œë¦¼ í‰ê°€ ë£¨í”„
        while True:
            try:
                await self._evaluate_alert_rules()
                await asyncio.sleep(60)  # 1ë¶„ë§ˆë‹¤ í‰ê°€
            except Exception as e:
                self.logger.error(f"Error in alert monitoring: {str(e)}")
                await asyncio.sleep(60)
    
    async def _evaluate_alert_rules(self):
        """ì•Œë¦¼ ê·œì¹™ í‰ê°€"""
        
        current_time = datetime.now()
        
        for rule_name, rule in self.alert_rules.items():
            if not rule.enabled:
                continue
            
            try:
                # ê·œì¹™ ìƒíƒœ ì´ˆê¸°í™”
                if rule_name not in self.alert_states:
                    self.alert_states[rule_name] = {
                        'last_evaluation': current_time,
                        'condition_met_since': None,
                        'alert_sent': False
                    }
                
                rule_state = self.alert_states[rule_name]
                
                # ë©”íŠ¸ë¦­ ì¡°íšŒ
                end_time = current_time
                start_time = current_time - timedelta(seconds=rule.duration)
                
                # ìµœì‹  ë©”íŠ¸ë¦­ ê°’ ì¡°íšŒ
                metrics = await self.monitoring_manager.get_metrics(
                    rule.metric_name,
                    start_time,
                    end_time,
                    rule.labels
                )
                
                if not metrics:
                    continue
                
                # ì¡°ê±´ í‰ê°€
                latest_metric = metrics[-1]
                condition_met = self._evaluate_condition(
                    latest_metric.value, 
                    rule.condition, 
                    rule.threshold
                )
                
                # ì•Œë¦¼ ìƒíƒœ ê²°ì •
                if condition_met:
                    if rule_state['condition_met_since'] is None:
                        rule_state['condition_met_since'] = current_time
                    
                    # ì§€ì† ì‹œê°„ í™•ì¸
                    condition_duration = (current_time - rule_state['condition_met_since']).total_seconds()
                    
                    if condition_duration >= rule.duration and not rule_state['alert_sent']:
                        # ì•Œë¦¼ ë°œìƒ
                        await self._fire_alert(rule, latest_metric)
                        rule_state['alert_sent'] = True
                
                else:
                    # ì¡°ê±´ì´ ë§Œì¡±ë˜ì§€ ì•Šìœ¼ë©´ ìƒíƒœ ì´ˆê¸°í™”
                    rule_state['condition_met_since'] = None
                    
                    if rule_state['alert_sent']:
                        # ì•Œë¦¼ í•´ê²°
                        await self._resolve_alert(rule_name)
                        rule_state['alert_sent'] = False
                
                rule_state['last_evaluation'] = current_time
                
            except Exception as e:
                self.logger.error(f"Error evaluating rule {rule_name}: {str(e)}")
    
    def _evaluate_condition(self, value: float, condition: str, threshold: float) -> bool:
        """ì¡°ê±´ í‰ê°€"""
        
        if condition == ">=":
            return value >= threshold
        elif condition == ">":
            return value > threshold
        elif condition == "<=":
            return value <= threshold
        elif condition == "<":
            return value < threshold
        elif condition == "==":
            return abs(value - threshold) < 0.001  # ë¶€ë™ì†Œìˆ˜ì  ë¹„êµ
        elif condition == "!=":
            return abs(value - threshold) >= 0.001
        
        return False
    
    async def _fire_alert(self, rule: AlertRule, metric):
        """ì•Œë¦¼ ë°œìƒ"""
        
        alert_id = f"{rule.name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # ì•Œë¦¼ ìƒì„±
        alert = Alert(
            id=alert_id,
            rule_name=rule.name,
            status=AlertStatus.FIRING,
            severity=rule.severity,
            message=f"{rule.description}: {metric.value} {rule.condition} {rule.threshold}",
            labels=rule.labels or {},
            annotations=rule.annotations or {},
            start_time=datetime.now(),
            fingerprint=self._generate_fingerprint(rule, metric)
        )
        
        # í™œì„± ì•Œë¦¼ì— ì¶”ê°€
        self.active_alerts[alert_id] = alert
        
        # ì•Œë¦¼ ì „ì†¡
        await self._send_notifications(alert)
        
        self.logger.warning(f"Alert fired: {alert_id} - {alert.message}")
    
    async def _resolve_alert(self, rule_name: str):
        """ì•Œë¦¼ í•´ê²°"""
        
        # í•´ë‹¹ ê·œì¹™ì˜ í™œì„± ì•Œë¦¼ ì°¾ê¸°
        resolved_alerts = [
            alert for alert in self.active_alerts.values()
            if alert.rule_name == rule_name and alert.status == AlertStatus.FIRING
        ]
        
        for alert in resolved_alerts:
            # ì•Œë¦¼ ìƒíƒœ ì—…ë°ì´íŠ¸
            alert.status = AlertStatus.RESOLVED
            alert.end_time = datetime.now()
            
            # í•´ê²° ì•Œë¦¼ ì „ì†¡
            await self._send_notifications(alert)
            
            self.logger.info(f"Alert resolved: {alert.id}")
    
    async def _send_notifications(self, alert: Alert):
        """ì•Œë¦¼ ì „ì†¡"""
        
        for channel_name, channel in self.notification_channels.items():
            if not channel.enabled:
                continue
            
            handler = self.notification_handlers.get(channel.type)
            
            if handler:
                try:
                    await handler.send_notification(alert, channel.config)
                except Exception as e:
                    self.logger.error(f"Error sending notification via {channel_name}: {str(e)}")
    
    def _generate_fingerprint(self, rule: AlertRule, metric) -> str:
        """ì•Œë¦¼ ì§€ë¬¸ ìƒì„±"""
        
        # ê·œì¹™ ì´ë¦„ê³¼ ë ˆì´ë¸”ë¡œ ì§€ë¬¸ ìƒì„±
        fingerprint_data = {
            'rule_name': rule.name,
            'labels': rule.labels or {}
        }
        
        fingerprint_str = json.dumps(fingerprint_data, sort_keys=True)
        
        import hashlib
        return hashlib.md5(fingerprint_str.encode()).hexdigest()
    
    def get_active_alerts(self) -> List[Alert]:
        """í™œì„± ì•Œë¦¼ ì¡°íšŒ"""
        
        return [
            alert for alert in self.active_alerts.values()
            if alert.status == AlertStatus.FIRING
        ]
    
    def get_alert_history(self, hours: int = 24) -> List[Alert]:
        """ì•Œë¦¼ ì´ë ¥ ì¡°íšŒ"""
        
        cutoff_time = datetime.now() - timedelta(hours=hours)
        
        return [
            alert for alert in self.active_alerts.values()
            if alert.start_time >= cutoff_time
        ]
    
    def add_alert_rule(self, rule: AlertRule):
        """ì•Œë¦¼ ê·œì¹™ ì¶”ê°€"""
        
        self.alert_rules[rule.name] = rule
        self.logger.info(f"Added alert rule: {rule.name}")
    
    def update_alert_rule(self, rule_name: str, **kwargs):
        """ì•Œë¦¼ ê·œì¹™ ì—…ë°ì´íŠ¸"""
        
        if rule_name not in self.alert_rules:
            raise ValueError(f"Alert rule not found: {rule_name}")
        
        rule = self.alert_rules[rule_name]
        
        for key, value in kwargs.items():
            if hasattr(rule, key):
                setattr(rule, key, value)
        
        self.logger.info(f"Updated alert rule: {rule_name}")
    
    def delete_alert_rule(self, rule_name: str):
        """ì•Œë¦¼ ê·œì¹™ ì‚­ì œ"""
        
        if rule_name in self.alert_rules:
            del self.alert_rules[rule_name]
            
            # ê´€ë ¨ ìƒíƒœ ì •ë¦¬
            if rule_name in self.alert_states:
                del self.alert_states[rule_name]
            
            self.logger.info(f"Deleted alert rule: {rule_name}")
    
    def add_notification_channel(self, channel: NotificationChannel):
        """ì•Œë¦¼ ì±„ë„ ì¶”ê°€"""
        
        self.notification_channels[channel.name] = channel
        self.logger.info(f"Added notification channel: {channel.name}")
    
    def delete_notification_channel(self, channel_name: str):
        """ì•Œë¦¼ ì±„ë„ ì‚­ì œ"""
        
        if channel_name in self.notification_channels:
            del self.notification_channels[channel_name]
            self.logger.info(f"Deleted notification channel: {channel_name}")

class EmailNotificationHandler:
    """ì´ë©”ì¼ ì•Œë¦¼ í•¸ë“¤ëŸ¬"""
    
    async def send_notification(self, alert: Alert, config: Dict[str, Any]):
        """ì´ë©”ì¼ ì•Œë¦¼ ì „ì†¡"""
        
        try:
            # ì´ë©”ì¼ ë‚´ìš© ìƒì„±
            subject = f"[{alert.severity.value.upper()}] {alert.rule_name}"
            
            if alert.status == AlertStatus.FIRING:
                body = f"""
Alert: {alert.message}
Severity: {alert.severity.value}
Time: {alert.start_time}
Labels: {alert.labels}
Annotations: {alert.annotations}
"""
            else:
                body = f"""
Alert Resolved: {alert.rule_name}
Time: {alert.start_time} - {alert.end_time}
Duration: {alert.end_time - alert.start_time}
"""
            
            # ì´ë©”ì¼ ì „ì†¡
            msg = MIMEMultipart()
            msg['From'] = config['from_address']
            msg['To'] = ', '.join(config['to_addresses'])
            msg['Subject'] = subject
            
            msg.attach(MIMEText(body, 'plain'))
            
            # SMTP ì„œë²„ ì—°ê²° ë° ì „ì†¡
            server = smtplib.SMTP(config['smtp_server'], config['smtp_port'])
            server.starttls()
            server.login(config['username'], config['password'])
            
            text = msg.as_string()
            server.sendmail(config['from_address'], config['to_addresses'], text)
            server.quit()
            
        except Exception as e:
            logging.getLogger(__name__).error(f"Error sending email notification: {str(e)}")

class SlackNotificationHandler:
    """Slack ì•Œë¦¼ í•¸ë“¤ëŸ¬"""
    
    async def send_notification(self, alert: Alert, config: Dict[str, Any]):
        """Slack ì•Œë¦¼ ì „ì†¡"""
        
        try:
            # Slack ë©”ì‹œì§€ ìƒì„±
            color = {
                AlertSeverity.INFO: "good",
                AlertSeverity.WARNING: "warning",
                AlertSeverity.ERROR: "danger",
                AlertSeverity.CRITICAL: "danger"
            }.get(alert.severity, "warning")
            
            if alert.status == AlertStatus.FIRING:
                text = f"ğŸš¨ Alert: {alert.message}"
            else:
                text = f"âœ… Resolved: {alert.rule_name}"
            
            payload = {
                "channel": config.get('channel', '#alerts'),
                "username": config.get('username', 'AlertBot'),
                "attachments": [
                    {
                        "color": color,
                        "title": alert.rule_name,
                        "text": text,
                        "fields": [
                            {
                                "title": "Severity",
                                "value": alert.severity.value,
                                "short": True
                            },
                            {
                                "title": "Time",
                                "value": alert.start_time.strftime('%Y-%m-%d %H:%M:%S'),
                                "short": True
                            }
                        ],
                        "footer": "InsiteChart Alerts",
                        "ts": int(alert.start_time.timestamp())
                    }
                ]
            }
            
            # ì›¹í›… ì „ì†¡
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    config['webhook_url'],
                    json=payload,
                    headers={'Content-Type': 'application/json'}
                ) as response:
                    if response.status != 200:
                        raise Exception(f"Slack webhook failed: {response.status}")
        
        except Exception as e:
            logging.getLogger(__name__).error(f"Error sending Slack notification: {str(e)}")

class WebhookNotificationHandler:
    """ì›¹í›… ì•Œë¦¼ í•¸ë“¤ëŸ¬"""
    
    async def send_notification(self, alert: Alert, config: Dict[str, Any]):
        """ì›¹í›… ì•Œë¦¼ ì „ì†¡"""
        
        try:
            # í˜ì´ë¡œë“œ ìƒì„±
            payload = {
                "alert_id": alert.id,
                "rule_name": alert.rule_name,
                "status": alert.status.value,
                "severity": alert.severity.value,
                "message": alert.message,
                "labels": alert.labels,
                "annotations": alert.annotations,
                "start_time": alert.start_time.isoformat(),
                "end_time": alert.end_time.isoformat() if alert.end_time else None
            }
            
            # ì›¹í›… ì „ì†¡
            headers = config.get('headers', {})
            headers['Content-Type'] = 'application/json'
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    config['url'],
                    json=payload,
                    headers=headers
                ) as response:
                    if response.status not in [200, 201, 202]:
                        raise Exception(f"Webhook failed: {response.status}")
        
        except Exception as e:
            logging.getLogger(__name__).error(f"Error sending webhook notification: {str(e)}")

class SMSNotificationHandler:
    """SMS ì•Œë¦¼ í•¸ë“¤ëŸ¬"""
    
    async def send_notification(self, alert: Alert, config: Dict[str, Any]):
        """SMS ì•Œë¦¼ ì „ì†¡"""
        
        try:
            # SMS ë©”ì‹œì§€ ìƒì„±
            if alert.status == AlertStatus.FIRING:
                message = f"[{alert.severity.value.upper()}] {alert.rule_name}: {alert.message}"
            else:
                message = f"[RESOLVED] {alert.rule_name}"
            
            # SMS API í˜¸ì¶œ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Twilio ë“± ì‚¬ìš©)
            # ì—¬ê¸°ì„œëŠ” ë¡œê·¸ë§Œ ì¶œë ¥
            logging.getLogger(__name__).info(f"SMS would be sent: {message}")
        
        except Exception as e:
            logging.getLogger(__name__).error(f"Error sending SMS notification: {str(e)}")
```

## 3. ëŒ€ì‹œë³´ë“œ ì‹œìŠ¤í…œ

### 3.1 ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

```python
# monitoring/dashboard.py
import asyncio
import json
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
import logging
from .monitoring_manager import MonitoringManager
from .alerting_system import AlertManager

@dataclass
class DashboardWidget:
    """ëŒ€ì‹œë³´ë“œ ìœ„ì ¯"""
    id: str
    type: str  # metric_chart, alert_list, system_status, etc.
    title: str
    config: Dict[str, Any]
    position: Dict[str, int]  # x, y, width, height
    refresh_interval: int  # ì´ˆ

@dataclass
class Dashboard:
    """ëŒ€ì‹œë³´ë“œ"""
    id: str
    name: str
    description: str
    widgets: List[DashboardWidget]
    layout: Dict[str, Any]
    created_at: datetime
    updated_at: datetime

class MonitoringDashboard:
    """ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ"""
    
    def __init__(self, monitoring_manager: MonitoringManager, alert_manager: AlertManager):
        self.monitoring_manager = monitoring_manager
        self.alert_manager = alert_manager
        self.logger = logging.getLogger(__name__)
        
        # ëŒ€ì‹œë³´ë“œ ì €ì¥ì†Œ
        self.dashboards: Dict[str, Dashboard] = {}
        
        # ê¸°ë³¸ ëŒ€ì‹œë³´ë“œ ì´ˆê¸°í™”
        self._initialize_default_dashboards()
    
    def _initialize_default_dashboards(self):
        """ê¸°ë³¸ ëŒ€ì‹œë³´ë“œ ì´ˆê¸°í™”"""
        
        # ì‹œìŠ¤í…œ ê°œìš” ëŒ€ì‹œë³´ë“œ
        system_overview_widgets = [
            DashboardWidget(
                id="cpu_usage",
                type="metric_chart",
                title="CPU Usage",
                config={
                    "metric_name": "system_cpu_usage",
                    "chart_type": "line",
                    "time_range": "1h",
                    "aggregation": "avg",
                    "threshold": 80
                },
                position={"x": 0, "y": 0, "width": 6, "height": 4},
                refresh_interval=30
            ),
            DashboardWidget(
                id="memory_usage",
                type="metric_chart",
                title="Memory Usage",
                config={
                    "metric_name": "system_memory_usage",
                    "chart_type": "line",
                    "time_range": "1h",
                    "aggregation": "avg",
                    "threshold": 85
                },
                position={"x": 6, "y": 0, "width": 6, "height": 4},
                refresh_interval=30
            ),
            DashboardWidget(
                id="disk_usage",
                type="metric_chart",
                title="Disk Usage",
                config={
                    "metric_name": "system_disk_usage",
                    "chart_type": "bar",
                    "time_range": "1h",
                    "aggregation": "avg",
                    "threshold": 90
                },
                position={"x": 0, "y": 4, "width": 6, "height": 4},
                refresh_interval=60
            ),
            DashboardWidget(
                id="active_alerts",
                type="alert_list",
                title="Active Alerts",
                config={
                    "severity_filter": ["error", "critical"],
                    "max_items": 10
                },
                position={"x": 6, "y": 4, "width": 6, "height": 4},
                refresh_interval=30
            )
        ]
        
        system_overview = Dashboard(
            id="system_overview",
            name="System Overview",
            description="Overall system status and metrics",
            widgets=system_overview_widgets,
            layout={"columns": 12},
            created_at=datetime.now(),
            updated_at=datetime.now()
        )
        
        # ì• í”Œë¦¬ì¼€ì´ì…˜ ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ
        app_performance_widgets = [
            DashboardWidget(
                id="http_requests",
                type="metric_chart",
                title="HTTP Requests",
                config={
                    "metric_name": "http_requests_total",
                    "chart_type": "line",
                    "time_range": "1h",
                    "aggregation": "rate"
                },
                position={"x": 0, "y": 0, "width": 6, "height": 4},
                refresh_interval=30
            ),
            DashboardWidget(
                id="response_time",
                type="metric_chart",
                title="Response Time",
                config={
                    "metric_name": "http_request_duration",
                    "chart_type": "line",
                    "time_range": "1h",
                    "aggregation": "p95",
                    "threshold": 1000  # 1ì´ˆ
                },
                position={"x": 6, "y": 0, "width": 6, "height": 4},
                refresh_interval=30
            ),
            DashboardWidget(
                id="active_users",
                type="metric_chart",
                title="Active Users",
                config={
                    "metric_name": "users_active",
                    "chart_type": "line",
                    "time_range": "24h",
                    "aggregation": "avg"
                },
                position={"x": 0, "y": 4, "width": 6, "height": 4},
                refresh_interval=60
            ),
            DashboardWidget(
                id="error_rate",
                type="metric_chart",
                title="Error Rate",
                config={
                    "metric_name": "http_requests_total",
                    "chart_type": "line",
                    "time_range": "1h",
                    "aggregation": "error_rate",
                    "threshold": 5  # 5%
                },
                position={"x": 6, "y": 4, "width": 6, "height": 4},
                refresh_interval=30
            )
        ]
        
        app_performance = Dashboard(
            id="app_performance",
            name="Application Performance",
            description="Application performance metrics",
            widgets=app_performance_widgets,
            layout={"columns": 12},
            created_at=datetime.now(),
            updated_at=datetime.now()
        )
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­ ëŒ€ì‹œë³´ë“œ
        business_metrics_widgets = [
            DashboardWidget(
                id="stock_searches",
                type="metric_chart",
                title="Stock Searches",
                config={
                    "metric_name": "stock_searches_total",
                    "chart_type": "line",
                    "time_range": "24h",
                    "aggregation": "rate"
                },
                position={"x": 0, "y": 0, "width": 6, "height": 4},
                refresh_interval=60
            ),
            DashboardWidget(
                id="sentiment_analyses",
                type="metric_chart",
                title="Sentiment Analyses",
                config={
                    "metric_name": "sentiment_analyses_total",
                    "chart_type": "line",
                    "time_range": "24h",
                    "aggregation": "rate"
                },
                position={"x": 6, "y": 0, "width": 6, "height": 4},
                refresh_interval=60
            ),
            DashboardWidget(
                id="top_symbols",
                type="top_n_table",
                title="Top Searched Symbols",
                config={
                    "metric_name": "stock_searches_total",
                    "time_range": "24h",
                    "limit": 10,
                    "group_by": "symbol"
                },
                position={"x": 0, "y": 4, "width": 12, "height": 4},
                refresh_interval=300  # 5ë¶„
            )
        ]
        
        business_metrics = Dashboard(
            id="business_metrics",
            name="Business Metrics",
            description="Business and user engagement metrics",
            widgets=business_metrics_widgets,
            layout={"columns": 12},
            created_at=datetime.now(),
            updated_at=datetime.now()
        )
        
        self.dashboards = {
            "system_overview": system_overview,
            "app_performance": app_performance,
            "business_metrics": business_metrics
        }
    
    async def get_dashboard_data(self, dashboard_id: str) -> Dict[str, Any]:
        """ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì¡°íšŒ"""
        
        if dashboard_id not in self.dashboards:
            raise ValueError(f"Dashboard not found: {dashboard_id}")
        
        dashboard = self.dashboards[dashboard_id]
        widget_data = {}
        
        # ê° ìœ„ì ¯ ë°ì´í„° ì¡°íšŒ
        for widget in dashboard.widgets:
            try:
                if widget.type == "metric_chart":
                    data = await self._get_metric_chart_data(widget)
                elif widget.type == "alert_list":
                    data = await self._get_alert_list_data(widget)
                elif widget.type == "top_n_table":
                    data = await self._get_top_n_table_data(widget)
                else:
                    data = {"error": f"Unknown widget type: {widget.type}"}
                
                widget_data[widget.id] = data
                
            except Exception as e:
                self.logger.error(f"Error getting data for widget {widget.id}: {str(e)}")
                widget_data[widget.id] = {"error": str(e)}
        
        return {
            "dashboard": asdict(dashboard),
            "widget_data": widget_data,
            "timestamp": datetime.now().isoformat()
        }
    
    async def _get_metric_chart_data(self, widget: DashboardWidget) -> Dict[str, Any]:
        """ë©”íŠ¸ë¦­ ì°¨íŠ¸ ë°ì´í„° ì¡°íšŒ"""
        
        config = widget.config
        metric_name = config["metric_name"]
        time_range = config["time_range"]
        aggregation = config.get("aggregation", "avg")
        threshold = config.get("threshold")
        
        # ì‹œê°„ ë²”ìœ„ ê³„ì‚°
        end_time = datetime.now()
        
        if time_range == "1h":
            start_time = end_time - timedelta(hours=1)
        elif time_range == "6h":
            start_time = end_time - timedelta(hours=6)
        elif time_range == "24h":
            start_time = end_time - timedelta(days=1)
        elif time_range == "7d":
            start_time = end_time - timedelta(days=7)
        else:
            start_time = end_time - timedelta(hours=1)
        
        # ë©”íŠ¸ë¦­ ë°ì´í„° ì¡°íšŒ
        metrics = await self.monitoring_manager.get_metrics(
            metric_name, start_time, end_time
        )
        
        if not metrics:
            return {"data": [], "threshold": threshold}
        
        # ë°ì´í„° ì§‘ê³„
        if aggregation == "rate":
            # ì‹œê°„ë‹¹ ë¹„ìœ¨ ê³„ì‚°
            data_points = self._calculate_rate(metrics, time_range)
        elif aggregation == "p95":
            # 95ë²ˆì§¸ ë°±ë¶„ìœ„ìˆ˜ ê³„ì‚°
            data_points = self._calculate_percentile(metrics, 95)
        elif aggregation == "error_rate":
            # ì—ëŸ¬ìœ¨ ê³„ì‚°
            data_points = await self._calculate_error_rate(metrics, time_range)
        else:
            # í‰ê·  ê³„ì‚°
            data_points = self._calculate_average(metrics, time_range)
        
        return {
            "data": data_points,
            "threshold": threshold,
            "unit": self._get_metric_unit(metric_name)
        }
    
    async def _get_alert_list_data(self, widget: DashboardWidget) -> Dict[str, Any]:
        """ì•Œë¦¼ ëª©ë¡ ë°ì´í„° ì¡°íšŒ"""
        
        config = widget.config
        severity_filter = config.get("severity_filter", [])
        max_items = config.get("max_items", 10)
        
        # í™œì„± ì•Œë¦¼ ì¡°íšŒ
        active_alerts = self.alert_manager.get_active_alerts()
        
        # ì‹¬ê°ë„ í•„í„°ë§
        if severity_filter:
            active_alerts = [
                alert for alert in active_alerts
                if alert.severity.value in severity_filter
            ]
        
        # ìµœì‹  ì•Œë¦¼ ì •ë ¬ ë° ì œí•œ
        active_alerts.sort(key=lambda x: x.start_time, reverse=True)
        active_alerts = active_alerts[:max_items]
        
        return {
            "alerts": [
                {
                    "id": alert.id,
                    "rule_name": alert.rule_name,
                    "severity": alert.severity.value,
                    "message": alert.message,
                    "start_time": alert.start_time.isoformat(),
                    "labels": alert.labels,
                    "annotations": alert.annotations
                }
                for alert in active_alerts
            ]
        }
    
    async def _get_top_n_table_data(self, widget: DashboardWidget) -> Dict[str, Any]:
        """Top N í…Œì´ë¸” ë°ì´í„° ì¡°íšŒ"""
        
        config = widget.config
        metric_name = config["metric_name"]
        time_range = config["time_range"]
        limit = config.get("limit", 10)
        group_by = config.get("group_by")
        
        # ì‹œê°„ ë²”ìœ„ ê³„ì‚°
        end_time = datetime.now()
        
        if time_range == "1h":
            start_time = end_time - timedelta(hours=1)
        elif time_range == "24h":
            start_time = end_time - timedelta(days=1)
        else:
            start_time = end_time - timedelta(days=1)
        
        # ë©”íŠ¸ë¦­ ë°ì´í„° ì¡°íšŒ
        metrics = await self.monitoring_manager.get_metrics(
            metric_name, start_time, end_time
        )
        
        if not metrics:
            return {"data": []}
        
        # ê·¸ë£¹ë³„ ì§‘ê³„
        grouped_data = {}
        
        for metric in metrics:
            group_key = None
            
            if group_by == "symbol" and metric.labels:
                group_key = metric.labels.get("symbol", "unknown")
            else:
                group_key = "total"
            
            if group_key not in grouped_data:
                grouped_data[group_key] = []
            
            grouped_data[group_key].append(metric.value)
        
        # ê·¸ë£¹ë³„ í•©ê³„ ê³„ì‚° ë° ì •ë ¬
        top_data = []
        for group_key, values in grouped_data.items():
            total_value = sum(values)
            top_data.append({
                "group": group_key,
                "value": total_value
            })
        
        top_data.sort(key=lambda x: x["value"], reverse=True)
        top_data = top_data[:limit]
        
        return {"data": top_data}
    
    def _calculate_rate(self, metrics: List, time_range: str) -> List[Dict]:
        """ì‹œê°„ë‹¹ ë¹„ìœ¨ ê³„ì‚°"""
        
        if not metrics:
            return []
        
        # ì‹œê°„ ê°„ê²© ê²°ì •
        if time_range == "1h":
            interval = timedelta(minutes=5)
        elif time_range == "6h":
            interval = timedelta(minutes=30)
        elif time_range == "24h":
            interval = timedelta(hours=1)
        else:
            interval = timedelta(minutes=5)
        
        # ì‹œê°„ ê°„ê²©ë³„ ë°ì´í„° ì§‘ê³„
        data_points = []
        current_time = metrics[0].timestamp
        
        while current_time <= metrics[-1].timestamp:
            end_time = current_time + interval
            
            # ê°„ê²© ë‚´ ë©”íŠ¸ë¦­ í•„í„°ë§
            interval_metrics = [
                m for m in metrics
                if current_time <= m.timestamp < end_time
            ]
            
            if interval_metrics:
                # ì¹´ìš´í„° ë©”íŠ¸ë¦­ì¸ ê²½ìš° ì¦ê°€ëŸ‰ ê³„ì‚°
                if len(interval_metrics) >= 2:
                    rate = interval_metrics[-1].value - interval_metrics[0].value
                else:
                    rate = interval_metrics[0].value
                
                data_points.append({
                    "timestamp": current_time.isoformat(),
                    "value": rate
                })
            
            current_time = end_time
        
        return data_points
    
    def _calculate_percentile(self, metrics: List, percentile: int) -> List[Dict]:
        """ë°±ë¶„ìœ„ìˆ˜ ê³„ì‚°"""
        
        if not metrics:
            return []
        
        # ì‹œê°„ ê°„ê²©ë³„ ë°ì´í„° ê·¸ë£¹í™”
        data_points = []
        interval = timedelta(minutes=5)
        current_time = metrics[0].timestamp
        
        while current_time <= metrics[-1].timestamp:
            end_time = current_time + interval
            
            # ê°„ê²© ë‚´ ë©”íŠ¸ë¦­ í•„í„°ë§
            interval_metrics = [
                m for m in metrics
                if current_time <= m.timestamp < end_time
            ]
            
            if interval_metrics:
                values = [m.value for m in interval_metrics]
                values.sort()
                
                # ë°±ë¶„ìœ„ìˆ˜ ê³„ì‚°
                index = int(len(values) * percentile / 100)
                if index >= len(values):
                    index = len(values) - 1
                
                data_points.append({
                    "timestamp": current_time.isoformat(),
                    "value": values[index]
                })
            
            current_time = end_time
        
        return data_points
    
    async def _calculate_error_rate(self, metrics: List, time_range: str) -> List[Dict]:
        """ì—ëŸ¬ìœ¨ ê³„ì‚°"""
        
        if not metrics:
            return []
        
        # ì‹œê°„ ê°„ê²©ë³„ ë°ì´í„° ê·¸ë£¹í™”
        data_points = []
        interval = timedelta(minutes=5)
        current_time = metrics[0].timestamp
        
        while current_time <= metrics[-1].timestamp:
            end_time = current_time + interval
            
            # ê°„ê²© ë‚´ ë©”íŠ¸ë¦­ í•„í„°ë§
            interval_metrics = [
                m for m in metrics
                if current_time <= m.timestamp < end_time
            ]
            
            if interval_metrics:
                # ìƒíƒœ ì½”ë“œë³„ ê·¸ë£¹í™”
                status_counts = {}
                total_requests = 0
                
                for metric in interval_metrics:
                    status_code = metric.labels.get("status_code", "unknown")
                    status_counts[status_code] = status_counts.get(status_code, 0) + metric.value
                    total_requests += metric.value
                
                # ì—ëŸ¬ìœ¨ ê³„ì‚° (5xx ìƒíƒœ ì½”ë“œ)
                error_count = sum(
                    count for status, count in status_counts.items()
                    if status.startswith("5")
                )
                
                error_rate = (error_count / total_requests * 100) if total_requests > 0 else 0
                
                data_points.append({
                    "timestamp": current_time.isoformat(),
                    "value": error_rate
                })
            
            current_time = end_time
        
        return data_points
    
    def _calculate_average(self, metrics: List, time_range: str) -> List[Dict]:
        """í‰ê·  ê³„ì‚°"""
        
        if not metrics:
            return []
        
        # ì‹œê°„ ê°„ê²©ë³„ ë°ì´í„° ê·¸ë£¹í™”
        data_points = []
        interval = timedelta(minutes=5)
        current_time = metrics[0].timestamp
        
        while current_time <= metrics[-1].timestamp:
            end_time = current_time + interval
            
            # ê°„ê²© ë‚´ ë©”íŠ¸ë¦­ í•„í„°ë§
            interval_metrics = [
                m for m in metrics
                if current_time <= m.timestamp < end_time
            ]
            
            if interval_metrics:
                values = [m.value for m in interval_metrics]
                average = sum(values) / len(values)
                
                data_points.append({
                    "timestamp": current_time.isoformat(),
                    "value": average
                })
            
            current_time = end_time
        
        return data_points
    
    def _get_metric_unit(self, metric_name: str) -> str:
        """ë©”íŠ¸ë¦­ ë‹¨ìœ„ ì¡°íšŒ"""
        
        if "cpu" in metric_name or "memory" in metric_name or "disk" in metric_name:
            return "%"
        elif "bytes" in metric_name:
            return "bytes"
        elif "duration" in metric_name or "response_time" in metric_name:
            return "ms"
        elif "requests" in metric_name:
            return "count"
        else:
            return ""
```

## 4. êµ¬í˜„ ê°€ì´ë“œ

### 4.1 ë‹¨ê³„ë³„ êµ¬í˜„ ê³„íš

#### 1ë‹¨ê³„: ê¸°ë³¸ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (2-3ì£¼)
- ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° êµ¬í˜„
- ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° êµ¬í˜„
- Redis ê¸°ë°˜ ë©”íŠ¸ë¦­ ì €ì¥ì†Œ êµ¬ì¶•
- ê¸°ë³¸ ëŒ€ì‹œë³´ë“œ ìœ„ì ¯ ê°œë°œ

#### 2ë‹¨ê³„: ì•Œë¦¼ ì‹œìŠ¤í…œ (2-3ì£¼)
- ì•Œë¦¼ ê·œì¹™ ì—”ì§„ êµ¬í˜„
- ë‹¤ì–‘í•œ ì•Œë¦¼ ì±„ë„ í•¸ë“¤ëŸ¬ ê°œë°œ
- ì•Œë¦¼ ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶•
- ì•Œë¦¼ í…œí”Œë¦¿ ë° í¬ë§·íŒ…

#### 3ë‹¨ê³„: ê³ ê¸‰ ëª¨ë‹ˆí„°ë§ (2-3ì£¼)
- ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° êµ¬í˜„
- ì™¸ë¶€ API ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥ ì¶”ê°€
- ë°ì´í„°ë² ì´ìŠ¤ ë° ìºì‹œ ëª¨ë‹ˆí„°ë§ ê°•í™”
- ë¶„ì‚° ì¶”ì  ì‹œìŠ¤í…œ í†µí•©

#### 4ë‹¨ê³„: ëŒ€ì‹œë³´ë“œ ê³ ë„í™” (2-3ì£¼)
- ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ ì—…ë°ì´íŠ¸
- ëŒ€í™”í˜• ì°¨íŠ¸ ë° í•„í„°ë§
- ì‚¬ìš©ìë³„ ëŒ€ì‹œë³´ë“œ ì„¤ì •
- ëª¨ë°”ì¼ ëŒ€ì‘ ëŒ€ì‹œë³´ë“œ

#### 5ë‹¨ê³„: ë¶„ì„ ë° ì˜ˆì¸¡ (3-4ì£¼)
- ë©”íŠ¸ë¦­ ê¸°ë°˜ ì´ìƒ ê°ì§€
- ì„±ëŠ¥ ì¶”ì„¸ ë¶„ì„
- ìš©ëŸ‰ ê³„íš ì§€ì›
- ìë™í™”ëœ ì„±ëŠ¥ ìµœì í™” ì œì•ˆ

### 4.2 ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­

1. **ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì„±ëŠ¥**
   - ë¹„ë™ê¸° ì²˜ë¦¬ë¡œ ì• í”Œë¦¬ì¼€ì´ì…˜ ì˜í–¥ ìµœì†Œí™”
   - ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë„¤íŠ¸ì›Œí¬ ì˜¤ë²„í—¤ë“œ ê°ì†Œ
   - ìƒ˜í”Œë§ìœ¼ë¡œ ê³ ë¹ˆë„ ë©”íŠ¸ë¦­ ì œì–´

2. **ì €ì¥ì†Œ ìµœì í™”**
   - ì ì ˆí•œ ë°ì´í„° ë³´ê´€ ê¸°ê°„ ì„¤ì •
   - ì‹œê³„ì—´ ë°ì´í„°ë² ì´ìŠ¤ ê³ ë ¤
   - ì••ì¶• ë° ì¸ë±ì‹± ì „ëµ

3. **ëŒ€ì‹œë³´ë“œ ì„±ëŠ¥**
   - í´ë¼ì´ì–¸íŠ¸ ì¸¡ ìºì‹±
   - ë°ì´í„° í”„ë¦¬í˜ì¹­
   - ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ìµœì í™”

### 4.3 ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

1. **ë©”íŠ¸ë¦­ ë°ì´í„° ë³´ì•ˆ**
   - ë¯¼ê° ì •ë³´ í¬í•¨ ì—¬ë¶€ ê²€í† 
   - ì ‘ê·¼ ì œì–´ ë° ì¸ì¦
   - ë°ì´í„° ì „ì†¡ ì•”í˜¸í™”

2. **ì•Œë¦¼ ë³´ì•ˆ**
   - ì•Œë¦¼ ì±„ë„ ë³´ì•ˆ ê°•í™”
   - ê°œì¸ì •ë³´ í¬í•¨ ì œì–´
   - ì•Œë¦¼ ìœ„ë³€ì¡° ë°©ì§€

3. **ëŒ€ì‹œë³´ë“œ ë³´ì•ˆ**
   - ì‚¬ìš©ìë³„ ì ‘ê·¼ ê¶Œí•œ
   - ë°ì´í„° í•„í„°ë§ ë° ë§ˆìŠ¤í‚¹
   - ê°ì‚¬ ë¡œê·¸ ê¸°ë¡

## 5. ê²°ë¡ 

ë³¸ ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼ ì‹œìŠ¤í…œ ì„¤ê³„ëŠ” InsiteChart í”Œë«í¼ì˜ ì•ˆì •ì ì¸ ìš´ì˜ê³¼ ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ í¬ê´„ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤. ë‹¤ê³„ì¸µ ëª¨ë‹ˆí„°ë§, ì§€ëŠ¥í˜• ì•Œë¦¼, ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œë¥¼ í†µí•´ ì‹œìŠ¤í…œ ìƒíƒœë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ íŒŒì•…í•˜ê³  ì ì¬ì  ë¬¸ì œë¥¼ ì‚¬ì „ì— ëŒ€ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë‹¨ê³„ì ì¸ êµ¬í˜„ì„ í†µí•´ ì‹œìŠ¤í…œ ì•ˆì •ì„±ì„ ì ì§„ì ìœ¼ë¡œ ê°•í™”í•˜ê³ , ì‹¤ì œ ìš´ì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§ ì •ì±…ì„ ìµœì í™”í•˜ì—¬ ì¥ê¸°ì ì¸ ì„±ê³µì„ ë³´ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.