# í†µí•© ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

## 1. ì•„í‚¤í…ì²˜ ê°œìš”

### 1.1 ì„¤ê³„ ì›ì¹™
ë³¸ ì‹œìŠ¤í…œì€ ë‹¤ìŒê³¼ ê°™ì€ í•µì‹¬ ì„¤ê³„ ì›ì¹™ì„ ë”°ë¦…ë‹ˆë‹¤:

- **ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜**: ë…ë¦½ì ìœ¼ë¡œ ë°°í¬ ê°€ëŠ¥í•œ ì„œë¹„ìŠ¤ ë‹¨ìœ„ë¡œ ì‹œìŠ¤í…œ ë¶„ë¦¬
- **í™•ì¥ì„±**: ìˆ˜í‰ì  í™•ì¥ì´ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜ ì„¤ê³„
- **ê³ ê°€ìš©ì„±**: ì¥ì•  ë°œìƒ ì‹œ ì„œë¹„ìŠ¤ ì—°ì†ì„± ë³´ì¥
- **ë³´ì•ˆ**: ëª¨ë“  ë ˆì´ì–´ì—ì„œ ë³´ì•ˆ ì •ì±… ì ìš©
- **ëª¨ë‹ˆí„°ë§**: ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ ìƒíƒœ ë° ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### 1.2 ì•„í‚¤í…ì²˜ ë¹„ì „
"ë°ì´í„° ê¸°ë°˜ì˜ ìŠ¤ë§ˆíŠ¸í•œ íˆ¬ì ê²°ì •ì„ ì§€ì›í•˜ëŠ” í™•ì¥ ê°€ëŠ¥í•œ ê¸ˆìœµ ë¶„ì„ í”Œë«í¼ êµ¬ì¶•"

## 2. ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 2.1 ê³ ìˆ˜ì¤€ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph "í”„ë¡ íŠ¸ì—”ë“œ ë ˆì´ì–´"
        A[Web Application<br/>Streamlit/React]
        B[Mobile Application<br/>React Native]
        C[Admin Dashboard<br/>React]
    end
    
    subgraph "API ê²Œì´íŠ¸ì›¨ì´ ë ˆì´ì–´"
        D[Kong API Gateway<br/>Load Balancer]
        E[Authentication Service<br/>JWT/OAuth]
        F[Rate Limiting Service]
    end
    
    subgraph "ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ë ˆì´ì–´"
        G[User Service<br/>ì‚¬ìš©ì ê´€ë¦¬]
        H[Stock Search Service<br/>ì£¼ì‹ ê²€ìƒ‰]
        I[Social Sentiment Service<br/>ì†Œì…œ ì„¼í‹°ë¨¼íŠ¸]
        J[Chart Analysis Service<br/>ì°¨íŠ¸ ë¶„ì„]
        K[Notification Service<br/>ì•Œë¦¼ ì„œë¹„ìŠ¤]
        L[Analytics Service<br/>ë°ì´í„° ë¶„ì„]
    end
    
    subgraph "ë°ì´í„° ë ˆì´ì–´"
        M[PostgreSQL<br/>ê´€ê³„í˜• ë°ì´í„°]
        N[TimescaleDB<br/>ì‹œê³„ì—´ ë°ì´í„°]
        O[Redis<br/>ìºì‹œ]
        P[Elasticsearch<br/>ê²€ìƒ‰/ë¡œê·¸]
        Q[S3<br/>íŒŒì¼ ì €ì¥ì†Œ]
    end
    
    subgraph "ë©”ì‹œì§• ë ˆì´ì–´"
        R[RabbitMQ<br/>ë©”ì‹œì§€ í]
    end
    
    subgraph "ì™¸ë¶€ API"
        S[Yahoo Finance API]
        T[Reddit API]
        U[Twitter API]
        V[Discord API]
    end
    
    A --> D
    B --> D
    C --> D
    D --> E
    D --> F
    E --> G
    E --> H
    E --> I
    E --> J
    E --> K
    E --> L
    G --> M
    H --> M
    H --> N
    H --> O
    I --> M
    I --> N
    I --> O
    J --> N
    K --> R
    L --> P
    H --> S
    I --> T
    I --> U
    I --> V
    R --> K
    R --> L
```

### 2.2 ì„œë¹„ìŠ¤ ìƒí˜¸ì‘ìš©

#### 2.2.1 ì‚¬ìš©ì íë¦„
```mermaid
sequenceDiagram
    participant U as User
    participant W as Web App
    participant G as API Gateway
    participant A as Auth Service
    participant S as Search Service
    participant SS as Sentiment Service
    participant DB as Database
    
    U->>W: ë¡œê·¸ì¸ ìš”ì²­
    W->>G: ì¸ì¦ ìš”ì²­
    G->>A: ì‚¬ìš©ì í™•ì¸
    A-->>G: JWT í† í°
    G-->>W: ì¸ì¦ ì„±ê³µ
    W-->>U: ë¡œê·¸ì¸ ì™„ë£Œ
    
    U->>W: ì£¼ì‹ ê²€ìƒ‰
    W->>G: ê²€ìƒ‰ API í˜¸ì¶œ
    G->>S: ê²€ìƒ‰ ìš”ì²­
    S->>DB: ë°ì´í„° ì¡°íšŒ
    DB-->>S: ê²€ìƒ‰ ê²°ê³¼
    S-->>G: ê²€ìƒ‰ ì‘ë‹µ
    G-->>W: ê²€ìƒ‰ ê²°ê³¼
    W-->>U: ê²°ê³¼ í‘œì‹œ
    
    U->>W: ì„¼í‹°ë¨¼íŠ¸ ì¡°íšŒ
    W->>G: ì„¼í‹°ë¨¼íŠ¸ API í˜¸ì¶œ
    G->>SS: ì„¼í‹°ë¨¼íŠ¸ ìš”ì²­
    SS->>DB: ì„¼í‹°ë¨¼íŠ¸ ë°ì´í„° ì¡°íšŒ
    DB-->>SS: ì„¼í‹°ë¨¼íŠ¸ ë°ì´í„°
    SS-->>G: ì„¼í‹°ë¨¼íŠ¸ ì‘ë‹µ
    G-->>W: ì„¼í‹°ë¨¼íŠ¸ ê²°ê³¼
    W-->>U: ì„¼í‹°ë¨¼íŠ¸ í‘œì‹œ
```

## 3. ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ìƒì„¸ ì„¤ê³„

### 3.1 API ê²Œì´íŠ¸ì›¨ì´

#### 3.1.1 Kong API Gateway ì„¤ì •
```yaml
# kong.yml
_format_version: "3.0"

services:
  - name: user-service
    url: http://user-service:8001
    plugins:
      - name: rate-limiting
        config:
          minute: 100
          hour: 1000
      - name: jwt
        config:
          secret_is_base64: false
    routes:
      - name: user-routes
        paths: ["/api/v1/users"]

  - name: stock-search-service
    url: http://stock-search-service:8002
    plugins:
      - name: rate-limiting
        config:
          minute: 200
          hour: 2000
      - name: jwt
        config:
          secret_is_base64: false
    routes:
      - name: search-routes
        paths: ["/api/v1/search"]

  - name: social-sentiment-service
    url: http://social-sentiment-service:8003
    plugins:
      - name: rate-limiting
        config:
          minute: 150
          hour: 1500
      - name: jwt
        config:
          secret_is_base64: false
    routes:
      - name: sentiment-routes
        paths: ["/api/v1/sentiment"]
```

#### 3.1.2 ë¡œë“œ ë°¸ëŸ°ì‹± ì „ëµ
- **ë¼ìš´ë“œ ë¡œë¹ˆ**: ìµœì†Œ ì—°ê²° ìˆ˜ ê¸°ë°˜
- **ìµœì†Œ ì—°ê²°**: ê° ì„œë¹„ìŠ¤ë‹¹ ìµœì†Œ 2ê°œ ì—°ê²°
- **í—¬ìŠ¤ ì²´í¬**: 30ì´ˆ ê°„ê²©ìœ¼ë¡œ ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
- **ì¥ì•  ê²©ë¦¬**: ë¹„ì •ìƒ ì„œë¹„ìŠ¤ ìë™ íŠ¸ë˜í”½ ì°¨ë‹¨

### 3.2 ì¸ì¦ ì„œë¹„ìŠ¤

#### 3.2.1 JWT ê¸°ë°˜ ì¸ì¦
```python
# auth_service/models.py
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Optional, List
import jwt

@dataclass
class User:
    id: int
    username: str
    email: str
    password_hash: str
    role: str
    is_active: bool = True
    created_at: datetime = None
    last_login: Optional[datetime] = None
    permissions: List[str] = None

class AuthService:
    def __init__(self, secret_key: str, token_expiry: int = 3600):
        self.secret_key = secret_key
        self.token_expiry = token_expiry
        self.refresh_token_expiry = 86400  # 24ì‹œê°„
    
    def generate_tokens(self, user: User) -> dict:
        """ì•¡ì„¸ìŠ¤ í† í°ê³¼ ë¦¬í”„ë ˆì‹œ í† í° ìƒì„±"""
        now = datetime.utcnow()
        
        access_payload = {
            'user_id': user.id,
            'username': user.username,
            'role': user.role,
            'permissions': self.get_user_permissions(user),
            'iat': now,
            'exp': now + timedelta(seconds=self.token_expiry),
            'type': 'access'
        }
        
        refresh_payload = {
            'user_id': user.id,
            'username': user.username,
            'iat': now,
            'exp': now + timedelta(seconds=self.refresh_token_expiry),
            'type': 'refresh'
        }
        
        access_token = jwt.encode(access_payload, self.secret_key, algorithm='HS256')
        refresh_token = jwt.encode(refresh_payload, self.secret_key, algorithm='HS256')
        
        return {
            'access_token': access_token,
            'refresh_token': refresh_token,
            'token_type': 'Bearer',
            'expires_in': self.token_expiry
        }
```

#### 3.2.2 OAuth 2.0 í†µí•©
```python
# auth_service/oauth.py
from authlib.integrations.starlette_client import OAuth
from fastapi import FastAPI

class OAuthManager:
    def __init__(self, app: FastAPI):
        self.oauth = OAuth(app)
        self.setup_providers()
    
    def setup_providers(self):
        # Google OAuth
        self.oauth.register(
            name='google',
            client_id=os.getenv('GOOGLE_CLIENT_ID'),
            client_secret=os.getenv('GOOGLE_CLIENT_SECRET'),
            server_metadata_url='https://accounts.google.com/.well-known/openid-configuration',
            client_kwargs={
                'scope': 'openid email profile'
            }
        )
        
        # GitHub OAuth
        self.oauth.register(
            name='github',
            client_id=os.getenv('GITHUB_CLIENT_ID'),
            client_secret=os.getenv('GITHUB_CLIENT_SECRET'),
            authorize_url='https://github.com/login/oauth/authorize',
            access_token_url='https://github.com/login/oauth/access_token',
            client_kwargs={
                'scope': 'user:email'
            }
        )
```

### 3.3 ì£¼ì‹ ê²€ìƒ‰ ì„œë¹„ìŠ¤

#### 3.3.1 ì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜
```python
# stock_search_service/service.py
class StockSearchService:
    def __init__(self, db_pool, redis_client, yahoo_client):
        self.db_pool = db_pool
        self.redis = redis_client
        self.yahoo_client = yahoo_client
        self.cache_ttl = 300  # 5ë¶„
    
    async def search_stocks(self, query: str, filters: dict = None) -> List[StockResult]:
        """ì£¼ì‹ ê²€ìƒ‰ ë©”ì¸ ë¡œì§"""
        # 1. ìºì‹œ í™•ì¸
        cache_key = f"search:{hash(query)}:{hash(str(filters))}"
        cached_result = await self.redis.get(cache_key)
        if cached_result:
            return json.loads(cached_result)
        
        # 2. Yahoo Finance API í˜¸ì¶œ
        search_results = await self.yahoo_client.search_stocks(query)
        
        # 3. í•„í„°ë§ ì ìš©
        if filters:
            search_results = self.apply_filters(search_results, filters)
        
        # 4. ê´€ë ¨ë„ ì ìˆ˜ ê³„ì‚°
        search_results = self.calculate_relevance_scores(search_results, query)
        
        # 5. ê²°ê³¼ ìºì‹±
        await self.redis.setex(cache_key, self.cache_ttl, json.dumps(search_results))
        
        return search_results
    
    async def get_autocomplete_suggestions(self, query: str, limit: int = 10) -> List[str]:
        """ìë™ì™„ì„± ì œì•ˆ ìƒì„±"""
        # ì‹¤ì‹œê°„ ìë™ì™„ì„± ë¡œì§ êµ¬í˜„
        pass
```

#### 3.3.2 ë°ì´í„° ëª¨ë¸
```python
# stock_search_service/models.py
from dataclasses import dataclass
from typing import Optional, List
from datetime import datetime

@dataclass
class StockResult:
    symbol: str
    company_name: str
    stock_type: str
    exchange: str
    sector: Optional[str] = None
    industry: Optional[str] = None
    market_cap: Optional[float] = None
    current_price: Optional[float] = None
    relevance_score: float = 0.0
    sentiment_score: Optional[float] = None
    mention_count_24h: int = 0
    trending_status: bool = False

@dataclass
class SearchHistory:
    id: int
    user_id: int
    symbol: str
    search_query: str
    search_time: datetime
    search_count: int = 1
```

### 3.4 ì†Œì…œ ì„¼í‹°ë¨¼íŠ¸ ì„œë¹„ìŠ¤

#### 3.4.1 ë°ì´í„° ìˆ˜ì§‘ ì•„í‚¤í…ì²˜
```python
# social_sentiment_service/collector.py
class SocialDataCollector:
    def __init__(self, reddit_client, twitter_client, db_pool, message_queue):
        self.reddit_client = reddit_client
        self.twitter_client = twitter_client
        self.db_pool = db_pool
        self.message_queue = message_queue
    
    async def collect_mentions(self, timeframe: str = "24h") -> List[StockMention]:
        """ì†Œì…œ ë¯¸ë””ì–´ ì–¸ê¸‰ ë°ì´í„° ìˆ˜ì§‘"""
        mentions = []
        
        # Reddit ë°ì´í„° ìˆ˜ì§‘
        reddit_mentions = await self.reddit_client.collect_mentions(timeframe)
        mentions.extend(reddit_mentions)
        
        # Twitter ë°ì´í„° ìˆ˜ì§‘
        twitter_mentions = await self.twitter_client.collect_mentions(timeframe)
        mentions.extend(twitter_mentions)
        
        # ë°ì´í„° ì •ì œ ë° ì €ì¥
        processed_mentions = self.process_mentions(mentions)
        await self.save_mentions(processed_mentions)
        
        # ë©”ì‹œì§€ íì— ì „ì†¡ (ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„ìš©)
        for mention in processed_mentions:
            await self.message_queue.publish('sentiment_analysis', {
                'symbol': mention.symbol,
                'text': mention.text,
                'source': mention.source
            })
        
        return processed_mentions
```

#### 3.4.2 ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„
```python
# social_sentiment_service/analyzer.py
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import re

class SentimentAnalyzer:
    def __init__(self):
        self.analyzer = SentimentIntensityAnalyzer()
        self.stock_lexicon = self.load_stock_lexicon()
    
    def analyze_sentiment(self, text: str) -> SentimentResult:
        """í…ìŠ¤íŠ¸ ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„"""
        # ê¸°ë³¸ VADER ë¶„ì„
        vader_scores = self.analyzer.polarity_scores(text)
        
        # ì£¼ì‹ íŠ¹í™” ìš©ì–´ ê°€ì¤‘ì¹˜ ì ìš©
        stock_scores = self.analyze_stock_specific_terms(text)
        
        # ì¢…í•© ì ìˆ˜ ê³„ì‚°
        final_score = self.calculate_weighted_sentiment(vader_scores, stock_scores)
        
        return SentimentResult(
            compound_score=final_score,
            positive_score=vader_scores['pos'],
            negative_score=vader_scores['neg'],
            neutral_score=vader_scores['neu'],
            confidence=self.calculate_confidence(final_score, text)
        )
    
    def analyze_stock_specific_terms(self, text: str) -> dict:
        """ì£¼ì‹ ì»¤ë®¤ë‹ˆí‹° íŠ¹í™” ìš©ì–´ ë¶„ì„"""
        scores = {'bullish': 0, 'bearish': 0, 'neutral': 0}
        
        # ê¸ì •ì  ìš©ì–´
        bullish_terms = ['moon', 'rocket', 'diamond hands', 'bullish', 'buy', 'hold']
        # ë¶€ì •ì  ìš©ì–´
        bearish_terms = ['crash', 'paper hands', 'bearish', 'sell', 'dump']
        
        text_lower = text.lower()
        
        for term in bullish_terms:
            if term in text_lower:
                scores['bullish'] += 1
        
        for term in bearish_terms:
            if term in text_lower:
                scores['bearish'] += 1
        
        return scores
```

## 4. ë°ì´í„° ì•„í‚¤í…ì²˜

### 4.1 ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„

#### 4.1.1 PostgreSQL ìŠ¤í‚¤ë§ˆ
```sql
-- ì‚¬ìš©ì í…Œì´ë¸”
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    role VARCHAR(20) NOT NULL DEFAULT 'basic',
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_login TIMESTAMP
);

-- ì£¼ì‹ ê¸°ë³¸ ì •ë³´ í…Œì´ë¸”
CREATE TABLE stocks (
    symbol VARCHAR(10) PRIMARY KEY,
    company_name VARCHAR(255) NOT NULL,
    stock_type VARCHAR(20) NOT NULL,
    exchange VARCHAR(20) NOT NULL,
    sector VARCHAR(100),
    industry VARCHAR(100),
    market_cap BIGINT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ê²€ìƒ‰ ê¸°ë¡ í…Œì´ë¸”
CREATE TABLE search_history (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id),
    symbol VARCHAR(10) REFERENCES stocks(symbol),
    search_query VARCHAR(255),
    search_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    search_count INTEGER DEFAULT 1
);

-- ê´€ì‹¬ì¢…ëª© í…Œì´ë¸”
CREATE TABLE watchlists (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id),
    symbol VARCHAR(10) REFERENCES stocks(symbol),
    category VARCHAR(50),
    note TEXT,
    added_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    order_index INTEGER,
    UNIQUE(user_id, symbol)
);

-- ì†Œì…œ ì–¸ê¸‰ í…Œì´ë¸”
CREATE TABLE stock_mentions (
    id SERIAL PRIMARY KEY,
    symbol VARCHAR(10) REFERENCES stocks(symbol),
    text TEXT NOT NULL,
    source VARCHAR(20) NOT NULL,
    community VARCHAR(100),
    author VARCHAR(100),
    timestamp TIMESTAMP NOT NULL,
    upvotes INTEGER DEFAULT 0,
    sentiment_score FLOAT,
    investment_style VARCHAR(20),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ì¸ë±ìŠ¤ ìƒì„±
CREATE INDEX idx_search_history_user_time ON search_history(user_id, search_time DESC);
CREATE INDEX idx_stock_mentions_symbol_time ON stock_mentions(symbol, timestamp DESC);
CREATE INDEX idx_watchlists_user_category ON watchlists(user_id, category);
```

#### 4.1.2 TimescaleDB ì‹œê³„ì—´ ë°ì´í„°
```sql
-- ì£¼ì‹ ê°€ê²© ì‹œê³„ì—´ ë°ì´í„°
CREATE TABLE stock_prices (
    time TIMESTAMP NOT NULL,
    symbol VARCHAR(10) NOT NULL,
    open_price FLOAT,
    high_price FLOAT,
    low_price FLOAT,
    close_price FLOAT,
    volume BIGINT,
    adj_close_price FLOAT
);

-- í•˜ì´í¼í…Œì´ë¸” ìƒì„± (ì‹œê°„ë‹¹ ë°ì´í„°)
SELECT create_hypertable('stock_prices', 'time', chunk_time_interval => INTERVAL '1 hour');

-- ì„¼í‹°ë¨¼íŠ¸ ì‹œê³„ì—´ ë°ì´í„°
CREATE TABLE sentiment_timeseries (
    time TIMESTAMP NOT NULL,
    symbol VARCHAR(10) NOT NULL,
    sentiment_score FLOAT,
    mention_count INTEGER,
    positive_count INTEGER,
    negative_count INTEGER,
    neutral_count INTEGER
);

-- í•˜ì´í¼í…Œì´ë¸” ìƒì„± (ì¼ë³„ ë°ì´í„°)
SELECT create_hypertable('sentiment_timeseries', 'time', chunk_time_interval => INTERVAL '1 day');
```

### 4.2 ìºì‹± ì „ëµ

#### 4.2.1 Redis ìºì‹œ êµ¬ì¡°
```python
# cache/cache_manager.py
class CacheManager:
    def __init__(self, redis_client):
        self.redis = redis_client
        
        # ìºì‹œ í‚¤ ì •ì˜
        self.keys = {
            'stock_search': 'search:{query_hash}',
            'stock_info': 'stock:{symbol}',
            'sentiment_data': 'sentiment:{symbol}:{timeframe}',
            'user_session': 'session:{user_id}',
            'trending_stocks': 'trending:{timeframe}',
            'autocomplete': 'autocomplete:{query}'
        }
        
        # ìºì‹œ TTL ì„¤ì •
        self.ttl = {
            'stock_search': 300,      # 5ë¶„
            'stock_info': 3600,      # 1ì‹œê°„
            'sentiment_data': 300,   # 5ë¶„
            'user_session': 86400,   # 24ì‹œê°„
            'trending_stocks': 600,  # 10ë¶„
            'autocomplete': 1800     # 30ë¶„
        }
    
    async def get_stock_search_results(self, query_hash: str) -> Optional[List[dict]]:
        """ì£¼ì‹ ê²€ìƒ‰ ê²°ê³¼ ìºì‹œ ì¡°íšŒ"""
        key = self.keys['stock_search'].format(query_hash=query_hash)
        cached_data = await self.redis.get(key)
        return json.loads(cached_data) if cached_data else None
    
    async def set_stock_search_results(self, query_hash: str, results: List[dict]):
        """ì£¼ì‹ ê²€ìƒ‰ ê²°ê³¼ ìºì‹œ ì €ì¥"""
        key = self.keys['stock_search'].format(query_hash=query_hash)
        await self.redis.setex(
            key, 
            self.ttl['stock_search'], 
            json.dumps(results, default=str)
        )
```

## 5. ë©”ì‹œì§• ì•„í‚¤í…ì²˜

### 5.1 RabbitMQ ë©”ì‹œì§€ í

#### 5.1.1 í ì„¤ê³„
```python
# messaging/queue_manager.py
import aio_pika
from typing import Dict, Any

class QueueManager:
    def __init__(self, rabbitmq_url: str):
        self.rabbitmq_url = rabbitmq_url
        self.connection = None
        self.channel = None
        
        # í ì •ì˜
        self.queues = {
            'sentiment_analysis': {
                'name': 'sentiment.analysis',
                'routing_key': 'sentiment.analysis',
                'durable': True,
                'arguments': {
                    'x-message-ttl': 3600000,  # 1ì‹œê°„
                    'x-max-length': 10000
                }
            },
            'trending_detection': {
                'name': 'trending.detection',
                'routing_key': 'trending.detection',
                'durable': True,
                'arguments': {
                    'x-message-ttl': 3600000,
                    'x-max-length': 5000
                }
            },
            'notifications': {
                'name': 'notifications',
                'routing_key': 'notifications',
                'durable': True,
                'arguments': {
                    'x-message-ttl': 86400000,  # 24ì‹œê°„
                    'x-max-length': 50000
                }
            }
        }
    
    async def setup(self):
        """RabbitMQ ì—°ê²° ë° í ì„¤ì •"""
        self.connection = await aio_pika.connect_robust(self.rabbitmq_url)
        self.channel = await self.connection.channel()
        
        # í ì„ ì–¸
        for queue_config in self.queues.values():
            await self.channel.queue_declare(**queue_config)
        
        # í”„ë¦¬í˜ì¹˜ ìˆ˜ ì„¤ì •
        await self.channel.set_qos(prefetch_count=10)
    
    async def publish_message(self, queue_name: str, message: Dict[str, Any]):
        """ë©”ì‹œì§€ ë°œí–‰"""
        queue_config = self.queues[queue_name]
        
        await self.channel.basic_publish(
            exchange='',
            routing_key=queue_config['routing_key'],
            body=json.dumps(message),
            properties=aio_pika.BasicProperties(
                delivery_mode=2,  # ì˜ì†ì„± ë©”ì‹œì§€
                content_type='application/json'
            )
        )
```

## 6. ëª¨ë‹ˆí„°ë§ ì•„í‚¤í…ì²˜

### 6.1 Prometheus ë©”íŠ¸ë¦­

#### 6.1.1 í•µì‹¬ ë©”íŠ¸ë¦­ ì •ì˜
```python
# monitoring/metrics.py
from prometheus_client import Counter, Histogram, Gauge, start_http_server

class ServiceMetrics:
    def __init__(self):
        # API ìš”ì²­ ë©”íŠ¸ë¦­
        self.api_requests_total = Counter(
            'api_requests_total',
            'Total API requests',
            ['method', 'endpoint', 'status']
        )
        
        self.api_request_duration = Histogram(
            'api_request_duration_seconds',
            'API request duration',
            ['method', 'endpoint']
        )
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­
        self.search_queries_total = Counter(
            'search_queries_total',
            'Total search queries'
        )
        
        self.sentiment_analyses_total = Counter(
            'sentiment_analyses_total',
            'Total sentiment analyses'
        )
        
        # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
        self.active_connections = Gauge(
            'active_connections',
            'Number of active connections'
        )
        
        self.cache_hit_rate = Gauge(
            'cache_hit_rate',
            'Cache hit rate'
        )
    
    def start_metrics_server(self, port: int = 8000):
        """ë©”íŠ¸ë¦­ ì„œë²„ ì‹œì‘"""
        start_http_server(port)
```

### 6.2 ë¡œê¹… ì „ëµ

#### 6.2.1 êµ¬ì¡°í™”ëœ ë¡œê¹…
```python
# logging/logger.py
import logging
import json
from datetime import datetime
from typing import Dict, Any

class StructuredLogger:
    def __init__(self, service_name: str):
        self.service_name = service_name
        self.logger = logging.getLogger(service_name)
        
        # ë¡œê±° ì„¤ì •
        handler = logging.StreamHandler()
        formatter = StructuredFormatter()
        handler.setFormatter(formatter)
        self.logger.addHandler(handler)
        self.logger.setLevel(logging.INFO)
    
    def log_api_request(self, method: str, endpoint: str, status: int, 
                      duration: float, user_id: str = None):
        """API ìš”ì²­ ë¡œê¹…"""
        self.logger.info("API request", extra={
            'event_type': 'api_request',
            'service': self.service_name,
            'method': method,
            'endpoint': endpoint,
            'status': status,
            'duration_ms': duration * 1000,
            'user_id': user_id,
            'timestamp': datetime.utcnow().isoformat()
        })
    
    def log_error(self, error: Exception, context: Dict[str, Any] = None):
        """ì—ëŸ¬ ë¡œê¹…"""
        self.logger.error("Service error", extra={
            'event_type': 'error',
            'service': self.service_name,
            'error_type': type(error).__name__,
            'error_message': str(error),
            'context': context or {},
            'timestamp': datetime.utcnow().isoformat()
        })

class StructuredFormatter(logging.Formatter):
    def format(self, record):
        log_entry = {
            'level': record.levelname,
            'message': record.getMessage(),
            **record.__dict__
        }
        return json.dumps(log_entry)
```

## 7. ë³´ì•ˆ ì•„í‚¤í…ì²˜

### 7.1 ë³´ì•ˆ ë ˆì´ì–´

#### 7.1.1 ë³´ì•ˆ ë¯¸ë“¤ì›¨ì–´
```python
# security/middleware.py
from fastapi import Request, HTTPException, status
from fastapi.security import HTTPBearer
import time
import logging

class SecurityMiddleware:
    def __init__(self, auth_service):
        self.auth_service = auth_service
        self.rate_limiter = RateLimiter()
        self.logger = logging.getLogger(__name__)
    
    async def authenticate_request(self, request: Request) -> Optional[User]:
        """ìš”ì²­ ì¸ì¦"""
        try:
            # Authorization í—¤ë” í™•ì¸
            authorization = request.headers.get('authorization')
            if not authorization or not authorization.startswith('Bearer '):
                return None
            
            token = authorization[7:]  # 'Bearer ' ì œê±°
            
            # í† í° ê²€ì¦
            payload = self.auth_service.verify_token(token)
            if not payload:
                return None
            
            # ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ
            user = await self.auth_service.get_user_by_id(payload['user_id'])
            if not user or not user.is_active:
                return None
            
            return user
            
        except Exception as e:
            self.logger.error(f"Authentication error: {str(e)}")
            return None
    
    async def check_rate_limit(self, request: Request, user: User = None) -> bool:
        """Rate Limiting í™•ì¸"""
        client_ip = self.get_client_ip(request)
        
        if user:
            # ì‚¬ìš©ìë³„ Rate Limiting
            return await self.rate_limiter.check_user_limit(user.id)
        else:
            # IPë³„ Rate Limiting
            return await self.rate_limiter.check_ip_limit(client_ip)
    
    def get_client_ip(self, request: Request) -> str:
        """í´ë¼ì´ì–¸íŠ¸ IP ì£¼ì†Œ ì¡°íšŒ"""
        # í”„ë¡ì‹œ í™˜ê²½ì—ì„œ ì‹¤ì œ IP í™•ì¸
        forwarded_for = request.headers.get('x-forwarded-for')
        if forwarded_for:
            return forwarded_for.split(',')[0].strip()
        
        real_ip = request.headers.get('x-real-ip')
        if real_ip:
            return real_ip
        
        return request.client.host
```

## 8. í™•ì¥ì„± ì „ëµ

### 8.1 ìˆ˜í‰ì  í™•ì¥

#### 8.1.1 ì˜¤í† ìŠ¤ì¼€ì¼ë§
```yaml
# deployment/autoscaling.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: stock-search-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: stock-search-service
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
```

### 8.2 ë°ì´í„°ë² ì´ìŠ¤ í™•ì¥

#### 8.2.1 ì½ê¸° ì „ìš© ë³µì œë³¸
```sql
-- ì½ê¸° ì „ìš© ë³µì œë³¸ ì„¤ì •
CREATE USER read_only_user WITH PASSWORD 'secure_password';
GRANT CONNECT ON DATABASE insitechart TO read_only_user;
GRANT USAGE ON SCHEMA public TO read_only_user;
GRANT SELECT ON ALL TABLES IN SCHEMA public TO read_only_user;

-- ì½ê¸° ì „ìš© ì„œë¹„ìŠ¤ ì—°ê²° ë¬¸ìì—´
DATABASE_URL=postgresql://read_only_user:secure_password@replica-host:5432/insitechart
```

## 9. ì¬í•´ ë³µêµ¬ ì „ëµ

### 9.1 ë‹¤ì¤‘ ë¦¬ì „ ë°°í¬

#### 9.1.1 ì§€ë¦¬ì  ë¶„ì‚°
```mermaid
graph TB
    subgraph "Primary Region (US-East)"
        A[Load Balancer]
        B[API Gateway]
        C[Services]
        D[Primary Database]
        E[Redis Cluster]
    end
    
    subgraph "Secondary Region (US-West)"
        F[Load Balancer]
        G[API Gateway]
        H[Services]
        I[Secondary Database]
        J[Redis Cluster]
    end
    
    subgraph "Tertiary Region (EU)"
        K[Load Balancer]
        L[API Gateway]
        M[Services]
        N[Backup Database]
        O[Redis Cluster]
    end
    
    D -.->|Replication| I
    I -.->|Replication| N
    
    A --> B
    B --> C
    C --> D
    C --> E
    
    F --> G
    G --> H
    H --> I
    H --> J
    
    K --> L
    L --> M
    M --> N
    M --> O
```

### 9.2 ì¥ì•  ì¡°ì¹˜ ì ˆì°¨

#### 9.2.1 ìë™ ì¥ì•  ì¡°ì¹˜
```python
# disaster_recovery/failover_manager.py
class FailoverManager:
    def __init__(self, monitoring_service, dns_service):
        self.monitoring_service = monitoring_service
        self.dns_service = dns_service
        self.current_primary = 'us-east'
        
    async def check_service_health(self):
        """ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
        regions = ['us-east', 'us-west', 'eu-west']
        health_status = {}
        
        for region in regions:
            is_healthy = await self.monitoring_service.check_region_health(region)
            health_status[region] = is_healthy
        
        return health_status
    
    async def initiate_failover(self, failed_region: str):
        """ì¥ì•  ì¡°ì¹˜ ì‹œì‘"""
        # 1. ê±´ê°•í•œ ë¦¬ì „ ì„ íƒ
        health_status = await self.check_service_health()
        healthy_regions = [r for r, h in health_status.items() if h and r != failed_region]
        
        if not healthy_regions:
            raise Exception("No healthy regions available for failover")
        
        new_primary = healthy_regions[0]
        
        # 2. DNS ì „í™˜
        await self.dns_service.update_primary_region(new_primary)
        
        # 3. ë°ì´í„°ë² ì´ìŠ¤ ìŠ¹ê²© (í•„ìš”ì‹œ)
        if failed_region == self.current_primary:
            await self.promote_database_replica(new_primary)
        
        # 4. ì•Œë¦¼ ë°œì†¡
        await self.send_failover_notification(failed_region, new_primary)
        
        self.current_primary = new_primary
```

## 10. Streamlit ê¸°ë°˜ ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜ êµ¬í˜„

### 10.1 í˜„ì¬ ì•±ì— ì ìš©í•  ìˆ˜ ìˆëŠ” ëª¨ë“ˆí™” ì•„í‚¤í…ì²˜

#### 10.1.1 ëª¨ë“ˆí™”ëœ ì»´í¬ë„ŒíŠ¸ êµ¬ì¡°
```python
# components/base.py
import streamlit as st
from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional

class BaseComponent(ABC):
    """ëª¨ë“  ì»´í¬ë„ŒíŠ¸ì˜ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    def __init__(self, component_id: str):
        self.component_id = component_id
        self.state_key = f"{self.__class__.__name__}_{component_id}"
    
    @abstractmethod
    def render(self, **kwargs) -> Any:
        """ì»´í¬ë„ŒíŠ¸ ë Œë”ë§"""
        pass
    
    def get_state(self) -> Dict[str, Any]:
        """ì»´í¬ë„ŒíŠ¸ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°"""
        return st.session_state.get(self.state_key, {})
    
    def set_state(self, state: Dict[str, Any]):
        """ì»´í¬ë„ŒíŠ¸ ìƒíƒœ ì„¤ì •"""
        st.session_state[self.state_key] = state
    
    def update_state(self, updates: Dict[str, Any]):
        """ì»´í¬ë„ŒíŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        current_state = self.get_state()
        current_state.update(updates)
        self.set_state(current_state)

# components/search.py
from .base import BaseComponent
from typing import List, Dict, Any
import asyncio
import requests
import time
from dataclasses import dataclass

@dataclass
class StockSuggestion:
    symbol: str
    company_name: str
    stock_type: str
    exchange: str
    sector: str
    industry: str
    relevance_score: float
    current_price: Optional[float] = None
    market_cap: Optional[float] = None

class StockSearchComponent(BaseComponent):
    """ì£¼ì‹ ê²€ìƒ‰ ì»´í¬ë„ŒíŠ¸"""
    
    def __init__(self, component_id: str = "stock_search"):
        super().__init__(component_id)
        self.cache = {}
        self.cache_ttl = 300  # 5ë¶„
    
    def render(self, on_select_callback=None, **kwargs) -> List[StockSuggestion]:
        """ê²€ìƒ‰ ì»´í¬ë„ŒíŠ¸ ë Œë”ë§"""
        st.markdown("### ğŸ” Enhanced Stock Search")
        
        # ê²€ìƒ‰ ì…ë ¥
        col_search, col_clear = st.columns([4, 1])
        
        with col_search:
            search_query = st.text_input(
                "Search stocks...",
                placeholder="Enter symbol or company name...",
                key=f"{self.state_key}_search_input"
            )
        
        with col_clear:
            st.write("")
            if st.button("Clear", key=f"{self.state_key}_clear"):
                self.set_state({'search_results': [], 'last_query': ''})
                st.rerun()
        
        # ê²€ìƒ‰ ì‹¤í–‰
        if search_query and search_query != self.get_state().get('last_query', ''):
            with st.spinner("Searching..."):
                # ë¹„ë™ê¸° ê²€ìƒ‰ ì‹¤í–‰
                results = asyncio.run(self._perform_search(search_query))
                self.update_state({
                    'search_results': results,
                    'last_query': search_query
                })
        
        # í•„í„° UI
        search_results = self.get_state().get('search_results', [])
        if search_results:
            self._render_filters(search_results)
        
        # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
        filtered_results = self._apply_filters(search_results)
        
        if filtered_results:
            st.markdown("#### Search Results")
            for result in filtered_results:
                self._render_result_item(result, on_select_callback)
        elif search_results:
            st.info("No results match your filters.")
        
        return filtered_results
    
    async def _perform_search(self, query: str) -> List[StockSuggestion]:
        """ê²€ìƒ‰ ìˆ˜í–‰"""
        # ìºì‹œ í™•ì¸
        cache_key = f"search_{query}"
        if cache_key in self.cache:
            cached_data, timestamp = self.cache[cache_key]
            if time.time() - timestamp < self.cache_ttl:
                return cached_data
        
        try:
            url = "https://query2.finance.yahoo.com/v1/finance/search"
            params = {
                "q": query,
                "quotes_count": 20,
                "country": "United States"
            }
            
            response = requests.get(
                url=url,
                params=params,
                headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'},
                timeout=10
            )
            
            if response.status_code == 200:
                data = response.json()
                suggestions = []
                
                for quote in data.get('quotes', []):
                    # ê´€ë ¨ë„ ì ìˆ˜ ê³„ì‚°
                    relevance_score = self._calculate_relevance_score(quote, query)
                    
                    suggestion = StockSuggestion(
                        symbol=quote.get('symbol', ''),
                        company_name=quote.get('shortname') or quote.get('longname', ''),
                        stock_type=quote.get('quoteType', ''),
                        exchange=quote.get('exchange', ''),
                        sector=quote.get('sector', ''),
                        industry=quote.get('industry', ''),
                        relevance_score=relevance_score
                    )
                    suggestions.append(suggestion)
                
                # ê´€ë ¨ë„ ìˆœìœ¼ë¡œ ì •ë ¬
                suggestions.sort(key=lambda x: x.relevance_score, reverse=True)
                
                # ìºì‹œ ì €ì¥
                self.cache[cache_key] = (suggestions, time.time())
                
                return suggestions
            else:
                return []
        except Exception as e:
            st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
            return []
    
    def _calculate_relevance_score(self, stock: Dict[str, Any], query: str) -> float:
        """ê´€ë ¨ë„ ì ìˆ˜ ê³„ì‚°"""
        query = query.lower()
        symbol = stock.get('symbol', '').lower()
        name = stock.get('shortname', '').lower()
        longname = stock.get('longname', '').lower()
        
        score = 0
        
        # ì‹¬ë³¼ ì •í™• ì¼ì¹˜
        if symbol == query:
            score += 100
        # ì‹¬ë³¼ ì‹œì‘ ì¼ì¹˜
        elif symbol.startswith(query):
            score += 80
        # íšŒì‚¬ëª… ì‹œì‘ ì¼ì¹˜
        elif name.startswith(query) or longname.startswith(query):
            score += 60
        # ì‹¬ë³¼ ë¶€ë¶„ ì¼ì¹˜
        elif query in symbol:
            score += 40
        # íšŒì‚¬ëª… ë¶€ë¶„ ì¼ì¹˜
        elif query in name or query in longname:
            score += 20
        
        return score
    
    def _render_filters(self, results: List[StockSuggestion]):
        """í•„í„° UI ë Œë”ë§"""
        with st.expander("ğŸ”§ Filters", expanded=False):
            stock_types = list(set(r.stock_type for r in results if r.stock_type))
            exchanges = list(set(r.exchange for r in results if r.exchange))
            sectors = list(set(r.sector for r in results if r.sector))
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                stock_type = st.selectbox(
                    "Stock Type",
                    ["All"] + stock_types,
                    key=f"{self.state_key}_filter_type"
                )
                self.update_state({'filter_type': stock_type if stock_type != "All" else None})
            
            with col2:
                exchange = st.selectbox(
                    "Exchange",
                    ["All"] + exchanges,
                    key=f"{self.state_key}_filter_exchange"
                )
                self.update_state({'filter_exchange': exchange if exchange != "All" else None})
            
            with col3:
                sector = st.selectbox(
                    "Sector",
                    ["All"] + sectors,
                    key=f"{self.state_key}_filter_sector"
                )
                self.update_state({'filter_sector': sector if sector != "All" else None})
    
    def _apply_filters(self, results: List[StockSuggestion]) -> List[StockSuggestion]:
        """í•„í„° ì ìš©"""
        filtered = results
        state = self.get_state()
        
        if state.get('filter_type'):
            filtered = [r for r in filtered if r.stock_type == state['filter_type']]
        
        if state.get('filter_exchange'):
            filtered = [r for r in filtered if r.exchange == state['filter_exchange']]
        
        if state.get('filter_sector'):
            filtered = [r for r in filtered if state['filter_sector'].lower() in r.sector.lower()]
        
        return filtered
    
    def _render_result_item(self, result: StockSuggestion, on_select_callback=None):
        """ê²€ìƒ‰ ê²°ê³¼ ì•„ì´í…œ ë Œë”ë§"""
        col_symbol, col_name, col_info, col_action = st.columns([1, 3, 2, 1])
        
        with col_symbol:
            st.markdown(f"**{result.symbol}**")
        
        with col_name:
            st.markdown(result.company_name)
        
        with col_info:
            st.markdown(f"{result.stock_type} â€¢ {result.exchange}")
        
        with col_action:
            if st.button("Select", key=f"{self.state_key}_select_{result.symbol}"):
                if on_select_callback:
                    on_select_callback(result)
                else:
                    st.session_state.current_ticker = result.symbol
                st.rerun()

# components/chart.py
from .base import BaseComponent
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import yfinance as yf
import pandas as pd
import ta

class StockChartComponent(BaseComponent):
    """ì£¼ì‹ ì°¨íŠ¸ ì»´í¬ë„ŒíŠ¸"""
    
    def __init__(self, component_id: str = "stock_chart"):
        super().__init__(component_id)
    
    def render(self, symbol: str, **kwargs) -> None:
        """ì°¨íŠ¸ ì»´í¬ë„ŒíŠ¸ ë Œë”ë§"""
        if not symbol:
            st.warning("Please select a stock to view chart.")
            return
        
        # ê¸°ê°„ ì„ íƒ
        self._render_period_selector()
        
        # ì°¨íŠ¸ íƒ€ì… ì„ íƒ
        self._render_chart_type_selector()
        
        # ì§€í‘œ ì„ íƒ
        self._render_indicator_selector()
        
        # ì°¨íŠ¸ ë Œë”ë§
        self._render_chart(symbol)
    
    def _render_period_selector(self):
        """ê¸°ê°„ ì„ íƒê¸° ë Œë”ë§"""
        periods = {
            "1D": "1d", "1W": "5d", "1M": "1mo", "3M": "3mo",
            "6M": "6mo", "1Y": "1y", "2Y": "2y", "5Y": "5y", "MAX": "max"
        }
        
        selected_period = self.get_state().get('selected_period', '1Y')
        
        col_periods = st.columns(9)
        for i, (label, value) in enumerate(periods.items()):
            with col_periods[i]:
                is_selected = selected_period == label
                if st.button(
                    label,
                    key=f"{self.state_key}_period_{label}",
                    type="primary" if is_selected else "secondary"
                ):
                    self.update_state({'selected_period': label})
                    st.rerun()
    
    def _render_chart_type_selector(self):
        """ì°¨íŠ¸ íƒ€ì… ì„ íƒê¸° ë Œë”ë§"""
        chart_types = ["Candlestick", "Line", "Area"]
        selected_type = self.get_state().get('chart_type', 'Candlestick')
        
        chart_type = st.selectbox(
            "Chart Type",
            chart_types,
            index=chart_types.index(selected_type),
            key=f"{self.state_key}_chart_type"
        )
        
        if chart_type != selected_type:
            self.update_state({'chart_type': chart_type})
    
    def _render_indicator_selector(self):
        """ì§€í‘œ ì„ íƒê¸° ë Œë”ë§"""
        with st.expander("ğŸ”§ Indicators", expanded=False):
            col1, col2, col3 = st.columns(3)
            
            with col1:
                show_bb = st.checkbox(
                    "ğŸ“Š Bollinger Bands",
                    value=self.get_state().get('show_bb', False),
                    key=f"{self.state_key}_show_bb"
                )
                show_rsi = st.checkbox(
                    "ğŸ“ˆ RSI",
                    value=self.get_state().get('show_rsi', False),
                    key=f"{self.state_key}_show_rsi"
                )
            
            with col2:
                show_macd = st.checkbox(
                    "ğŸ“‰ MACD",
                    value=self.get_state().get('show_macd', False),
                    key=f"{self.state_key}_show_macd"
                )
                show_volume = st.checkbox(
                    "ğŸ“¦ Volume",
                    value=self.get_state().get('show_volume', True),
                    key=f"{self.state_key}_show_volume"
                )
            
            with col3:
                show_sma = st.checkbox(
                    "ğŸ“ Moving Averages",
                    value=self.get_state().get('show_sma', False),
                    key=f"{self.state_key}_show_sma"
                )
            
            self.update_state({
                'show_bb': show_bb,
                'show_rsi': show_rsi,
                'show_macd': show_macd,
                'show_volume': show_volume,
                'show_sma': show_sma
            })
    
    def _render_chart(self, symbol: str):
        """ì°¨íŠ¸ ë Œë”ë§"""
        state = self.get_state()
        period_map = {
            "1D": "1d", "1W": "5d", "1M": "1mo", "3M": "3mo",
            "6M": "6mo", "1Y": "1y", "2Y": "2y", "5Y": "5y", "MAX": "max"
        }
        
        period = period_map.get(state.get('selected_period', '1Y'), '1y')
        
        try:
            ticker = yf.Ticker(symbol)
            hist_data = ticker.history(period=period)
            
            if hist_data.empty:
                st.warning(f"No historical data available for {symbol}")
                return
            
            # ì„œë¸Œí”Œë¡¯ ìƒì„±
            num_subplots = 1
            if state.get('show_rsi'):
                num_subplots += 1
            if state.get('show_macd'):
                num_subplots += 1
            
            row_heights = [0.6] + [0.2] * (num_subplots - 1)
            
            subplot_titles = [f'{symbol} - {state.get("selected_period", "1Y")}']
            if state.get('show_rsi'):
                subplot_titles.append('RSI')
            if state.get('show_macd'):
                subplot_titles.append('MACD')
            
            fig = make_subplots(
                rows=num_subplots, cols=1,
                shared_xaxes=True,
                vertical_spacing=0.03,
                subplot_titles=subplot_titles,
                row_heights=row_heights,
                specs=[[{"secondary_y": True}]] + [[{"secondary_y": False}]] * (num_subplots - 1)
            )
            
            # ë©”ì¸ ì°¨íŠ¸
            self._add_main_chart(fig, hist_data, 1, state.get('chart_type', 'Candlestick'))
            
            # ë³¼ë¥¨
            if state.get('show_volume'):
                self._add_volume_chart(fig, hist_data, 1)
            
            # ì´ë™í‰ê· 
            if state.get('show_sma'):
                self._add_moving_averages(fig, hist_data, 1)
            
            # ë³¼ë¦°ì € ë°´ë“œ
            if state.get('show_bb'):
                self._add_bollinger_bands(fig, hist_data, 1)
            
            # RSI
            current_row = 2
            if state.get('show_rsi'):
                self._add_rsi_chart(fig, hist_data, current_row)
                current_row += 1
            
            # MACD
            if state.get('show_macd'):
                self._add_macd_chart(fig, hist_data, current_row)
            
            # ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸
            fig.update_layout(
                height=700,
                showlegend=True,
                hovermode='x unified',
                xaxis_rangeslider_visible=False
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
        except Exception as e:
            st.error(f"Error loading chart: {str(e)}")
    
    def _add_main_chart(self, fig, hist_data, row, chart_type):
        """ë©”ì¸ ì°¨íŠ¸ ì¶”ê°€"""
        if chart_type == "Candlestick":
            fig.add_trace(go.Candlestick(
                x=hist_data.index,
                open=hist_data['Open'],
                high=hist_data['High'],
                low=hist_data['Low'],
                close=hist_data['Close'],
                name='Price',
                increasing_line_color='#26a69a',
                decreasing_line_color='#ef5350'
            ), row=row, col=1, secondary_y=False)
        elif chart_type == "Area":
            fig.add_trace(go.Scatter(
                x=hist_data.index,
                y=hist_data['Close'],
                mode='lines',
                name='Close',
                line=dict(color='#1f77b4', width=2),
                fill='tozeroy',
                fillcolor='rgba(31, 119, 180, 0.2)'
            ), row=row, col=1, secondary_y=False)
        else:  # Line
            fig.add_trace(go.Scatter(
                x=hist_data.index,
                y=hist_data['Close'],
                mode='lines',
                name='Close',
                line=dict(color='#1f77b4', width=2.5)
            ), row=row, col=1, secondary_y=False)
    
    def _add_volume_chart(self, fig, hist_data, row):
        """ë³¼ë¥¨ ì°¨íŠ¸ ì¶”ê°€"""
        colors = ['#ef5350' if hist_data['Close'].iloc[i] < hist_data['Open'].iloc[i] else '#26a69a'
                 for i in range(len(hist_data))]
        
        fig.add_trace(go.Bar(
            x=hist_data.index,
            y=hist_data['Volume'],
            name='Volume',
            marker_color=colors,
            opacity=0.5,
            showlegend=False
        ), row=row, col=1, secondary_y=True)
    
    def _add_moving_averages(self, fig, hist_data, row):
        """ì´ë™í‰ê·  ì¶”ê°€"""
        # SMA 20
        sma_20 = ta.trend.sma_indicator(hist_data['Close'], window=20)
        fig.add_trace(go.Scatter(
            x=hist_data.index, y=sma_20,
            mode='lines', name='SMA 20',
            line=dict(color='#ff9800', width=1.5)
        ), row=row, col=1, secondary_y=False)
        
        # SMA 50
        sma_50 = ta.trend.sma_indicator(hist_data['Close'], window=50)
        fig.add_trace(go.Scatter(
            x=hist_data.index, y=sma_50,
            mode='lines', name='SMA 50',
            line=dict(color='#9c27b0', width=1.5)
        ), row=row, col=1, secondary_y=False)
    
    def _add_bollinger_bands(self, fig, hist_data, row):
        """ë³¼ë¦°ì € ë°´ë“œ ì¶”ê°€"""
        # ë³¼ë¦°ì € ë°´ë“œ ê³„ì‚°
        bb = ta.volatility.BollingerBands(hist_data['Close'], window=20, window_dev=2)
        bb_upper = bb.bollinger_hband()
        bb_middle = bb.bollinger_mavg()
        bb_lower = bb.bollinger_lband()
        
        fig.add_trace(go.Scatter(
            x=hist_data.index, y=bb_upper,
            mode='lines', name='BB Upper',
            line=dict(color='rgba(250, 128, 114, 0.5)', width=1, dash='dash')
        ), row=row, col=1, secondary_y=False)
        
        fig.add_trace(go.Scatter(
            x=hist_data.index, y=bb_middle,
            mode='lines', name='BB Middle',
            line=dict(color='rgba(250, 128, 114, 0.8)', width=1.5)
        ), row=row, col=1, secondary_y=False)
        
        fig.add_trace(go.Scatter(
            x=hist_data.index, y=bb_lower,
            mode='lines', name='BB Lower',
            line=dict(color='rgba(250, 128, 114, 0.5)', width=1, dash='dash'),
            fill='tonexty', fillcolor='rgba(250, 128, 114, 0.1)'
        ), row=row, col=1, secondary_y=False)
    
    def _add_rsi_chart(self, fig, hist_data, row):
        """RSI ì°¨íŠ¸ ì¶”ê°€"""
        # RSI ê³„ì‚°
        rsi = ta.momentum.rsi(hist_data['Close'], window=14)
        
        fig.add_trace(go.Scatter(
            x=hist_data.index, y=rsi,
            mode='lines', name='RSI',
            line=dict(color='#9c27b0', width=2)
        ), row=row, col=1)
        
        fig.add_hline(y=70, line_dash="dash", line_color="red", row=row, col=1)
        fig.add_hline(y=30, line_dash="dash", line_color="green", row=row, col=1)
        fig.update_yaxes(range=[0, 100], row=row, col=1)
    
    def _add_macd_chart(self, fig, hist_data, row):
        """MACD ì°¨íŠ¸ ì¶”ê°€"""
        # MACD ê³„ì‚°
        macd = ta.trend.MACD(hist_data['Close'])
        
        fig.add_trace(go.Scatter(
            x=hist_data.index, y=macd.macd(),
            mode='lines', name='MACD',
            line=dict(color='#2196f3', width=2)
        ), row=row, col=1)
        
        fig.add_trace(go.Scatter(
            x=hist_data.index, y=macd.macd_signal(),
            mode='lines', name='Signal',
            line=dict(color='#f44336', width=2)
        ), row=row, col=1)
        
        colors = ['#26a69a' if val >= 0 else '#ef5350' for val in macd.macd_diff()]
        fig.add_trace(go.Bar(
            x=hist_data.index, y=macd.macd_diff(),
            name='Histogram',
            marker_color=colors,
            opacity=0.5
        ), row=row, col=1)

# components/watchlist.py
from .base import BaseComponent
from typing import List, Dict, Any

class WatchlistComponent(BaseComponent):
    """ê´€ì‹¬ì¢…ëª© ì»´í¬ë„ŒíŠ¸"""
    
    def __init__(self, component_id: str = "watchlist"):
        super().__init__(component_id)
    
    def render(self, on_select_callback=None, **kwargs) -> None:
        """ê´€ì‹¬ì¢…ëª© ì»´í¬ë„ŒíŠ¸ ë Œë”ë§"""
        st.markdown("### ğŸ”– Enhanced Watchlist")
        
        # ê´€ì‹¬ì¢…ëª© ëª©ë¡
        watchlist = self.get_watchlist()
        
        if watchlist:
            for symbol in watchlist:
                self._render_watchlist_item(symbol, on_select_callback)
        else:
            st.info("No stocks in watchlist.")
        
        # ìƒˆ ì£¼ì‹ ì¶”ê°€
        self._render_add_stock_form()
        
        # ê´€ì‹¬ì¢…ëª© ê´€ë¦¬
        if watchlist:
            self._render_watchlist_management(watchlist)
    
    def get_watchlist(self) -> List[str]:
        """ê´€ì‹¬ì¢…ëª© ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        return st.session_state.get('watchlist', [])
    
    def _render_watchlist_item(self, symbol: str, on_select_callback=None):
        """ê´€ì‹¬ì¢…ëª© ì•„ì´í…œ ë Œë”ë§"""
        col_symbol, col_action = st.columns([4, 1])
        
        with col_symbol:
            if st.button(f"ğŸ“Š {symbol}", key=f"{self.state_key}_select_{symbol}"):
                if on_select_callback:
                    on_select_callback(symbol)
                else:
                    st.session_state.current_ticker = symbol
                st.rerun()
        
        with col_action:
            if st.button("ğŸ—‘ï¸", key=f"{self.state_key}_remove_{symbol}"):
                watchlist = self.get_watchlist()
                watchlist.remove(symbol)
                st.session_state.watchlist = watchlist
                st.rerun()
    
    def _render_add_stock_form(self):
        """ìƒˆ ì£¼ì‹ ì¶”ê°€ í¼ ë Œë”ë§"""
        with st.expander("Add Stock", expanded=False):
            new_symbol = st.text_input(
                "Symbol",
                placeholder="AAPL",
                key=f"{self.state_key}_new_symbol"
            ).upper()
            
            if st.button("Add", key=f"{self.state_key}_add_stock"):
                if new_symbol:
                    watchlist = self.get_watchlist()
                    if new_symbol not in watchlist:
                        watchlist.append(new_symbol)
                        st.session_state.watchlist = watchlist
                        st.success(f"{new_symbol} added to watchlist!")
                        st.rerun()
                    else:
                        st.warning(f"{new_symbol} is already in watchlist.")
                else:
                    st.error("Please enter a symbol.")
    
    def _render_watchlist_management(self, watchlist: List[str]):
        """ê´€ì‹¬ì¢…ëª© ê´€ë¦¬ ë Œë”ë§"""
        with st.expander("Manage Watchlist", expanded=False):
            remove_symbol = st.selectbox(
                "Remove Stock",
                watchlist,
                key=f"{self.state_key}_remove_select"
            )
            
            if st.button("Remove Selected", key=f"{self.state_key}_remove_selected"):
                watchlist.remove(remove_symbol)
                st.session_state.watchlist = watchlist
                st.rerun()
```

#### 10.1.2 ì„œë¹„ìŠ¤ ë ˆì´ì–´ êµ¬í˜„
```python
# services/stock_service.py
import yfinance as yf
import pandas as pd
from typing import Dict, Any, Optional
from datetime import datetime
import asyncio

class StockService:
    """ì£¼ì‹ ë°ì´í„° ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.cache = {}
        self.cache_ttl = 300  # 5ë¶„
    
    async def get_stock_info(self, symbol: str) -> Optional[Dict[str, Any]]:
        """ì£¼ì‹ ê¸°ë³¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        cache_key = f"stock_info_{symbol}"
        
        # ìºì‹œ í™•ì¸
        if cache_key in self.cache:
            data, timestamp = self.cache[cache_key]
            if (datetime.now() - timestamp).seconds < self.cache_ttl:
                return data
        
        try:
            ticker = yf.Ticker(symbol)
            info = ticker.info
            
            if not info or 'symbol' not in info:
                return None
            
            stock_data = {
                'symbol': symbol,
                'company_name': info.get('longName', ''),
                'stock_type': info.get('quoteType', ''),
                'exchange': info.get('exchange', ''),
                'sector': info.get('sector', ''),
                'industry': info.get('industry', ''),
                'current_price': info.get('currentPrice') or info.get('regularMarketPrice'),
                'previous_close': info.get('previousClose'),
                'day_high': info.get('dayHigh'),
                'day_low': info.get('dayLow'),
                'volume': info.get('volume'),
                'market_cap': info.get('marketCap'),
                'pe_ratio': info.get('trailingPE'),
                'dividend_yield': info.get('dividendYield'),
                'beta': info.get('beta'),
                'fifty_two_week_high': info.get('fiftyTwoWeekHigh'),
                'fifty_two_week_low': info.get('fiftyTwoWeekLow')
            }
            
            # ìºì‹œ ì €ì¥
            self.cache[cache_key] = (stock_data, datetime.now())
            
            return stock_data
        except Exception as e:
            print(f"Error getting stock info for {symbol}: {str(e)}")
            return None
    
    async def get_historical_data(self, symbol: str, period: str = "1y") -> Optional[pd.DataFrame]:
        """ê³¼ê±° ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        cache_key = f"historical_{symbol}_{period}"
        
        # ìºì‹œ í™•ì¸
        if cache_key in self.cache:
            data, timestamp = self.cache[cache_key]
            if (datetime.now() - timestamp).seconds < self.cache_ttl:
                return data
        
        try:
            ticker = yf.Ticker(symbol)
            hist_data = ticker.history(period=period)
            
            if hist_data.empty:
                return None
            
            # ìºì‹œ ì €ì¥
            self.cache[cache_key] = (hist_data, datetime.now())
            
            return hist_data
        except Exception as e:
            print(f"Error getting historical data for {symbol}: {str(e)}")
            return None

# services/sentiment_service.py
import asyncio
from typing import Dict, Any, Optional, List
from datetime import datetime, timedelta
import random

class SentimentService:
    """ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.cache = {}
        self.cache_ttl = 300  # 5ë¶„
    
    async def get_sentiment_data(self, symbol: str) -> Optional[Dict[str, Any]]:
        """ì„¼í‹°ë¨¼íŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        cache_key = f"sentiment_{symbol}"
        
        # ìºì‹œ í™•ì¸
        if cache_key in self.cache:
            data, timestamp = self.cache[cache_key]
            if (datetime.now() - timestamp).seconds < self.cache_ttl:
                return data
        
        try:
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Reddit, Twitter API ë“±ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œ ë°ì´í„° ìƒì„±
            sentiment_data = {
                'symbol': symbol,
                'overall_sentiment': round(random.uniform(-0.5, 0.8), 2),
                'reddit_sentiment': round(random.uniform(-0.6, 0.7), 2),
                'twitter_sentiment': round(random.uniform(-0.4, 0.9), 2),
                'mention_count_24h': random.randint(50, 2000),
                'positive_mentions': random.randint(20, 1000),
                'negative_mentions': random.randint(10, 500),
                'neutral_mentions': random.randint(20, 800),
                'trending_status': random.choice([True, False]),
                'trend_score': round(random.uniform(0.5, 3.0), 1) if random.choice([True, False]) else None,
                'top_communities': [
                    {'name': 'wallstreetbets', 'mentions': random.randint(10, 100)},
                    {'name': 'investing', 'mentions': random.randint(5, 50)},
                    {'name': 'stocks', 'mentions': random.randint(5, 30)}
                ]
            }
            
            # ìºì‹œ ì €ì¥
            self.cache[cache_key] = (sentiment_data, datetime.now())
            
            return sentiment_data
        except Exception as e:
            print(f"Error getting sentiment data for {symbol}: {str(e)}")
            return None
    
    async def get_trending_stocks(self, limit: int = 10) -> List[Dict[str, Any]]:
        """íŠ¸ë Œë”© ì£¼ì‹ ê°€ì ¸ì˜¤ê¸°"""
        cache_key = f"trending_{limit}"
        
        # ìºì‹œ í™•ì¸
        if cache_key in self.cache:
            data, timestamp = self.cache[cache_key]
            if (datetime.now() - timestamp).seconds < self.cache_ttl:
                return data
        
        try:
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” APIì—ì„œ íŠ¸ë Œë”© ì£¼ì‹ ê°€ì ¸ì˜¤ê¸°
            # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œ ë°ì´í„° ìƒì„±
            trending_stocks = []
            popular_symbols = ['GME', 'AMC', 'TSLA', 'AAPL', 'NVDA', 'AMD', 'PLTR', 'BB', 'NOK', 'SNDL']
            
            for symbol in popular_symbols[:limit]:
                trending_stock = {
                    'symbol': symbol,
                    'trend_score': round(random.uniform(1.5, 5.0), 1),
                    'mention_count_24h': random.randint(500, 5000),
                    'sentiment_score': round(random.uniform(-0.3, 0.8), 2),
                    'trending_duration_hours': random.randint(1, 24)
                }
                trending_stocks.append(trending_stock)
            
            # íŠ¸ë Œë“œ ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
            trending_stocks.sort(key=lambda x: x['trend_score'], reverse=True)
            
            # ìºì‹œ ì €ì¥
            self.cache[cache_key] = (trending_stocks, datetime.now())
            
            return trending_stocks
        except Exception as e:
            print(f"Error getting trending stocks: {str(e)}")
            return []
```

#### 10.1.3 í†µí•© ì•± êµ¬ì¡°
```python
# app_enhanced.py
import streamlit as st
import asyncio
from components.search import StockSearchComponent
from components.chart import StockChartComponent
from components.watchlist import WatchlistComponent
from services.stock_service import StockService
from services.sentiment_service import SentimentService

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="InsiteChart - Enhanced Stock Analysis",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
if 'stock_service' not in st.session_state:
    st.session_state.stock_service = StockService()

if 'sentiment_service' not in st.session_state:
    st.session_state.sentiment_service = SentimentService()

# ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
def initialize_components():
    """ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
    if 'search_component' not in st.session_state:
        st.session_state.search_component = StockSearchComponent()
    
    if 'chart_component' not in st.session_state:
        st.session_state.chart_component = StockChartComponent()
    
    if 'watchlist_component' not in st.session_state:
        st.session_state.watchlist_component = WatchlistComponent()

# ìƒíƒœ ì´ˆê¸°í™”
def initialize_state():
    """ìƒíƒœ ì´ˆê¸°í™”"""
    if 'current_ticker' not in st.session_state:
        st.session_state.current_ticker = 'AAPL'
    
    if 'watchlist' not in st.session_state:
        st.session_state.watchlist = ['AAPL', 'MSFT', 'GOOGL', 'TSLA']

# ì½œë°± í•¨ìˆ˜
def on_stock_select(stock_data):
    """ì£¼ì‹ ì„ íƒ ì½œë°±"""
    st.session_state.current_ticker = stock_data.symbol
    
    # ê´€ì‹¬ì¢…ëª©ì— ì¶”ê°€ (ì„ íƒì )
    if stock_data.symbol not in st.session_state.watchlist:
        st.session_state.watchlist.append(stock_data.symbol)
        st.success(f"{stock_data.symbol} added to watchlist!")

def on_watchlist_select(symbol):
    """ê´€ì‹¬ì¢…ëª© ì„ íƒ ì½œë°±"""
    st.session_state.current_ticker = symbol

# ë©”ì¸ ì•±
def main():
    """ë©”ì¸ ì•±"""
    # ì´ˆê¸°í™”
    initialize_state()
    initialize_components()
    
    # ì»´í¬ë„ŒíŠ¸ ê°€ì ¸ì˜¤ê¸°
    search_component = st.session_state.search_component
    chart_component = st.session_state.chart_component
    watchlist_component = st.session_state.watchlist_component
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.title("ğŸ“ˆ InsiteChart")
        
        # ê´€ì‹¬ì¢…ëª© ì»´í¬ë„ŒíŠ¸
        watchlist_component.render(on_select_callback=on_watchlist_select)
        
        st.markdown("---")
        
        # í˜„ì¬ ì„ íƒëœ ì£¼ì‹ ì •ë³´
        if st.session_state.current_ticker:
            st.markdown(f"### Current: {st.session_state.current_ticker}")
            
            # ì£¼ì‹ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            stock_info = asyncio.run(
                st.session_state.stock_service.get_stock_info(st.session_state.current_ticker)
            )
            
            if stock_info:
                st.markdown(f"**{stock_info['company_name']}**")
                st.markdown(f"Price: ${stock_info['current_price']:.2f}")
                
                if stock_info['previous_close']:
                    change = stock_info['current_price'] - stock_info['previous_close']
                    change_pct = (change / stock_info['previous_close']) * 100
                    color = "ğŸŸ¢" if change >= 0 else "ğŸ”´"
                    st.markdown(f"{color} {change:+.2f} ({change_pct:+.2f}%)")
    
    # ë©”ì¸ ì»¨í…ì¸ 
    st.title("ğŸ“Š Enhanced Stock Analysis")
    
    # íƒ­ êµ¬ì¡°
    tab1, tab2, tab3 = st.tabs(["ğŸ” Search", "ğŸ“ˆ Chart", "ğŸ“Š Sentiment"])
    
    with tab1:
        # ê²€ìƒ‰ ì»´í¬ë„ŒíŠ¸
        search_component.render(on_select_callback=on_stock_select)
    
    with tab2:
        # ì°¨íŠ¸ ì»´í¬ë„ŒíŠ¸
        chart_component.render(st.session_state.current_ticker)
    
    with tab3:
        # ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„
        st.markdown("### ğŸ“Š Social Sentiment Analysis")
        
        if st.session_state.current_ticker:
            # ì„¼í‹°ë¨¼íŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            sentiment_data = asyncio.run(
                st.session_state.sentiment_service.get_sentiment_data(st.session_state.current_ticker)
            )
            
            if sentiment_data:
                # ì„¼í‹°ë¨¼íŠ¸ ì ìˆ˜ í‘œì‹œ
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    sentiment_color = "ğŸŸ¢" if sentiment_data['overall_sentiment'] > 0.1 else "ğŸ”´" if sentiment_data['overall_sentiment'] < -0.1 else "âšª"
                    st.metric("Overall Sentiment", f"{sentiment_color} {sentiment_data['overall_sentiment']:.2f}")
                
                with col2:
                    st.metric("Mentions (24h)", sentiment_data['mention_count_24h'])
                
                with col3:
                    if sentiment_data['trending_status']:
                        st.metric("Trending", "ğŸ”¥ Yes", delta=f"+{sentiment_data['trend_score']:.1f}")
                    else:
                        st.metric("Trending", "âŒ No")
                
                # ì»¤ë®¤ë‹ˆí‹° ë¶„ì„
                st.markdown("#### Community Breakdown")
                for community in sentiment_data['top_communities']:
                    st.markdown(f"- **{community['name']}**: {community['mentions']} mentions")
            else:
                st.info("No sentiment data available for this stock.")
        else:
            st.info("Please select a stock to view sentiment analysis.")
        
        st.markdown("---")
        
        # íŠ¸ë Œë”© ì£¼ì‹
        st.markdown("### ğŸ”¥ Trending Stocks")
        
        trending_stocks = asyncio.run(
            st.session_state.sentiment_service.get_trending_stocks(limit=10)
        )
        
        if trending_stocks:
            for stock in trending_stocks:
                col_symbol, col_trend, col_mentions, col_sentiment = st.columns([1, 1, 1, 1])
                
                with col_symbol:
                    st.markdown(f"**{stock['symbol']}**")
                
                with col_trend:
                    st.markdown(f"ğŸ”¥ {stock['trend_score']}")
                
                with col_mentions:
                    st.markdown(f"ğŸ’¬ {stock['mention_count_24h']}")
                
                with col_sentiment:
                    sentiment_color = "ğŸŸ¢" if stock['sentiment_score'] > 0.1 else "ğŸ”´" if stock['sentiment_score'] < -0.1 else "âšª"
                    st.markdown(f"{sentiment_color} {stock['sentiment_score']:.2f}")
                
                if st.button("View", key=f"trending_{stock['symbol']}"):
                    st.session_state.current_ticker = stock['symbol']
                    st.rerun()
        else:
            st.info("No trending stocks available.")

if __name__ == "__main__":
    main()
```

### 10.2 ë‹¨ê³„ì  ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ

#### 10.2.1 1ë‹¨ê³„: ëª¨ë“ˆí™” ì ìš©
1. **ì»´í¬ë„ŒíŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ ë„ì…**
   - ê¸°ì¡´ ì½”ë“œë¥¼ ì»´í¬ë„ŒíŠ¸ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
   - ê¸°ë³¸ ì»´í¬ë„ŒíŠ¸ í´ë˜ìŠ¤ êµ¬í˜„
   - ìƒíƒœ ê´€ë¦¬ ê°œì„ 

2. **ì„œë¹„ìŠ¤ ë ˆì´ì–´ ë„ì…**
   - ë°ì´í„° ì²˜ë¦¬ ë¡œì§ì„ ì„œë¹„ìŠ¤ë¡œ ë¶„ë¦¬
   - ìºì‹± ì‹œìŠ¤í…œ êµ¬í˜„
   - ë¹„ë™ê¸° ì²˜ë¦¬ ë„ì…

#### 10.2.2 2ë‹¨ê³„: ê¸°ëŠ¥ í†µí•©
1. **í†µí•© ë°ì´í„° ëª¨ë¸ ì ìš©**
   - ì£¼ì‹ê³¼ ì„¼í‹°ë¨¼íŠ¸ ë°ì´í„° í†µí•©
   - ì¼ê´€ëœ API ì¸í„°í˜ì´ìŠ¤ ì œê³µ

2. **UI/UX ê°œì„ **
   - ë°˜ì‘í˜• ë””ìì¸ ì ìš©
   - ì‚¬ìš©ì ê²½í—˜ ê°œì„ 

#### 10.2.3 3ë‹¨ê³„: ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì „í™˜
1. **API ë¶„ë¦¬**
   - ê° ì„œë¹„ìŠ¤ë¥¼ ë…ë¦½ì ì¸ APIë¡œ ë¶„ë¦¬
   - API Gateway ë„ì…

2. **ë°ì´í„°ë² ì´ìŠ¤ ë„ì…**
   - PostgreSQL, Redis ë„ì…
   - ë°ì´í„° ì˜ì†ì„± êµ¬í˜„

ì´ í†µí•© ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ëŠ” í™•ì¥ ê°€ëŠ¥í•˜ê³  ì•ˆì •ì ì¸ ì„œë¹„ìŠ¤ ìš´ì˜ì„ ìœ„í•œ ì²´ê³„ì ì¸ ì„¤ê³„ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ê° ì»´í¬ë„ŒíŠ¸ëŠ” ë…ë¦½ì ìœ¼ë¡œ ìš´ì˜ë˜ë©´ì„œë„ ê¸´ë°€í•˜ê²Œ í†µí•©ë˜ì–´ ì‚¬ìš©ìì—ê²Œ ì¼ê´€ëœ ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤. íŠ¹íˆ í˜„ì¬ Streamlit ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì¦‰ì‹œ ì ìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ì½”ë“œ ì˜ˆì‹œë“¤ì„ í¬í•¨í•˜ì—¬ ì‹¤ìš©ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.

## 11. í†µí•© ê°œì„  ì „ëµ

### 11.1 ì‹œìŠ¤í…œ í†µí•© ê°œì„  ë°©ì•ˆ

#### 11.1.1 í†µí•© ë°ì´í„° ëª¨ë¸
```python
# models/unified_models.py
from dataclasses import dataclass
from typing import Optional, List, Dict, Any
from datetime import datetime
from enum import Enum

class StockType(Enum):
    EQUITY = "EQUITY"
    ETF = "ETF"
    MUTUAL_FUND = "MUTUAL_FUND"
    CRYPTO = "CRYPTO"
    INDEX = "INDEX"

class SentimentSource(Enum):
    REDDIT = "REDDIT"
    TWITTER = "TWITTER"
    DISCORD = "DISCORD"
    NEWS = "NEWS"

@dataclass
class UnifiedStockData:
    """í†µí•© ì£¼ì‹ ë°ì´í„° ëª¨ë¸"""
    symbol: str
    company_name: str
    stock_type: StockType
    exchange: str
    sector: Optional[str] = None
    industry: Optional[str] = None
    market_cap: Optional[float] = None
    current_price: Optional[float] = None
    previous_close: Optional[float] = None
    day_change: Optional[float] = None
    day_change_pct: Optional[float] = None
    volume: Optional[int] = None
    avg_volume: Optional[int] = None
    pe_ratio: Optional[float] = None
    dividend_yield: Optional[float] = None
    beta: Optional[float] = None
    fifty_two_week_high: Optional[float] = None
    fifty_two_week_low: Optional[float] = None
    
    # ì„¼í‹°ë¨¼íŠ¸ ë°ì´í„° í†µí•©
    overall_sentiment: Optional[float] = None
    sentiment_sources: Optional[Dict[SentimentSource, float]] = None
    mention_count_24h: Optional[int] = None
    trending_status: bool = False
    trend_score: Optional[float] = None
    
    # ë©”íƒ€ë°ì´í„°
    last_updated: Optional[datetime] = None
    data_quality_score: float = 1.0  # 0.0-1.0 ë°ì´í„° í’ˆì§ˆ ì ìˆ˜
    
    def __post_init__(self):
        if self.last_updated is None:
            self.last_updated = datetime.utcnow()
        
        if self.sentiment_sources is None:
            self.sentiment_sources = {}
        
        # ì¼ì¼ ë³€í™” ê³„ì‚°
        if self.current_price and self.previous_close:
            self.day_change = self.current_price - self.previous_close
            self.day_change_pct = (self.day_change / self.previous_close) * 100

@dataclass
class SearchQuery:
    """ê²€ìƒ‰ ì¿¼ë¦¬ ëª¨ë¸"""
    query: str
    user_id: Optional[str] = None
    filters: Optional[Dict[str, Any]] = None
    timestamp: datetime = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.utcnow()
        if self.filters is None:
            self.filters = {}

@dataclass
class SearchResult:
    """ê²€ìƒ‰ ê²°ê³¼ ëª¨ë¸"""
    query: SearchQuery
    results: List[UnifiedStockData]
    total_count: int
    search_time_ms: float
    cache_hit: bool = False
    suggestions: Optional[List[str]] = None
```

#### 11.1.2 í†µí•© ìºì‹± ì „ëµ
```python
# cache/unified_cache.py
import redis
import json
import hashlib
from typing import Optional, List, Dict, Any, Union
from datetime import datetime, timedelta
from models.unified_models import UnifiedStockData, SearchQuery

class UnifiedCacheManager:
    """í†µí•© ìºì‹œ ê´€ë¦¬ì"""
    
    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client
        self.default_ttl = 300  # 5ë¶„
        
        # ìºì‹œ í‚¤ ì •ì˜
        self.key_patterns = {
            'stock_data': 'stock:{symbol}',
            'search_results': 'search:{query_hash}',
            'sentiment_data': 'sentiment:{symbol}',
            'trending_stocks': 'trending:{timeframe}',
            'user_watchlist': 'watchlist:{user_id}',
            'autocomplete': 'autocomplete:{query}',
            'market_overview': 'market:overview'
        }
        
        # ìºì‹œ TTL ì„¤ì •
        self.ttl_settings = {
            'stock_data': 300,        # 5ë¶„
            'search_results': 180,    # 3ë¶„
            'sentiment_data': 120,    # 2ë¶„
            'trending_stocks': 600,   # 10ë¶„
            'user_watchlist': 3600,   # 1ì‹œê°„
            'autocomplete': 1800,     # 30ë¶„
            'market_overview': 60     # 1ë¶„
        }
    
    def _generate_query_hash(self, query: SearchQuery) -> str:
        """ê²€ìƒ‰ ì¿¼ë¦¬ í•´ì‹œ ìƒì„±"""
        query_str = f"{query.query}_{json.dumps(query.filters, sort_keys=True)}"
        return hashlib.md5(query_str.encode()).hexdigest()
    
    async def get_stock_data(self, symbol: str) -> Optional[UnifiedStockData]:
        """ì£¼ì‹ ë°ì´í„° ìºì‹œ ì¡°íšŒ"""
        key = self.key_patterns['stock_data'].format(symbol=symbol)
        cached_data = await self.redis.get(key)
        
        if cached_data:
            try:
                data = json.loads(cached_data)
                return UnifiedStockData(**data)
            except Exception as e:
                print(f"Error parsing cached stock data: {e}")
                return None
        
        return None
    
    async def set_stock_data(self, stock_data: UnifiedStockData) -> None:
        """ì£¼ì‹ ë°ì´í„° ìºì‹œ ì €ì¥"""
        key = self.key_patterns['stock_data'].format(symbol=stock_data.symbol)
        ttl = self.ttl_settings['stock_data']
        
        data_dict = {
            'symbol': stock_data.symbol,
            'company_name': stock_data.company_name,
            'stock_type': stock_data.stock_type.value,
            'exchange': stock_data.exchange,
            'sector': stock_data.sector,
            'industry': stock_data.industry,
            'market_cap': stock_data.market_cap,
            'current_price': stock_data.current_price,
            'previous_close': stock_data.previous_close,
            'day_change': stock_data.day_change,
            'day_change_pct': stock_data.day_change_pct,
            'volume': stock_data.volume,
            'avg_volume': stock_data.avg_volume,
            'pe_ratio': stock_data.pe_ratio,
            'dividend_yield': stock_data.dividend_yield,
            'beta': stock_data.beta,
            'fifty_two_week_high': stock_data.fifty_two_week_high,
            'fifty_two_week_low': stock_data.fifty_two_week_low,
            'overall_sentiment': stock_data.overall_sentiment,
            'sentiment_sources': {k.value: v for k, v in stock_data.sentiment_sources.items()},
            'mention_count_24h': stock_data.mention_count_24h,
            'trending_status': stock_data.trending_status,
            'trend_score': stock_data.trend_score,
            'last_updated': stock_data.last_updated.isoformat() if stock_data.last_updated else None,
            'data_quality_score': stock_data.data_quality_score
        }
        
        await self.redis.setex(key, ttl, json.dumps(data_dict, default=str))
    
    async def get_search_results(self, query: SearchQuery) -> Optional[List[UnifiedStockData]]:
        """ê²€ìƒ‰ ê²°ê³¼ ìºì‹œ ì¡°íšŒ"""
        query_hash = self._generate_query_hash(query)
        key = self.key_patterns['search_results'].format(query_hash=query_hash)
        cached_data = await self.redis.get(key)
        
        if cached_data:
            try:
                data = json.loads(cached_data)
                results = [UnifiedStockData(**item) for item in data['results']]
                return results
            except Exception as e:
                print(f"Error parsing cached search results: {e}")
                return None
        
        return None
    
    async def set_search_results(self, query: SearchQuery, results: List[UnifiedStockData]) -> None:
        """ê²€ìƒ‰ ê²°ê³¼ ìºì‹œ ì €ì¥"""
        query_hash = self._generate_query_hash(query)
        key = self.key_patterns['search_results'].format(query_hash=query_hash)
        ttl = self.ttl_settings['search_results']
        
        data_dict = {
            'query': query.query,
            'filters': query.filters,
            'results': [
                {
                    'symbol': stock.symbol,
                    'company_name': stock.company_name,
                    'stock_type': stock.stock_type.value,
                    'exchange': stock.exchange,
                    'sector': stock.sector,
                    'industry': stock.industry,
                    'market_cap': stock.market_cap,
                    'current_price': stock.current_price,
                    'previous_close': stock.previous_close,
                    'day_change': stock.day_change,
                    'day_change_pct': stock.day_change_pct,
                    'volume': stock.volume,
                    'avg_volume': stock.avg_volume,
                    'pe_ratio': stock.pe_ratio,
                    'dividend_yield': stock.dividend_yield,
                    'beta': stock.beta,
                    'fifty_two_week_high': stock.fifty_two_week_high,
                    'fifty_two_week_low': stock.fifty_two_week_low,
                    'overall_sentiment': stock.overall_sentiment,
                    'sentiment_sources': {k.value: v for k, v in stock.sentiment_sources.items()},
                    'mention_count_24h': stock.mention_count_24h,
                    'trending_status': stock.trending_status,
                    'trend_score': stock.trend_score,
                    'last_updated': stock.last_updated.isoformat() if stock.last_updated else None,
                    'data_quality_score': stock.data_quality_score
                }
                for stock in results
            ],
            'total_count': len(results),
            'timestamp': datetime.utcnow().isoformat()
        }
        
        await self.redis.setex(key, ttl, json.dumps(data_dict, default=str))
    
    async def invalidate_stock_data(self, symbol: str) -> None:
        """ì£¼ì‹ ë°ì´í„° ìºì‹œ ë¬´íš¨í™”"""
        key = self.key_patterns['stock_data'].format(symbol=symbol)
        await self.redis.delete(key)
        
        # ê´€ë ¨ ê²€ìƒ‰ ê²°ê³¼ë„ ë¬´íš¨í™” (íŒ¨í„´ ë§¤ì¹­)
        search_keys = await self.redis.keys(f"search:*")
        if search_keys:
            await self.redis.delete(*search_keys)
    
    async def get_cache_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ì •ë³´ ì¡°íšŒ"""
        info = await self.redis.info()
        
        return {
            'used_memory': info.get('used_memory_human'),
            'connected_clients': info.get('connected_clients'),
            'total_commands_processed': info.get('total_commands_processed'),
            'keyspace_hits': info.get('keyspace_hits'),
            'keyspace_misses': info.get('keyspace_misses'),
            'hit_rate': (
                info.get('keyspace_hits', 0) /
                (info.get('keyspace_hits', 0) + info.get('keyspace_misses', 1))
            ) * 100
        }
```

#### 11.1.3 í†µí•© ì—ëŸ¬ í•¸ë“¤ë§
```python
# error_handling/unified_error_handler.py
import logging
import traceback
from typing import Dict, Any, Optional, Callable
from functools import wraps
from datetime import datetime
from enum import Enum

class ErrorSeverity(Enum):
    LOW = "LOW"
    MEDIUM = "MEDIUM"
    HIGH = "HIGH"
    CRITICAL = "CRITICAL"

class ErrorCategory(Enum):
    NETWORK = "NETWORK"
    API = "API"
    DATA = "DATA"
    AUTHENTICATION = "AUTHENTICATION"
    VALIDATION = "VALIDATION"
    SYSTEM = "SYSTEM"

class UnifiedError(Exception):
    """í†µí•© ì—ëŸ¬ í´ë˜ìŠ¤"""
    
    def __init__(
        self,
        message: str,
        category: ErrorCategory,
        severity: ErrorSeverity = ErrorSeverity.MEDIUM,
        context: Optional[Dict[str, Any]] = None,
        original_error: Optional[Exception] = None
    ):
        super().__init__(message)
        self.message = message
        self.category = category
        self.severity = severity
        self.context = context or {}
        self.original_error = original_error
        self.timestamp = datetime.utcnow()
        self.traceback_str = traceback.format_exc() if original_error else None

class ErrorHandler:
    """í†µí•© ì—ëŸ¬ í•¸ë“¤ëŸ¬"""
    
    def __init__(self, logger: logging.Logger):
        self.logger = logger
        self.error_callbacks = {}
        self.error_stats = {
            'total_errors': 0,
            'by_category': {},
            'by_severity': {}
        }
    
    def register_callback(
        self,
        category: ErrorCategory,
        callback: Callable[[UnifiedError], None]
    ):
        """ì—ëŸ¬ ì½œë°± ë“±ë¡"""
        if category not in self.error_callbacks:
            self.error_callbacks[category] = []
        self.error_callbacks[category].append(callback)
    
    def handle_error(self, error: UnifiedError):
        """ì—ëŸ¬ ì²˜ë¦¬"""
        # í†µê³„ ì—…ë°ì´íŠ¸
        self.error_stats['total_errors'] += 1
        
        category_name = error.category.value
        if category_name not in self.error_stats['by_category']:
            self.error_stats['by_category'][category_name] = 0
        self.error_stats['by_category'][category_name] += 1
        
        severity_name = error.severity.value
        if severity_name not in self.error_stats['by_severity']:
            self.error_stats['by_severity'][severity_name] = 0
        self.error_stats['by_severity'][severity_name] += 1
        
        # ë¡œê¹…
        log_level = {
            ErrorSeverity.LOW: logging.INFO,
            ErrorSeverity.MEDIUM: logging.WARNING,
            ErrorSeverity.HIGH: logging.ERROR,
            ErrorSeverity.CRITICAL: logging.CRITICAL
        }.get(error.severity, logging.ERROR)
        
        self.logger.log(
            log_level,
            f"[{error.category.value}] {error.message}",
            extra={
                'category': error.category.value,
                'severity': error.severity.value,
                'context': error.context,
                'timestamp': error.timestamp.isoformat(),
                'traceback': error.traceback_str
            }
        )
        
        # ì½œë°± ì‹¤í–‰
        if error.category in self.error_callbacks:
            for callback in self.error_callbacks[error.category]:
                try:
                    callback(error)
                except Exception as callback_error:
                    self.logger.error(f"Error in callback: {callback_error}")
    
    def get_error_stats(self) -> Dict[str, Any]:
        """ì—ëŸ¬ í†µê³„ ì •ë³´ ì¡°íšŒ"""
        return self.error_stats.copy()

def handle_errors(
    category: ErrorCategory,
    severity: ErrorSeverity = ErrorSeverity.MEDIUM,
    reraise: bool = True,
    return_value: Any = None
):
    """ì—ëŸ¬ í•¸ë“¤ë§ ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ìˆ˜ì§‘
                context = {
                    'function': func.__name__,
                    'module': func.__module__,
                    'args': str(args)[:200],  # ê¸´ ì¸ìëŠ” ìë¦„
                    'kwargs': str(kwargs)[:200]
                }
                
                # í†µí•© ì—ëŸ¬ ìƒì„±
                unified_error = UnifiedError(
                    message=str(e),
                    category=category,
                    severity=severity,
                    context=context,
                    original_error=e
                )
                
                # ì—ëŸ¬ í•¸ë“¤ëŸ¬ ê°€ì ¸ì˜¤ê¸° (ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ë˜ëŠ” ì¸ìë¡œ ì „ë‹¬)
                error_handler = kwargs.get('error_handler')
                if error_handler and isinstance(error_handler, ErrorHandler):
                    error_handler.handle_error(unified_error)
                
                if reraise:
                    raise unified_error
                else:
                    return return_value
        
        return wrapper
    return decorator
```

#### 11.1.4 í†µí•© API ë ˆì´ì–´
```python
# api/unified_api.py
from fastapi import FastAPI, HTTPException, Depends, Query
from fastapi.security import HTTPBearer
from typing import List, Optional, Dict, Any
from models.unified_models import UnifiedStockData, SearchQuery, SearchResult
from services.unified_service import UnifiedService
from error_handling.unified_error_handler import ErrorHandler, handle_errors, ErrorCategory, ErrorSeverity

app = FastAPI(title="InsiteChart Unified API", version="1.0.0")
security = HTTPBearer()

# ì˜ì¡´ì„± ì£¼ì…
def get_unified_service() -> UnifiedService:
    return UnifiedService()

def get_error_handler() -> ErrorHandler:
    return ErrorHandler()

# API ë¼ìš°íŠ¸
@app.get("/api/v1/stocks/{symbol}", response_model=UnifiedStockData)
@handle_errors(category=ErrorCategory.API, severity=ErrorSeverity.MEDIUM)
async def get_stock(
    symbol: str,
    include_sentiment: bool = Query(True, description="Include sentiment data"),
    unified_service: UnifiedService = Depends(get_unified_service)
):
    """ì£¼ì‹ ì •ë³´ ì¡°íšŒ (í†µí•© ë°ì´í„°)"""
    try:
        stock_data = await unified_service.get_stock_data(symbol, include_sentiment)
        if not stock_data:
            raise HTTPException(status_code=404, detail=f"Stock {symbol} not found")
        return stock_data
    except UnifiedError as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/search", response_model=SearchResult)
@handle_errors(category=ErrorCategory.API, severity=ErrorSeverity.MEDIUM)
async def search_stocks(
    query: SearchQuery,
    unified_service: UnifiedService = Depends(get_unified_service)
):
    """ì£¼ì‹ ê²€ìƒ‰ (í†µí•© ê²€ìƒ‰)"""
    try:
        search_results = await unified_service.search_stocks(query)
        return search_results
    except UnifiedError as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/trending", response_model=List[UnifiedStockData])
@handle_errors(category=ErrorCategory.API, severity=ErrorSeverity.MEDIUM)
async def get_trending_stocks(
    limit: int = Query(10, ge=1, le=50),
    timeframe: str = Query("24h", regex="^(1h|6h|24h|7d)$"),
    unified_service: UnifiedService = Depends(get_unified_service)
):
    """íŠ¸ë Œë”© ì£¼ì‹ ì¡°íšŒ"""
    try:
        trending_stocks = await unified_service.get_trending_stocks(limit, timeframe)
        return trending_stocks
    except UnifiedError as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/sentiment/{symbol}")
@handle_errors(category=ErrorCategory.API, severity=ErrorSeverity.MEDIUM)
async def get_sentiment_analysis(
    symbol: str,
    sources: Optional[str] = Query(None, description="Comma-separated sources: reddit,twitter,discord"),
    timeframe: str = Query("24h", regex="^(1h|6h|24h|7d)$"),
    unified_service: UnifiedService = Depends(get_unified_service)
):
    """ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„ ì¡°íšŒ"""
    try:
        source_list = sources.split(',') if sources else None
        sentiment_data = await unified_service.get_sentiment_analysis(symbol, source_list, timeframe)
        return sentiment_data
    except UnifiedError as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return {"status": "healthy", "timestamp": datetime.utcnow().isoformat()}
```

### 11.2 í†µí•© ì„œë¹„ìŠ¤ êµ¬í˜„

#### 11.2.1 í†µí•© ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
```python
# services/unified_service.py
import asyncio
from typing import List, Optional, Dict, Any
from datetime import datetime, timedelta
from models.unified_models import UnifiedStockData, SearchQuery, SearchResult, StockType, SentimentSource
from cache.unified_cache import UnifiedCacheManager
from error_handling.unified_error_handler import ErrorHandler, UnifiedError, ErrorCategory, ErrorSeverity, handle_errors

class UnifiedService:
    """í†µí•© ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(
        self,
        stock_service,
        sentiment_service,
        cache_manager: UnifiedCacheManager,
        error_handler: ErrorHandler
    ):
        self.stock_service = stock_service
        self.sentiment_service = sentiment_service
        self.cache_manager = cache_manager
        self.error_handler = error_handler
        
        # ì—ëŸ¬ í•¸ë“¤ëŸ¬ ì½œë°± ë“±ë¡
        self.error_handler.register_callback(ErrorCategory.DATA, self._handle_data_error)
        self.error_handler.register_callback(ErrorCategory.NETWORK, self._handle_network_error)
    
    @handle_errors(category=ErrorCategory.DATA, severity=ErrorSeverity.MEDIUM)
    async def get_stock_data(self, symbol: str, include_sentiment: bool = True) -> Optional[UnifiedStockData]:
        """í†µí•© ì£¼ì‹ ë°ì´í„° ì¡°íšŒ"""
        # ìºì‹œ í™•ì¸
        cached_stock = await self.cache_manager.get_stock_data(symbol)
        if cached_stock:
            return cached_stock
        
        try:
            # ì£¼ì‹ ê¸°ë³¸ ì •ë³´ ì¡°íšŒ
            stock_info = await self.stock_service.get_stock_info(symbol)
            if not stock_info:
                return None
            
            # ì„¼í‹°ë¨¼íŠ¸ ë°ì´í„° ì¡°íšŒ (ì„ íƒì )
            sentiment_data = None
            if include_sentiment:
                sentiment_data = await self.sentiment_service.get_sentiment_data(symbol)
            
            # í†µí•© ë°ì´í„° ìƒì„±
            unified_stock = UnifiedStockData(
                symbol=stock_info['symbol'],
                company_name=stock_info['company_name'],
                stock_type=StockType(stock_info.get('stock_type', 'EQUITY')),
                exchange=stock_info['exchange'],
                sector=stock_info.get('sector'),
                industry=stock_info.get('industry'),
                market_cap=stock_info.get('market_cap'),
                current_price=stock_info.get('current_price'),
                previous_close=stock_info.get('previous_close'),
                volume=stock_info.get('volume'),
                avg_volume=stock_info.get('avg_volume'),
                pe_ratio=stock_info.get('pe_ratio'),
                dividend_yield=stock_info.get('dividend_yield'),
                beta=stock_info.get('beta'),
                fifty_two_week_high=stock_info.get('fifty_two_week_high'),
                fifty_two_week_low=stock_info.get('fifty_two_week_low'),
                overall_sentiment=sentiment_data.get('overall_sentiment') if sentiment_data else None,
                sentiment_sources=self._parse_sentiment_sources(sentiment_data) if sentiment_data else {},
                mention_count_24h=sentiment_data.get('mention_count_24h') if sentiment_data else None,
                trending_status=sentiment_data.get('trending_status', False) if sentiment_data else False,
                trend_score=sentiment_data.get('trend_score') if sentiment_data else None,
                data_quality_score=self._calculate_data_quality_score(stock_info, sentiment_data)
            )
            
            # ìºì‹œ ì €ì¥
            await self.cache_manager.set_stock_data(unified_stock)
            
            return unified_stock
            
        except Exception as e:
            raise UnifiedError(
                message=f"Error getting stock data for {symbol}: {str(e)}",
                category=ErrorCategory.DATA,
                severity=ErrorSeverity.HIGH,
                context={'symbol': symbol, 'include_sentiment': include_sentiment},
                original_error=e
            )
    
    @handle_errors(category=ErrorCategory.DATA, severity=ErrorSeverity.MEDIUM)
    async def search_stocks(self, query: SearchQuery) -> SearchResult:
        """í†µí•© ì£¼ì‹ ê²€ìƒ‰"""
        # ìºì‹œ í™•ì¸
        cached_results = await self.cache_manager.get_search_results(query)
        if cached_results:
            return SearchResult(
                query=query,
                results=cached_results,
                total_count=len(cached_results),
                search_time_ms=0,
                cache_hit=True
            )
        
        start_time = datetime.utcnow()
        
        try:
            # ì£¼ì‹ ê²€ìƒ‰
            search_results = await self.stock_service.search_stocks(query.query, query.filters)
            
            # ì„¼í‹°ë¨¼íŠ¸ ë°ì´í„° ë³‘í•© (ë³‘ë ¬ ì²˜ë¦¬)
            if search_results:
                sentiment_tasks = [
                    self.sentiment_service.get_sentiment_data(stock['symbol'])
                    for stock in search_results
                ]
                
                sentiment_results = await asyncio.gather(*sentiment_tasks, return_exceptions=True)
                
                # ê²°ê³¼ ë³‘í•©
                unified_results = []
                for i, stock in enumerate(search_results):
                    sentiment_data = sentiment_results[i] if not isinstance(sentiment_results[i], Exception) else None
                    
                    unified_stock = UnifiedStockData(
                        symbol=stock['symbol'],
                        company_name=stock['company_name'],
                        stock_type=StockType(stock.get('stock_type', 'EQUITY')),
                        exchange=stock['exchange'],
                        sector=stock.get('sector'),
                        industry=stock.get('industry'),
                        market_cap=stock.get('market_cap'),
                        current_price=stock.get('current_price'),
                        previous_close=stock.get('previous_close'),
                        volume=stock.get('volume'),
                        avg_volume=stock.get('avg_volume'),
                        pe_ratio=stock.get('pe_ratio'),
                        dividend_yield=stock.get('dividend_yield'),
                        beta=stock.get('beta'),
                        fifty_two_week_high=stock.get('fifty_two_week_high'),
                        fifty_two_week_low=stock.get('fifty_two_week_low'),
                        overall_sentiment=sentiment_data.get('overall_sentiment') if sentiment_data else None,
                        sentiment_sources=self._parse_sentiment_sources(sentiment_data) if sentiment_data else {},
                        mention_count_24h=sentiment_data.get('mention_count_24h') if sentiment_data else None,
                        trending_status=sentiment_data.get('trending_status', False) if sentiment_data else False,
                        trend_score=sentiment_data.get('trend_score') if sentiment_data else None,
                        data_quality_score=self._calculate_data_quality_score(stock, sentiment_data)
                    )
                    
                    unified_results.append(unified_stock)
                
                # ê´€ë ¨ë„ ì ìˆ˜ë¡œ ì •ë ¬
                unified_results.sort(key=lambda x: self._calculate_relevance_score(x, query.query), reverse=True)
            else:
                unified_results = []
            
            search_time = (datetime.utcnow() - start_time).total_seconds() * 1000
            
            result = SearchResult(
                query=query,
                results=unified_results,
                total_count=len(unified_results),
                search_time_ms=search_time,
                cache_hit=False
            )
            
            # ìºì‹œ ì €ì¥
            await self.cache_manager.set_search_results(query, unified_results)
            
            return result
            
        except Exception as e:
            raise UnifiedError(
                message=f"Error searching stocks: {str(e)}",
                category=ErrorCategory.DATA,
                severity=ErrorSeverity.HIGH,
                context={'query': query.query, 'filters': query.filters},
                original_error=e
            )
    
    @handle_errors(category=ErrorCategory.DATA, severity=ErrorSeverity.MEDIUM)
    async def get_trending_stocks(self, limit: int = 10, timeframe: str = "24h") -> List[UnifiedStockData]:
        """íŠ¸ë Œë”© ì£¼ì‹ ì¡°íšŒ"""
        cache_key = f"trending_{timeframe}_{limit}"
        
        # ìºì‹œ í™•ì¸
        cached_trending = await self.cache_manager.redis.get(cache_key)
        if cached_trending:
            try:
                data = json.loads(cached_trending)
                return [UnifiedStockData(**item) for item in data]
            except Exception:
                pass
        
        try:
            # ì„¼í‹°ë¨¼íŠ¸ ì„œë¹„ìŠ¤ì—ì„œ íŠ¸ë Œë”© ì£¼ì‹ ì¡°íšŒ
            trending_stocks = await self.sentiment_service.get_trending_stocks(limit, timeframe)
            
            # ì£¼ì‹ ì •ë³´ ë³‘í•© (ë³‘ë ¬ ì²˜ë¦¬)
            stock_tasks = [
                self.stock_service.get_stock_info(stock['symbol'])
                for stock in trending_stocks
            ]
            
            stock_results = await asyncio.gather(*stock_tasks, return_exceptions=True)
            
            # ê²°ê³¼ ë³‘í•©
            unified_results = []
            for i, trending_stock in enumerate(trending_stocks):
                stock_info = stock_results[i] if not isinstance(stock_results[i], Exception) else None
                
                if stock_info:
                    unified_stock = UnifiedStockData(
                        symbol=stock_info['symbol'],
                        company_name=stock_info['company_name'],
                        stock_type=StockType(stock_info.get('stock_type', 'EQUITY')),
                        exchange=stock_info['exchange'],
                        sector=stock_info.get('sector'),
                        industry=stock_info.get('industry'),
                        market_cap=stock_info.get('market_cap'),
                        current_price=stock_info.get('current_price'),
                        previous_close=stock_info.get('previous_close'),
                        volume=stock_info.get('volume'),
                        avg_volume=stock_info.get('avg_volume'),
                        pe_ratio=stock_info.get('pe_ratio'),
                        dividend_yield=stock_info.get('dividend_yield'),
                        beta=stock_info.get('beta'),
                        fifty_two_week_high=stock_info.get('fifty_two_week_high'),
                        fifty_two_week_low=stock_info.get('fifty_two_week_low'),
                        overall_sentiment=trending_stock.get('sentiment_score'),
                        mention_count_24h=trending_stock.get('mention_count_24h'),
                        trending_status=True,
                        trend_score=trending_stock.get('trend_score'),
                        data_quality_score=self._calculate_data_quality_score(stock_info, trending_stock)
                    )
                    
                    unified_results.append(unified_stock)
            
            # íŠ¸ë Œë“œ ì ìˆ˜ë¡œ ì •ë ¬
            unified_results.sort(key=lambda x: x.trend_score or 0, reverse=True)
            
            # ìºì‹œ ì €ì¥
            cache_data = [self._unified_stock_to_dict(stock) for stock in unified_results]
            await self.cache_manager.redis.setex(cache_key, 600, json.dumps(cache_data, default=str))
            
            return unified_results
            
        except Exception as e:
            raise UnifiedError(
                message=f"Error getting trending stocks: {str(e)}",
                category=ErrorCategory.DATA,
                severity=ErrorSeverity.HIGH,
                context={'limit': limit, 'timeframe': timeframe},
                original_error=e
            )
    
    def _parse_sentiment_sources(self, sentiment_data: Optional[Dict[str, Any]]) -> Dict[SentimentSource, float]:
        """ì„¼í‹°ë¨¼íŠ¸ ì†ŒìŠ¤ íŒŒì‹±"""
        if not sentiment_data:
            return {}
        
        sources = {}
        if 'reddit_sentiment' in sentiment_data:
            sources[SentimentSource.REDDIT] = sentiment_data['reddit_sentiment']
        if 'twitter_sentiment' in sentiment_data:
            sources[SentimentSource.TWITTER] = sentiment_data['twitter_sentiment']
        if 'discord_sentiment' in sentiment_data:
            sources[SentimentSource.DISCORD] = sentiment_data['discord_sentiment']
        
        return sources
    
    def _calculate_data_quality_score(self, stock_info: Dict[str, Any], sentiment_data: Optional[Dict[str, Any]]) -> float:
        """ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        score = 1.0
        
        # ì£¼ì‹ ë°ì´í„° í’ˆì§ˆ
        stock_fields = ['current_price', 'volume', 'market_cap']
        missing_stock_fields = sum(1 for field in stock_fields if not stock_info.get(field))
        score -= (missing_stock_fields * 0.2)
        
        # ì„¼í‹°ë¨¼íŠ¸ ë°ì´í„° í’ˆì§ˆ
        if sentiment_data:
            sentiment_fields = ['overall_sentiment', 'mention_count_24h']
            missing_sentiment_fields = sum(1 for field in sentiment_fields if field not in sentiment_data)
            score -= (missing_sentiment_fields * 0.1)
        else:
            score -= 0.2  # ì„¼í‹°ë¨¼íŠ¸ ë°ì´í„° ì—†ìŒ
        
        return max(0.0, min(1.0, score))
    
    def _calculate_relevance_score(self, stock: UnifiedStockData, query: str) -> float:
        """ê´€ë ¨ë„ ì ìˆ˜ ê³„ì‚°"""
        query = query.lower()
        symbol = stock.symbol.lower()
        name = stock.company_name.lower()
        
        score = 0.0
        
        # ì‹¬ë³¼ ì¼ì¹˜
        if symbol == query:
            score += 100
        elif symbol.startswith(query):
            score += 80
        elif query in symbol:
            score += 40
        
        # íšŒì‚¬ëª… ì¼ì¹˜
        if name.startswith(query):
            score += 60
        elif query in name:
            score += 20
        
        # íŠ¸ë Œë”© ë³´ë„ˆìŠ¤
        if stock.trending_status:
            score += stock.trend_score or 0
        
        # ì„¼í‹°ë¨¼íŠ¸ ë³´ë„ˆìŠ¤
        if stock.overall_sentiment and stock.overall_sentiment > 0.2:
            score += 10
        
        return score
    
    def _unified_stock_to_dict(self, stock: UnifiedStockData) -> Dict[str, Any]:
        """UnifiedStockDataë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            'symbol': stock.symbol,
            'company_name': stock.company_name,
            'stock_type': stock.stock_type.value,
            'exchange': stock.exchange,
            'sector': stock.sector,
            'industry': stock.industry,
            'market_cap': stock.market_cap,
            'current_price': stock.current_price,
            'previous_close': stock.previous_close,
            'day_change': stock.day_change,
            'day_change_pct': stock.day_change_pct,
            'volume': stock.volume,
            'avg_volume': stock.avg_volume,
            'pe_ratio': stock.pe_ratio,
            'dividend_yield': stock.dividend_yield,
            'beta': stock.beta,
            'fifty_two_week_high': stock.fifty_two_week_high,
            'fifty_two_week_low': stock.fifty_two_week_low,
            'overall_sentiment': stock.overall_sentiment,
            'sentiment_sources': {k.value: v for k, v in stock.sentiment_sources.items()},
            'mention_count_24h': stock.mention_count_24h,
            'trending_status': stock.trending_status,
            'trend_score': stock.trend_score,
            'last_updated': stock.last_updated.isoformat() if stock.last_updated else None,
            'data_quality_score': stock.data_quality_score
        }
    
    def _handle_data_error(self, error: UnifiedError):
        """ë°ì´í„° ì—ëŸ¬ í•¸ë“¤ëŸ¬"""
        # ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ì¡°ì • ë“± ì¶”ê°€ ì²˜ë¦¬
        pass
    
    def _handle_network_error(self, error: UnifiedError):
        """ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ í•¸ë“¤ëŸ¬"""
        # ì¬ì‹œë„ ë¡œì§ ë“± ì¶”ê°€ ì²˜ë¦¬
        pass
```

ì´ í†µí•© ê°œì„  ì „ëµì€ ì‹œìŠ¤í…œì˜ ê° êµ¬ì„± ìš”ì†Œë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í†µí•©í•˜ì—¬ ì¼ê´€ëœ ë°ì´í„° ëª¨ë¸, ìºì‹± ì „ëµ, ì—ëŸ¬ ì²˜ë¦¬ ë° API ë ˆì´ì–´ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì‚¬ìš©ìëŠ” í†µí•©ëœ ê²½í—˜ì„ ë°›ì„ ìˆ˜ ìˆìœ¼ë©°, ê°œë°œìëŠ” ìœ ì§€ë³´ìˆ˜ê°€ ìš©ì´í•œ ì½”ë“œë² ì´ìŠ¤ë¥¼ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## 12. Enhanced Stock Searchì™€ Social Sentiment Tracker í†µí•©

### 12.1 ë°œê²¬ëœ ë¬¸ì œì  ë° ê°œì„  ì‚¬í•­

#### 12.1.1 ìƒí˜¸ ì—°ë™ ë¶€ì¡±

**í˜„ì¬ ìƒí™©**
- Enhanced Stock Searchì™€ Social Sentiment Trackerê°€ ë…ë¦½ì ìœ¼ë¡œ ì„¤ê³„ë¨
- ë‘ ì‹œìŠ¤í…œ ê°„ ë°ì´í„° ê³µìœ  ë° ì—°ë™ ë©”ì»¤ë‹ˆì¦˜ ë¶€ì¬

**ê°œì„  ë°©ì•ˆ**
1. **í†µí•© ê²€ìƒ‰ ê²°ê³¼**: ê²€ìƒ‰ ì‹œ ì„¼í‹°ë¨¼íŠ¸ ì ìˆ˜ë„ í•¨ê»˜ í‘œì‹œ
2. **ì„¼í‹°ë¨¼íŠ¸ ê¸°ë°˜ ê²€ìƒ‰**: íŠ¸ë Œë”© ì£¼ì‹ì„ ê²€ìƒ‰ ì œì•ˆì— ìš°ì„  í‘œì‹œ
3. **ê´€ì‹¬ì¢…ëª© ì—°ë™**: ê´€ì‹¬ì¢…ëª©ì— ì‹¤ì‹œê°„ ì„¼í‹°ë¨¼íŠ¸ ìƒíƒœ í‘œì‹œ

#### 12.1.2 ë°ì´í„° ëª¨ë¸ í†µí•© í•„ìš”

**ê¸°ì¡´ ë¶„ë¦¬ëœ ëª¨ë¸**
```python
# Enhanced Search
@dataclass
class StockResult:
    symbol: str
    company_name: str
    stock_type: str
    exchange: str
    sector: str
    industry: str
    market_cap: Optional[float]
    current_price: Optional[float]
    relevance_score: float = 0.0

# Social Sentiment
@dataclass
class StockMention:
    symbol: str
    text: str
    source: str
    community: str
    author: str
    timestamp: datetime
    upvotes: int
    sentiment_score: float
    investment_style: str
```

**ê°œì„ ëœ í†µí•© ëª¨ë¸**
```python
@dataclass
class UnifiedStockData:
    # ê¸°ë³¸ ì •ë³´
    symbol: str
    company_name: str
    stock_type: str
    exchange: str
    sector: str
    industry: str
    
    # ê°€ê²© ì •ë³´
    current_price: Optional[float]
    market_cap: Optional[float]
    
    # ê²€ìƒ‰ ê´€ë ¨
    relevance_score: float = 0.0
    search_count: int = 0
    
    # ì„¼í‹°ë¨¼íŠ¸ ê´€ë ¨
    sentiment_score: Optional[float] = None
    mention_count_24h: int = 0
    trending_status: bool = False
    trend_score: Optional[float] = None
    
    # ë©”íƒ€ë°ì´í„°
    last_updated: datetime
    data_sources: List[str]
```

#### 12.1.3 í†µí•© ï¿½ì‹± ì‹œìŠ¤í…œ

**í˜„ì¬ ìƒí™©**
- Enhanced Search: SearchCache (TTL 5ë¶„, ìµœëŒ€ 1000ê°œ)
- Social Sentiment: SentimentCache (TTL 5ë¶„)

**ê°œì„ ëœ í†µí•© ìºì‹œ**
```python
class UnifiedCache:
    def __init__(self):
        self.stock_data_cache = {}  # ê¸°ë³¸ ì£¼ì‹ ì •ë³´
        self.sentiment_cache = {}   # ì„¼í‹°ë¨¼íŠ¸ ë°ì´í„°
        self.search_cache = {}      # ê²€ìƒ‰ ê²°ê³¼
        
    def get_stock_with_sentiment(self, symbol: str) -> UnifiedStockData
    def update_sentiment_data(self, symbol: str, sentiment_data: SentimentData)
    def invalidate_related_caches(self, symbol: str)
```

#### 12.1.4 UI/UX í†µí•© ê°œì„ 

**í˜„ì¬ ìƒí™©**
- ê²€ìƒ‰ UIì™€ ì„¼í‹°ë¨¼íŠ¸ UIê°€ ë¶„ë¦¬ë¨
- ì¼ê´€ì„± ì—†ëŠ” ë””ìì¸ íŒ¨í„´

**ê°œì„ ëœ í†µí•© UI**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ” Smart Search                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [ê²€ìƒ‰ì°½ with ìë™ì™„ì„±]                    ğŸ”¥ Trending   â”‚
â”‚                                                         â”‚
â”‚ ğŸ“Š Search Results                                       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ AAPL - Apple Inc.           ğŸ“ˆ +2.5%  ğŸ’­ +65       â”‚ â”‚
â”‚ â”‚ NASDAQ â€¢ Technology         $150.25   ğŸ“Š 1,247     â”‚ â”‚
â”‚ â”‚ [View Chart] [Add to Watchlist] [Sentiment Detail] â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 12.2 API í˜¸ì¶œ ìµœì í™”

```python
class UnifiedDataService:
    async def get_stock_with_all_data(self, symbol: str) -> UnifiedStockData:
        # ë³‘ë ¬ë¡œ ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘
        stock_info, sentiment_data = await asyncio.gather(
            self.get_stock_info(symbol),
            self.get_sentiment_data(symbol)
        )
        return self.merge_data(stock_info, sentiment_data)
```

### 12.3 ì¶”ê°€ ëˆ„ë½ ê¸°ëŠ¥

#### Enhanced Search ë³´ì™„
1. **ì„¼í‹°ë¨¼íŠ¸ ê¸°ë°˜ í•„í„°ë§**: ê¸ì •/ë¶€ì • ì„¼í‹°ë¨¼íŠ¸ë¡œ ê²€ìƒ‰ ê²°ê³¼ í•„í„°ë§
2. **íŠ¸ë Œë”© ì•Œë¦¼**: ê´€ì‹¬ì¢…ëª©ì´ íŠ¸ë Œë”©ë  ë•Œ ì•Œë¦¼
3. **ì†Œì…œ ì¸ê¸°ë„ ì •ë ¬**: ì–¸ê¸‰ëŸ‰ ê¸°ì¤€ ê²€ìƒ‰ ê²°ê³¼ ì •ë ¬

#### Social Sentiment ë³´ì™„
1. **ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ ì—°ë™**: ìì£¼ ê²€ìƒ‰í•œ ì£¼ì‹ì˜ ì„¼í‹°ë¨¼íŠ¸ ìš°ì„  í‘œì‹œ
2. **ê´€ì‹¬ì¢…ëª© ì„¼í‹°ë¨¼íŠ¸**: ê´€ì‹¬ì¢…ëª©ì˜ ì„¼í‹°ë¨¼íŠ¸ ë³€í™” ì¶”ì 
3. **ìŠ¤ë§ˆíŠ¸ ì•Œë¦¼**: ê´€ì‹¬ì¢…ëª©ì˜ ì„¼í‹°ë¨¼íŠ¸ ê¸‰ë³€ ì‹œ ì•Œë¦¼

### 12.4 í†µí•© ì—ëŸ¬ ì²˜ë¦¬

**í˜„ì¬ ìƒí™©**
- ê° ì‹œìŠ¤í…œë³„ ë…ë¦½ì ì¸ ì—ëŸ¬ ì²˜ë¦¬
- ì¼ê´€ì„± ì—†ëŠ” ì—ëŸ¬ ë©”ì‹œì§€

**ê°œì„ ëœ í†µí•© ì—ëŸ¬ ì²˜ë¦¬**
```python
class UnifiedErrorHandler:
    def handle_api_error(self, error: Exception, service: str) -> ErrorResponse
    def get_fallback_data(self, symbol: str, failed_services: List[str]) -> PartialData
    def show_user_friendly_message(self, error_type: str) -> str
```

### 12.5 êµ¬í˜„ ìš°ì„ ìˆœìœ„

#### Phase 1: ë°ì´í„° ëª¨ë¸ í†µí•© (Week 1)
1. UnifiedStockData ëª¨ë¸ ì •ì˜
2. í†µí•© ìºì‹± ì‹œìŠ¤í…œ êµ¬í˜„
3. ë°ì´í„° ë³€í™˜ ë ˆì´ì–´ êµ¬í˜„

#### Phase 2: ê¸°ë³¸ ì—°ë™ (Week 2)
1. ê²€ìƒ‰ ê²°ê³¼ì— ì„¼í‹°ë¨¼íŠ¸ ì •ë³´ ì¶”ê°€
2. ê´€ì‹¬ì¢…ëª©ì— ì„¼í‹°ë¨¼íŠ¸ ìƒíƒœ í‘œì‹œ
3. ê¸°ë³¸ UI í†µí•©

#### Phase 3: ê³ ê¸‰ ê¸°ëŠ¥ (Week 3)
1. ì„¼í‹°ë¨¼íŠ¸ ê¸°ë°˜ ê²€ìƒ‰ í•„í„°ë§
2. íŠ¸ë Œë”© ê¸°ë°˜ ê²€ìƒ‰ ì œì•ˆ
3. í†µí•© ì•Œë¦¼ ì‹œìŠ¤í…œ

#### Phase 4: ìµœì í™” ë° ì™„ì„± (Week 4)
1. ì„±ëŠ¥ ìµœì í™”
2. ì—ëŸ¬ ì²˜ë¦¬ í†µí•©
3. ì‚¬ìš©ì ê²½í—˜ ê°œì„ 

### 12.6 ìˆ˜ì •ì´ í•„ìš”í•œ ê¸°ì¡´ Spec í•­ëª©

#### Enhanced Stock Search ìˆ˜ì •ì‚¬í•­
1. **Requirements ì¶”ê°€**: ì„¼í‹°ë¨¼íŠ¸ ë°ì´í„° í†µí•© ìš”êµ¬ì‚¬í•­
2. **Design ìˆ˜ì •**: í†µí•© ë°ì´í„° ëª¨ë¸ ë° ìºì‹± ì‹œìŠ¤í…œ
3. **Tasks ì¶”ê°€**: ì„¼í‹°ë¨¼íŠ¸ ì—°ë™ ê´€ë ¨ ì‘ì—…

#### Social Sentiment Tracker ìˆ˜ì •ì‚¬í•­
1. **Requirements ì¶”ê°€**: ê²€ìƒ‰ ì‹œìŠ¤í…œ ì—°ë™ ìš”êµ¬ì‚¬í•­
2. **Design ìˆ˜ì •**: í†µí•© ì•„í‚¤í…ì²˜ ë° ë°ì´í„° ê³µìœ 
3. **Tasks ì¶”ê°€**: ê²€ìƒ‰ ì‹œìŠ¤í…œ ì—°ë™ ì‘ì—…

### 12.7 ê²°ë¡ 

ë‘ specì„ í†µí•©í•˜ì—¬ ë” ê°•ë ¥í•˜ê³  ì¼ê´€ëœ ì‚¬ìš©ì ê²½í—˜ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ ê²€ìƒ‰ê³¼ ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„ì˜ ì‹œë„ˆì§€ íš¨ê³¼ë¥¼ í†µí•´ apewisdom.ioë³´ë‹¤ ë” ë‚˜ì€ ê¸°ëŠ¥ì„ êµ¬í˜„í•  ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.

## 13. ì•„í‚¤í…ì²˜ ê²°ì • ê¸°ë¡ (ADR)

### ADR-001: ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ ì„ íƒ

**ìƒíƒœ**: ìˆ˜ë½ë¨

**ê²°ì •**: ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ë¥¼ ì±„íƒí•˜ì—¬ ê° ê¸°ëŠ¥ì„ ë…ë¦½ì ì¸ ì„œë¹„ìŠ¤ë¡œ ë¶„ë¦¬

**ê·¼ê±°**:
- ë…ë¦½ì ì¸ í™•ì¥ì„±: ê° ì„œë¹„ìŠ¤ë¥¼ ë…ë¦½ì ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥
- ê¸°ìˆ ì  ìœ ì—°ì„±: ì„œë¹„ìŠ¤ë³„ë¡œ ì í•©í•œ ê¸°ìˆ  ìŠ¤íƒ ì„ íƒ ê°€ëŠ¥
- ì¥ì•  ê²©ë¦¬: í•œ ì„œë¹„ìŠ¤ì˜ ì¥ì• ê°€ ì „ì²´ ì‹œìŠ¤í…œì— ì˜í–¥ì„ ìµœì†Œí™”
- íŒ€ ììœ¨ì„±: ê° íŒ€ì´ ë…ë¦½ì ìœ¼ë¡œ ì„œë¹„ìŠ¤ ê°œë°œ ë° ë°°í¬ ê°€ëŠ¥

**ê²°ê³¼**:
- ì´ˆê¸° ê°œë°œ ë³µì¡ì„± ì¦ê°€
- ì¥ê¸°ì ìœ¼ë¡œëŠ” ìœ ì§€ë³´ìˆ˜ ë° í™•ì¥ì„± í–¥ìƒ
- ì„œë¹„ìŠ¤ ê°„ í†µì‹  ì˜¤ë²„í—¤ë“œ ë°œìƒ

### ADR-002: API Gateway íŒ¨í„´ ë„ì…

**ìƒíƒœ**: ìˆ˜ë½ë¨

**ê²°ì •**: API Gatewayë¥¼ ë„ì…í•˜ì—¬ ì™¸ë¶€ ìš”ì²­ì„ ì¤‘ì•™ì—ì„œ ì²˜ë¦¬

**ê·¼ê±°**:
- ë³´ì•ˆ: ì¸ì¦ ë° ì¸ê°€ë¥¼ ì¤‘ì•™ì—ì„œ ì²˜ë¦¬
- ë¼ìš°íŒ…: ìš”ì²­ì„ ì ì ˆí•œ ì„œë¹„ìŠ¤ë¡œ ë¼ìš°íŒ…
- ëª¨ë‹ˆí„°ë§: ëª¨ë“  API ìš”ì²­ì„ ì¤‘ì•™ì—ì„œ ëª¨ë‹ˆí„°ë§
- ì†ë„ ì œí•œ: ì„œë¹„ìŠ¤ ë³´í˜¸ë¥¼ ìœ„í•œ ì†ë„ ì œí•œ

**ê²°ê³¼**:
- ë‹¨ì¼ ì¥ì• ì  ê°€ëŠ¥ì„± ì¦ê°€
- ë³µì¡ì„± ì¦ê°€
- ì¼ê´€ëœ API ê´€ë¦¬ ë° ë³´ì•ˆ ê°•í™”

### ADR-003: ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ ë„ì…

**ìƒíƒœ**: ìˆ˜ë½ë¨

**ê²°ì •**: ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ë¥¼ ë„ì…í•˜ì—¬ ì„œë¹„ìŠ¤ ê°„ ëŠìŠ¨í•œ ê²°í•© êµ¬í˜„

**ê·¼ê±°**:
- í™•ì¥ì„±: ì´ë²¤íŠ¸ ì†Œë¹„ìë¥¼ ë…ë¦½ì ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥
- ë‚´ê²°í•¨ì„±: ì´ë²¤íŠ¸ íë¥¼ í†µí•œ ë©”ì‹œì§€ ë³´ì¥
- ë¹„ë™ê¸° ì²˜ë¦¬: ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ì‘ì—…ì„ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬
- ì„œë¹„ìŠ¤ ë¶„ë¦¬: ì„œë¹„ìŠ¤ ê°„ ì§ì ‘ ì˜ì¡´ì„± ê°ì†Œ

**ê²°ê³¼**:
- ë³µì¡ì„± ì¦ê°€
- ë””ë²„ê¹… ì–´ë ¤ì›€
- ë†’ì€ í™•ì¥ì„± ë° ë‚´ê²°í•¨ì„± í™•ë³´

### ADR-004: Enhanced Stock Searchì™€ Social Sentiment Tracker í†µí•©

**ìƒíƒœ**: ìˆ˜ë½ë¨

**ê²°ì •**: ë‘ ì‹œìŠ¤í…œì„ í†µí•©í•˜ì—¬ ì‹œë„ˆì§€ íš¨ê³¼ë¥¼ ê·¹ëŒ€í™”

**ê·¼ê±°**:
- ì‚¬ìš©ì ê²½í—˜: ê²€ìƒ‰ê³¼ ì„¼í‹°ë¨¼íŠ¸ ì •ë³´ì˜ ìì—°ìŠ¤ëŸ¬ìš´ í†µí•©
- ë°ì´í„° ê°€ì¹˜: ì£¼ì‹ ì •ë³´ì™€ ì†Œì…œ ë°ì´í„°ì˜ ê²°í•©ìœ¼ë¡œ ë” ë†’ì€ ê°€ì¹˜ ì°½ì¶œ
- ê²½ìŸ ìš°ìœ„: apewisdom.ioë³´ë‹¤ í†µí•©ëœ ê²½í—˜ ì œê³µ
- ê°œë°œ íš¨ìœ¨: ì¤‘ë³µ ê¸°ëŠ¥ ì œê±° ë° ê³µìœ  ì»´í¬ë„ŒíŠ¸ í™œìš©

**ê²°ê³¼**:
- ì´ˆê¸° í†µí•© ë³µì¡ì„± ì¦ê°€
- ì¼ê´€ëœ ì‚¬ìš©ì ê²½í—˜ ì œê³µ
- ë°ì´í„° ëª¨ë¸ ë° API í†µí•© í•„ìš”
- ì¥ê¸°ì ìœ¼ë¡œëŠ” ìœ ì§€ë³´ìˆ˜ ë° í™•ì¥ì„± í–¥ìƒ

### ADR-005: í†µí•© ë°ì´í„° ëª¨ë¸ ë„ì…

**ìƒíƒœ**: ìˆ˜ë½ë¨

**ê²°ì •**: UnifiedStockData ëª¨ë¸ì„ ë„ì…í•˜ì—¬ ì£¼ì‹ ì •ë³´ì™€ ì„¼í‹°ë¨¼íŠ¸ ë°ì´í„° í†µí•©

**ê·¼ê±°**:
- ë°ì´í„° ì¼ê´€ì„±: ë‹¨ì¼ ë°ì´í„° ëª¨ë¸ë¡œ ì¼ê´€ëœ ì •ë³´ ì œê³µ
- ê°œë°œ íš¨ìœ¨: ì¤‘ë³µ ë°ì´í„° êµ¬ì¡° ì œê±°
- ìºì‹± íš¨ìœ¨: í†µí•©ëœ ë°ì´í„° ìºì‹±ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ
- API ë‹¨ìˆœí™”: í†µí•©ëœ ì—”ë“œí¬ì¸íŠ¸ë¡œ ë‹¨ìˆœí™”ëœ API ì œê³µ

**ê²°ê³¼**:
- ì´ˆê¸° ë°ì´í„° ëª¨ë¸ë§ ë³µì¡ì„± ì¦ê°€
- ì¥ê¸°ì ìœ¼ë¡œëŠ” ë°ì´í„° ì¼ê´€ì„± ë° ê°œë°œ íš¨ìœ¨ í–¥ìƒ
- ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ì˜ í˜¸í™˜ì„± ê³ ë ¤ í•„ìš”

### ADR-006: í†µí•© ìºì‹± ì „ëµ ë„ì…

**ìƒíƒœ**: ìˆ˜ë½ë¨

**ê²°ì •**: UnifiedCacheManagerë¥¼ ë„ì…í•˜ì—¬ ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ì˜ ìºì‹± í†µí•© ê´€ë¦¬

**ê·¼ê±°**:
- ì„±ëŠ¥ ìµœì í™”: í†µí•©ëœ ìºì‹±ìœ¼ë¡œ ì¤‘ë³µ ë°ì´í„° ì¡°íšŒ ë°©ì§€
- ë©”ëª¨ë¦¬ íš¨ìœ¨: ìºì‹œ ê³µê°„ íš¨ìœ¨ì  ì‚¬ìš©
- ë°ì´í„° ì¼ê´€ì„±: ê´€ë ¨ ë°ì´í„°ì˜ ë™ê¸°í™”ëœ ìºì‹±
- ìš´ì˜ ìš©ì´ì„±: ë‹¨ì¼ ìºì‹œ ê´€ë¦¬ í¬ì¸íŠ¸

**ê²°ê³¼**:
- ê¸°ì¡´ ì‹œìŠ¤í…œ ë³µì¡ì„± ì¦ê°€
- ì „ì²´ì ì¸ ì‹œìŠ¤í…œ ì„±ëŠ¥ í–¥ìƒ
- ìºì‹œ ë¬´íš¨í™” ë¡œì§ ë³µì¡í™”

### ADR-007: í†µí•© ì—ëŸ¬ ì²˜ë¦¬ ë„ì…

**ìƒíƒœ**: ìˆ˜ë½ë¨

**ê²°ì •**: UnifiedErrorHandlerë¥¼ ë„ì…í•˜ì—¬ ëª¨ë“  ì„œë¹„ìŠ¤ì˜ ì—ëŸ¬ ì²˜ë¦¬ í†µí•©

**ê·¼ê±°**:
- ì¼ê´€ëœ ì—ëŸ¬ ì²˜ë¦¬: ì‚¬ìš©ìì—ê²Œ ì¼ê´€ëœ ì—ëŸ¬ ë©”ì‹œì§€ ì œê³µ
- ì¤‘ì•™í™”ëœ ëª¨ë‹ˆí„°ë§: ëª¨ë“  ì—ëŸ¬ë¥¼ ì¤‘ì•™ì—ì„œ ìˆ˜ì§‘ ë° ë¶„ì„
- ì¥ì•  ëŒ€ì‘: ì²´ê³„ì ì¸ ì—ëŸ¬ ë¶„ë¥˜ ë° ëŒ€ì‘ ì „ëµ
- ê°œë°œ íš¨ìœ¨: ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì—ëŸ¬ ì²˜ë¦¬ ì»´í¬ë„ŒíŠ¸

**ê²°ê³¼**:
- ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ ë³µì¡ì„± ì¦ê°€
- ì´ˆê¸° ê°œë°œ ë¹„ìš© ì¦ê°€
- ì¥ê¸°ì ìœ¼ë¡œëŠ” ì•ˆì •ì„± ë° ìš´ì˜ íš¨ìœ¨ í–¥ìƒ