# êµ¬í˜„ ê³„íš

## 1. í”„ë¡œì íŠ¸ ë¡œë“œë§µ

### 1.1 ê°œë°œ ë‹¨ê³„ ê³„íš

```mermaid
gantt
    title InsiteChart í”„ë¡œì íŠ¸ ë¡œë“œë§µ
    dateFormat  YYYY-MM-DD
    section 1ë‹¨ê³„: ê¸°ë°˜ êµ¬ì¶•
    í”„ë¡œì íŠ¸ ì„¤ì •           :done, setup, 2024-01-01, 2024-01-07
    ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„       :done, db-design, 2024-01-08, 2024-01-21
    API ì•„í‚¤í…ì²˜ êµ¬ì¶•    :done, api-arch, 2024-01-15, 2024-01-28
    ê¸°ë³¸ UI í”„ë ˆì„ì›Œí¬    :done, ui-framework, 2024-01-22, 2024-02-04
    
    section 2ë‹¨ê³„: í•µì‹¬ ê¸°ëŠ¥
    ì£¼ì‹ ê²€ìƒ‰ ì—”ì§„       :active, stock-search, 2024-01-29, 2024-02-25
    ë°ì´í„° ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ :data-pipeline, after stock-search, 2024-02-05, 2024-03-04
    ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„        :sentiment, after data-pipeline, 2024-02-19, 2024-03-18
    ì‚¬ìš©ì ì¸ì¦ ì‹œìŠ¤í…œ    :auth, after stock-search, 2024-02-12, 2024-03-11
    
    section 3ë‹¨ê³„: ê³ ê¸‰ ê¸°ëŠ¥
    ì‹¤ì‹œê°„ ì•Œë¦¼          :realtime, 2024-03-11, 2024-04-08
    í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬       :portfolio, after sentiment, 2024-03-25, 2024-04-22
    ê³ ê¸‰ ë¶„ì„ ë„êµ¬        :analytics, after portfolio, 2024-04-01, 2024-04-29
    ëª¨ë°”ì¼ ì•±              :mobile, after analytics, 2024-04-15, 2024-05-27
    
    section 4ë‹¨ê³„: ìµœì í™”
    ì„±ëŠ¥ ìµœì í™”           :perf-opt, after mobile, 2024-05-13, 2024-06-10
    ë³´ì•ˆ ê°•í™”              :security, after perf-opt, 2024-05-20, 2024-06-17
    ì ‘ê·¼ì„± ê°œì„            :a11y, after security, 2024-06-03, 2024-06-24
    í…ŒìŠ¤íŠ¸ ìë™í™”          :testing, after a11y, 2024-06-10, 2024-07-01
    
    section 5ë‹¨ê³„: ë°°í¬
    ë² íƒ€ ë°°í¬              :beta, after testing, 2024-06-24, 2024-07-15
    ì‚¬ìš©ì í…ŒìŠ¤íŠ¸           :user-testing, after beta, 2024-07-08, 2024-07-22
    í”„ë¡œë•ì…˜ ë°°í¬          :production, after user-testing, 2024-07-16, 2024-07-29
    ëª¨ë‹ˆí„°ë§ ì„¤ì •           :monitoring, after production, 2024-07-23, 2024-08-05
```

### 1.2 ë§ˆì¼ìŠ¤í†¤ ì •ì˜

#### 1.2.1 ê¸°ìˆ ì  ë§ˆì¼ìŠ¤í†¤
- **MVP (Minimum Viable Product)**: ê¸°ë³¸ ì£¼ì‹ ê²€ìƒ‰ ë° ê°„ë‹¨í•œ ì„¼í‹°ë¨¼íŠ¸ í‘œì‹œ
- **Alpha ë²„ì „**: ì „ì²´ ê¸°ëŠ¥ êµ¬í˜„, ë‚´ë¶€ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
- **Beta ë²„ì „**: ì™¸ë¶€ í…ŒìŠ¤í„° ëŒ€ìƒ, ì•ˆì •ì„± í™•ë³´
- **ì •ì‹ ë²„ì „**: í”„ë¡œë•ì…˜ í™˜ê²½ ë°°í¬, ì¼ë°˜ ì‚¬ìš©ì ëŒ€ìƒ

#### 1.2.2 ë¹„ì¦ˆë‹ˆìŠ¤ ë§ˆì¼ìŠ¤í†¤
- **ì‚¬ìš©ì 100ëª… ë‹¬ì„±**: ì´ˆê¸° ì‚¬ìš©ì í™•ë³´
- **ë°ì´í„° ì†ŒìŠ¤ 5ê°œ ì—°ë™**: ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ í†µí•©
- **ì‹¤ì‹œê°„ ì²˜ë¦¬ 1,000 TPS**: ì‹œìŠ¤í…œ ì„±ëŠ¥ ëª©í‘œ ë‹¬ì„±
- **ëª¨ë°”ì¼ ì•± ì¶œì‹œ**: ëª¨ë°”ì¼ í”Œë«í¼ ì§€ì›

## 2. ê°œë°œ íŒ€ êµ¬ì„±

### 2.1 íŒ€ ì—­í•  ë° ì±…ì„

```typescript
// team/organization.ts
export interface TeamMember {
  id: string;
  name: string;
  role: TeamRole;
  responsibilities: string[];
  skills: string[];
  experience: number;
}

export type TeamRole = 
  | 'project-manager'
  | 'frontend-lead'
  | 'backend-lead'
  | 'fullstack-developer'
  | 'ui-ux-designer'
  | 'data-scientist'
  | 'devops-engineer'
  | 'qa-engineer'
  | 'security-specialist';

export const teamStructure: TeamMember[] = [
  {
    id: 'pm-001',
    name: 'ê¹€í”„ë¡œì íŠ¸',
    role: 'project-manager',
    responsibilities: [
      'í”„ë¡œì íŠ¸ ì¼ì • ê´€ë¦¬',
      'íŒ€ ê°„ ì¡°ìœ¨',
      'ì´í•´ê´€ê³„ì ì»¤ë®¤ë‹ˆì¼€ì´ì…˜',
      'ìœ„í—˜ ê´€ë¦¬'
    ],
    skills: ['Agile', 'Scrum', 'JIRA', 'Risk Management'],
    experience: 8
  },
  {
    id: 'fe-001',
    name: 'ì´í”„ë¡ íŠ¸',
    role: 'frontend-lead',
    responsibilities: [
      'í”„ë¡ íŠ¸ì—”ë“œ ì•„í‚¤í…ì²˜ ì„¤ê³„',
      'UI ì»´í¬ë„ŒíŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°œë°œ',
      'ë°˜ì‘í˜• ë””ìì¸ êµ¬í˜„',
      'í”„ë¡ íŠ¸ì—”ë“œ íŒ€ ë©¤ë²„ ê´€ë¦¬'
    ],
    skills: ['React', 'TypeScript', 'CSS-in-JS', 'Accessibility'],
    experience: 6
  },
  {
    id: 'be-001',
    name: 'ë°±ë°±ì—”ë“œ',
    role: 'backend-lead',
    responsibilities: [
      'ë°±ì—”ë“œ ì•„í‚¤í…ì²˜ ì„¤ê³„',
      'API ê°œë°œ ë° ë¬¸ì„œí™”',
      'ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„',
      'ë°±ì—”ë“œ íŒ€ ë©¤ë²„ ê´€ë¦¬'
    ],
    skills: ['Python', 'FastAPI', 'PostgreSQL', 'Redis', 'Docker'],
    experience: 7
  },
  {
    id: 'fs-001',
    name: 'ìµœí’€ìŠ¤íƒ',
    role: 'fullstack-developer',
    responsibilities: [
      'ì£¼ì‹ ê²€ìƒ‰ ê¸°ëŠ¥ ê°œë°œ',
      'ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„ API ê°œë°œ',
      'ì‚¬ìš©ì ì¸ì¦ ì‹œìŠ¤í…œ êµ¬í˜„',
      'í”„ë¡ íŠ¸ì—”ë“œ-ë°±ì—”ë“œ ì—°ë™'
    ],
    skills: ['React', 'Python', 'PostgreSQL', 'REST API'],
    experience: 4
  },
  {
    id: 'ux-001',
    name: 'ë””UXë””ìì´ë„ˆ',
    role: 'ui-ux-designer',
    responsibilities: [
      'ì‚¬ìš©ì ê²½í—˜ ì„¤ê³„',
      'UI/UX ë””ìì¸',
      'í”„ë¡œí† íƒ€ì´í•‘',
      'ë””ìì¸ ì‹œìŠ¤í…œ êµ¬ì¶•'
    ],
    skills: ['Figma', 'Adobe XD', 'Prototyping', 'User Research'],
    experience: 5
  },
  {
    id: 'ds-001',
    name: 'ë°ì´í„°ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸',
    role: 'data-scientist',
    responsibilities: [
      'ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„ ì•Œê³ ë¦¬ì¦˜ ê°œë°œ',
      'ë°ì´í„° ëª¨ë¸ë§',
      'ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•',
      'ë¶„ì„ ê²°ê³¼ ì‹œê°í™”'
    ],
    skills: ['Python', 'NLP', 'Machine Learning', 'Data Analysis'],
    experience: 6
  },
  {
    id: 'devops-001',
    name: 'ë°ë¸Œì˜µìŠ¤ì—”ì§€ë‹ˆì–´',
    role: 'devops-engineer',
    responsibilities: [
      'CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶•',
      'ì¸í”„ë¼ ìë™í™”',
      'ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•',
      'ë°°í¬ ë° ìš´ì˜'
    ],
    skills: ['Docker', 'Kubernetes', 'AWS', 'CI/CD', 'Monitoring'],
    experience: 5
  },
  {
    id: 'qa-001',
    name: 'QAì—”ì§€ë‹ˆì–´',
    role: 'qa-engineer',
    responsibilities: [
      'í…ŒìŠ¤íŠ¸ ê³„íš ìˆ˜ë¦½',
      'ìë™í™” í…ŒìŠ¤íŠ¸ êµ¬ì¶•',
      'ê²°í•¨ ê´€ë¦¬',
      'í’ˆì§ˆ ë³´ì¦'
    ],
    skills: ['Selenium', 'Cypress', 'Test Automation', 'Agile Testing'],
    experience: 4
  },
  {
    id: 'sec-001',
    name: 'ë³´ì•ˆì „ë¬¸ê°€',
    role: 'security-specialist',
    responsibilities: [
      'ë³´ì•ˆ ì•„í‚¤í…ì²˜ ì„¤ê³„',
      'ì·¨ì•½ì  ë¶„ì„',
      'ë³´ì•ˆ ì •ì±… ìˆ˜ë¦½',
      'ë³´ì•ˆ ê°ì‚¬'
    ],
    skills: ['OWASP', 'Penetration Testing', 'Security Auditing', 'Cryptography'],
    experience: 6
  }
];

// íŒ€ í˜‘ì—… ë°©ì‹
export const collaborationMethods = {
  dailyStandup: {
    time: '09:30',
    duration: 15,
    participants: ['project-manager', 'frontend-lead', 'backend-lead'],
    agenda: [
      'ì–´ì œ ì‘ì—… í˜„í™© ê³µìœ ',
      'ì˜¤ëŠ˜ ì‘ì—… ê³„íš',
      'ì¥ì• /ì´ìŠˆ ë…¼ì˜'
    ]
  },
  weeklySprint: {
    day: 'ì›”ìš”ì¼',
    time: '10:00',
    duration: 60,
    participants: 'all',
    agenda: [
      'ì§€ë‚œ ìŠ¤í”„ë¦°íŠ¸ íšŒê³ ',
      'ìƒˆ ìŠ¤í”„ë¦°íŠ¸ ê³„íš',
      'ë°±ë¡œê·¸ ì •ë¦¬',
      'íŒ€ë³„ ëª©í‘œ ì„¤ì •'
    ]
  },
  biweeklyDemo: {
    day: 'ê¸ˆìš”ì¼',
    time: '16:00',
    duration: 90,
    participants: 'all',
    agenda: [
      'ìµœì‹  ê¸°ëŠ¥ ì‹œì—°',
      'ì‚¬ìš©ì í”¼ë“œë°± ë…¼ì˜',
      'ê¸°ìˆ ì  ë„ì „ ê³¼ì œ ê³µìœ ',
      'ë‹¤ìŒ ìŠ¤í”„ë¦°íŠ¸ ëª©í‘œ ì¡°ì •'
    ]
  }
};
```

### 2.2 ê°œë°œ ë°©ë²•ë¡ 

#### 2.2.1 ì• ìì¼ ê°œë°œ í”„ë¡œì„¸ìŠ¤
```typescript
// development/agileProcess.ts
export interface Sprint {
  id: string;
  name: string;
  startDate: Date;
  endDate: Date;
  duration: number; // days
  goals: string[];
  backlog: UserStory[];
  team: string[];
}

export interface UserStory {
  id: string;
  title: string;
  description: string;
  acceptanceCriteria: string[];
  storyPoints: number;
  priority: 'low' | 'medium' | 'high' | 'critical';
  status: 'backlog' | 'in-progress' | 'testing' | 'done';
  assignee?: string;
  dependencies: string[];
}

export interface Epic {
  id: string;
  name: string;
  description: string;
  stories: string[];
  priority: number;
}

// ìŠ¤í”„ë¦°íŠ¸ ê³„íš ì˜ˆì‹œ
export const sprintPlan: Sprint = {
  id: 'sprint-001',
  name: '1ì£¼ì°¨: ê¸°ë°˜ êµ¬ì¶•',
  startDate: new Date('2024-01-29'),
  endDate: new Date('2024-02-09'),
  duration: 10,
  goals: [
    'í”„ë¡œì íŠ¸ ê¸°ë°˜ í™˜ê²½ êµ¬ì¶•',
    'ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì„¤ê³„',
    'ê¸°ë³¸ API ì—”ë“œí¬ì¸íŠ¸ ê°œë°œ',
    'UI í”„ë ˆì„ì›Œí¬ ì„¤ì •'
  ],
  backlog: [
    {
      id: 'story-001',
      title: 'ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì„¤ê³„',
      description: 'ì£¼ì‹, ì„¼í‹°ë¨¼íŠ¸, ì‚¬ìš©ì ë°ì´í„°ë¥¼ ì €ì¥í•  ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì„¤ê³„',
      acceptanceCriteria: [
        'ì£¼ì‹ ì •ë³´ ì €ì¥ì„ ìœ„í•œ í…Œì´ë¸” ì„¤ê³„',
        'ì„¼í‹°ë¨¼íŠ¸ ë°ì´í„° ì €ì¥ì„ ìœ„í•œ í…Œì´ë¸” ì„¤ê³„',
        'ì‚¬ìš©ì ì •ë³´ ì €ì¥ì„ ìœ„í•œ í…Œì´ë¸” ì„¤ê³„',
        'í…Œì´ë¸” ê°„ ê´€ê³„ ì •ì˜',
        'ì¸ë±ìŠ¤ ì„¤ê³„'
      ],
      storyPoints: 8,
      priority: 'critical',
      status: 'backlog',
      dependencies: []
    },
    {
      id: 'story-002',
      title: 'API ê¸°ë³¸ êµ¬ì¡° ì„¤ê³„',
      description: 'RESTful API ê¸°ë³¸ êµ¬ì¡°ì™€ ê³µí†µ ì»´í¬ë„ŒíŠ¸ ì„¤ê³„',
      acceptanceCriteria: [
        'API ë¼ìš°íŒ… êµ¬ì¡° ì„¤ê³„',
        'ìš”ì²­/ì‘ë‹µ ëª¨ë¸ ì •ì˜',
        'ì—ëŸ¬ í•¸ë“¤ë§ êµ¬ì¡° ì„¤ê³„',
        'ì¸ì¦/ì¸ê°€ ë¯¸ë“¤ì›¨ì–´ ì„¤ê³„',
        'ë¡œê¹… ì‹œìŠ¤í…œ êµ¬ì¶•'
      ],
      storyPoints: 5,
      priority: 'critical',
      status: 'backlog',
      dependencies: ['story-001']
    },
    {
      id: 'story-003',
      title: 'React í”„ë¡œì íŠ¸ ì„¤ì •',
      description: 'React ê¸°ë°˜ í”„ë¡ íŠ¸ì—”ë“œ í”„ë¡œì íŠ¸ ì´ˆê¸° ì„¤ì •',
      acceptanceCriteria: [
        'í”„ë¡œì íŠ¸ êµ¬ì¡° ì„¤ì •',
        'ìƒíƒœ ê´€ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ í†µí•©',
        'ë¼ìš°íŒ… ì„¤ì •',
        'ê¸°ë³¸ ì»´í¬ë„ŒíŠ¸ êµ¬ì¡°',
        'ìŠ¤íƒ€ì¼ ì‹œìŠ¤í…œ ì„¤ì •'
      ],
      storyPoints: 3,
      priority: 'high',
      status: 'backlog',
      dependencies: []
    }
  ],
  team: ['frontend-lead', 'backend-lead', 'fullstack-developer']
};

// ì—í”½ ì •ì˜ ì˜ˆì‹œ
export const epics: Epic[] = [
  {
    id: 'epic-001',
    name: 'ì£¼ì‹ ê²€ìƒ‰ ê¸°ëŠ¥',
    description: 'ì‚¬ìš©ìê°€ ì£¼ì‹ì„ ê²€ìƒ‰í•˜ê³  ìƒì„¸ ì •ë³´ë¥¼ ì¡°íšŒí•˜ëŠ” ê¸°ëŠ¥',
    stories: ['story-004', 'story-005', 'story-006'],
    priority: 1
  },
  {
    id: 'epic-002',
    name: 'ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„',
    description: 'ì†Œì…œ ë¯¸ë””ì–´ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì£¼ì‹ ì„¼í‹°ë¨¼íŠ¸ë¥¼ ì œê³µ',
    stories: ['story-007', 'story-008', 'story-009'],
    priority: 2
  },
  {
    id: 'epic-003',
    name: 'ì‚¬ìš©ì ê´€ë¦¬',
    description: 'ì‚¬ìš©ì ê°€ì…, ë¡œê·¸ì¸, í”„ë¡œí•„ ê´€ë¦¬ ê¸°ëŠ¥',
    stories: ['story-010', 'story-011', 'story-012'],
    priority: 3
  }
];

// ê°œë°œ ì›Œí¬í”Œë¡œìš°
export const developmentWorkflow = {
  planning: {
    description: 'ìŠ¤í”„ë¦°íŠ¸ ê³„íš íšŒì˜',
    activities: [
      'ë°±ë¡œê·¸ ë¦¬ë·°',
      'ìŠ¤í† ë¦¬ í¬ì¸íŠ¸ ì¶”ì •',
      'ìŠ¤í”„ë¦°íŠ¸ ëª©í‘œ ì„¤ì •',
      'ì—­í•  ë¶„ë‹´'
    ],
    outputs: ['ìŠ¤í”„ë¦°íŠ¸ ë°±ë¡œê·¸', 'íŒ€ë³„ ëª©í‘œ']
  },
  development: {
    description: 'ê°œë°œ ë‹¨ê³„',
    activities: [
      'í”¼ì²˜ ë¸Œëœì¹˜ ìƒì„±',
      'ê°œë°œ ë° ë‹¨ìœ„ í…ŒìŠ¤íŠ¸',
      'ì½”ë“œ ë¦¬ë·°',
      'í†µí•© í…ŒìŠ¤íŠ¸'
    ],
    outputs: ['ì™„ë£Œëœ ê¸°ëŠ¥', 'í…ŒìŠ¤íŠ¸ ê²°ê³¼']
  },
  review: {
    description: 'ê²€í†  ë‹¨ê³„',
    activities: [
      'ê¸°ëŠ¥ ì‹œì—°',
      'ì½”ë“œ í’ˆì§ˆ ê²€í† ',
      'ì‚¬ìš©ì ìŠ¤í† ë¦¬ ì¶©ì¡± ì—¬ë¶€ í™•ì¸',
      'ìˆ˜ìš© ê¸°ì¤€ í‰ê°€'
    ],
    outputs: ['ê²€í†  ì˜ê²¬', 'ìˆ˜ì • ì‚¬í•­']
  },
  deployment: {
    description: 'ë°°í¬ ë‹¨ê³„',
    activities: [
      'ë©”ì¸ ë¸Œëœì¹˜ ë¨¸ì§€',
      'CI/CD íŒŒì´í”„ë¼ì¸ ì‹¤í–‰',
      'ìŠ¤í…Œì´ì§• í™˜ê²½ ë°°í¬',
      'í”„ë¡œë•ì…˜ í™˜ê²½ ë°°í¬'
    ],
    outputs: ['ë°°í¬ëœ ë²„ì „', 'ë°°í¬ ë³´ê³ ì„œ']
  },
  retrospective: {
    description: 'íšŒê³  ë‹¨ê³„',
    activities: [
      'ì˜ëœ ì  ë…¼ì˜',
      'ê°œì„ í•  ì  ë…¼ì˜',
      'ì‹¤í–‰ ê³„ì•½ ìˆ˜ë¦½',
      'ë‹¤ìŒ ìŠ¤í”„ë¦°íŠ¸ ì ìš©'
    ],
    outputs: ['íšŒê³  ë³´ê³ ì„œ', 'ê°œì„  ê³„íš']
  }
};
```

## 3. ê¸°ìˆ  ìŠ¤íƒ êµ¬í˜„

### 3.1 í”„ë¡ íŠ¸ì—”ë“œ ê¸°ìˆ  ìŠ¤íƒ

#### 3.1.1 React í”„ë¡œì íŠ¸ ì„¤ì •
```bash
# í”„ë¡œì íŠ¸ ìƒì„±
npx create-react-app insitechart-frontend --template typescript
cd insitechart-frontend

# í•„ìˆ˜ ì˜ì¡´ì„± ì„¤ì¹˜
npm install @reduxjs/toolkit react-redux react-router-dom
npm install @mui/material @emotion/react @emotion/styled
npm install @mui/icons-material @mui/x-charts
npm install axios react-query
npm install react-hook-form @hookform/resolvers yup
npm install date-fns
npm install recharts
npm install react-i18next i18next
npm install @testing-library/jest-dom @testing-library/user-event

# ê°œë°œ ì˜ì¡´ì„± ì„¤ì¹˜
npm install -D @types/node
npm install -D eslint-config-prettier prettier
npm install -D husky lint-staged
npm install -D @storybook/react-builder storybook
```

#### 3.1.2 í”„ë¡œì íŠ¸ êµ¬ì¡°
```
src/
â”œâ”€â”€ components/           # ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì»´í¬ë„ŒíŠ¸
â”‚   â”œâ”€â”€ common/         # ê³µí†µ ì»´í¬ë„ŒíŠ¸
â”‚   â”œâ”€â”€ forms/          # í¼ ì»´í¬ë„ŒíŠ¸
â”‚   â”œâ”€â”€ charts/         # ì°¨íŠ¸ ì»´í¬ë„ŒíŠ¸
â”‚   â””â”€â”€ layout/         # ë ˆì´ì•„ì›ƒ ì»´í¬ë„ŒíŠ¸
â”œâ”€â”€ pages/              # í˜ì´ì§€ ì»´í¬ë„ŒíŠ¸
â”‚   â”œâ”€â”€ Dashboard/
â”‚   â”œâ”€â”€ StockSearch/
â”‚   â”œâ”€â”€ Sentiment/
â”‚   â””â”€â”€ Profile/
â”œâ”€â”€ hooks/              # ì»¤ìŠ¤í…€ í›…
â”œâ”€â”€ services/           # API ì„œë¹„ìŠ¤
â”œâ”€â”€ store/              # Redux ìƒíƒœ ê´€ë¦¬
â”œâ”€â”€ utils/              # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”œâ”€â”€ types/              # TypeScript íƒ€ì… ì •ì˜
â”œâ”€â”€ constants/          # ìƒìˆ˜ ì •ì˜
â”œâ”€â”€ styles/             # ìŠ¤íƒ€ì¼ íŒŒì¼
â”œâ”€â”€ assets/             # ì •ì  ìì‚°
â”œâ”€â”€ locales/            # ë‹¤êµ­ì–´ íŒŒì¼
â””â”€â”€ tests/              # í…ŒìŠ¤íŠ¸ íŒŒì¼
```

### 3.2 ë°±ì—”ë“œ ê¸°ìˆ  ìŠ¤íƒ

#### 3.2.1 FastAPI í”„ë¡œì íŠ¸ ì„¤ì •
```bash
# í”„ë¡œì íŠ¸ ìƒì„±
mkdir insitechart-backend
cd insitechart-backend

# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# í•„ìˆ˜ ì˜ì¡´ì„± ì„¤ì¹˜
pip install fastapi uvicorn
pip install sqlalchemy alembic psycopg2-binary asyncpg
pip install redis celery
pip install pydantic python-jose[cryptography] passlib[bcrypt]
pip install python-multipart aiofiles
pip install httpx
pip install pytest pytest-asyncio pytest-cov
pip install black isort flake8 mypy

# í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±
mkdir -p app/{api,core,db,models,schemas,services,utils}
mkdir -p tests/{unit,integration,e2e}
```

#### 3.2.2 í”„ë¡œì íŠ¸ êµ¬ì¡°
```
insitechart-backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/              # API ë¼ìš°íŠ¸
â”‚   â”‚   â”œâ”€â”€ v1/
â”‚   â”‚   â”‚   â”œâ”€â”€ endpoints/
â”‚   â”‚   â”‚   â””â”€â”€ api.py
â”‚   â”‚   â””â”€â”€ deps.py       # ì˜ì¡´ì„± ì£¼ì…
â”‚   â”œâ”€â”€ core/              # í•µì‹¬ ì„¤ì •
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ security.py
â”‚   â”‚   â””â”€â”€ logging.py
â”‚   â”œâ”€â”€ db/                # ë°ì´í„°ë² ì´ìŠ¤
â”‚   â”‚   â”œâ”€â”€ session.py
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â””â”€â”€ init_db.py
â”‚   â”œâ”€â”€ models/            # ë°ì´í„° ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ stock.py
â”‚   â”‚   â”œâ”€â”€ sentiment.py
â”‚   â”‚   â””â”€â”€ user.py
â”‚   â”œâ”€â”€ schemas/           # Pydantic ìŠ¤í‚¤ë§ˆ
â”‚   â”‚   â”œâ”€â”€ stock.py
â”‚   â”‚   â”œâ”€â”€ sentiment.py
â”‚   â”‚   â””â”€â”€ user.py
â”‚   â”œâ”€â”€ services/          # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
â”‚   â”‚   â”œâ”€â”€ stock_service.py
â”‚   â”‚   â”œâ”€â”€ sentiment_service.py
â”‚   â”‚   â””â”€â”€ user_service.py
â”‚   â””â”€â”€ utils/             # ìœ í‹¸ë¦¬í‹°
â”‚       â”œâ”€â”€ auth.py
â”‚       â”œâ”€â”€ cache.py
â”‚       â””â”€â”€ helpers.py
â”œâ”€â”€ alembic/              # ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜
â”œâ”€â”€ tests/                 # í…ŒìŠ¤íŠ¸
â”œâ”€â”€ requirements.txt        # í”„ë¡œë•ì…˜ ì˜ì¡´ì„±
â”œâ”€â”€ requirements-dev.txt    # ê°œë°œ ì˜ì¡´ì„±
â””â”€â”€ main.py               # ì• í”Œë¦¬ì¼€ì´ì…˜ ì§„ì…ì 
```

## 4. ë°ì´í„°ë² ì´ìŠ¤ êµ¬í˜„

### 4.1 PostgreSQL ìŠ¤í‚¤ë§ˆ

#### 4.1.1 í…Œì´ë¸” ìƒì„± ìŠ¤í¬ë¦½íŠ¸
```sql
-- 01_create_users_table.sql
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    full_name VARCHAR(100),
    is_active BOOLEAN DEFAULT true,
    is_verified BOOLEAN DEFAULT false,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    last_login TIMESTAMP WITH TIME ZONE
);

-- 02_create_stocks_table.sql
CREATE TABLE stocks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    symbol VARCHAR(10) UNIQUE NOT NULL,
    company_name VARCHAR(255) NOT NULL,
    stock_type VARCHAR(50),
    exchange VARCHAR(50),
    sector VARCHAR(100),
    industry VARCHAR(100),
    description TEXT,
    website VARCHAR(255),
    country VARCHAR(100),
    currency VARCHAR(3) DEFAULT 'USD',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- 03_create_stock_prices_table.sql
CREATE TABLE stock_prices (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    stock_id UUID NOT NULL REFERENCES stocks(id) ON DELETE CASCADE,
    price_date DATE NOT NULL,
    open_price DECIMAL(10, 2) NOT NULL,
    high_price DECIMAL(10, 2) NOT NULL,
    low_price DECIMAL(10, 2) NOT NULL,
    close_price DECIMAL(10, 2) NOT NULL,
    adjusted_close_price DECIMAL(10, 2),
    volume BIGINT NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- TimescaleDB í•˜ì´í¼í…Œì´ë¸” ìƒì„±
SELECT create_hypertable('stock_prices', 'price_date', chunk_time_interval => INTERVAL '1 day');

-- 04_create_sentiment_data_table.sql
CREATE TABLE sentiment_data (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    stock_id UUID NOT NULL REFERENCES stocks(id) ON DELETE CASCADE,
    overall_sentiment DECIMAL(3, 2) NOT NULL, -- -1.00 to 1.00
    reddit_sentiment DECIMAL(3, 2),
    twitter_sentiment DECIMAL(3, 2),
    mention_count INTEGER DEFAULT 0,
    positive_mentions INTEGER DEFAULT 0,
    negative_mentions INTEGER DEFAULT 0,
    neutral_mentions INTEGER DEFAULT 0,
    confidence_score DECIMAL(3, 2),
    analysis_date DATE NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- TimescaleDB í•˜ì´í¼í…Œì´ë¸” ìƒì„±
SELECT create_hypertable('sentiment_data', 'analysis_date', chunk_time_interval => INTERVAL '1 day');

-- 05_create_stock_mentions_table.sql
CREATE TABLE stock_mentions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    stock_id UUID NOT NULL REFERENCES stocks(id) ON DELETE CASCADE,
    source VARCHAR(50) NOT NULL, -- 'reddit', 'twitter', 'news'
    community VARCHAR(100),
    author VARCHAR(100),
    text TEXT NOT NULL,
    url TEXT,
    upvotes INTEGER DEFAULT 0,
    timestamp TIMESTAMP WITH TIME ZONE NOT NULL,
    sentiment_score DECIMAL(3, 2),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- TimescaleDB í•˜ì´í¼í…Œì´ë¸” ìƒì„±
SELECT create_hypertable('stock_mentions', 'timestamp', chunk_time_interval => INTERVAL '1 hour');

-- 06_create_user_watchlists_table.sql
CREATE TABLE user_watchlists (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    stock_id UUID NOT NULL REFERENCES stocks(id) ON DELETE CASCADE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    UNIQUE(user_id, stock_id)
);

-- 07_create_user_alerts_table.sql
CREATE TABLE user_alerts (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    stock_id UUID NOT NULL REFERENCES stocks(id) ON DELETE CASCADE,
    alert_type VARCHAR(50) NOT NULL, -- 'price', 'sentiment', 'volume'
    condition VARCHAR(50) NOT NULL, -- 'above', 'below', 'change_percent'
    threshold_value DECIMAL(10, 2) NOT NULL,
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- 08_create_user_sessions_table.sql
CREATE TABLE user_sessions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    session_token VARCHAR(255) UNIQUE NOT NULL,
    expires_at TIMESTAMP WITH TIME ZONE NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- 09_create_audit_log_table.sql
CREATE TABLE audit_log (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id),
    action VARCHAR(100) NOT NULL,
    resource_type VARCHAR(50),
    resource_id VARCHAR(100),
    old_values JSONB,
    new_values JSONB,
    ip_address INET,
    user_agent TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- ì¸ë±ìŠ¤ ìƒì„±
CREATE INDEX idx_stocks_symbol ON stocks(symbol);
CREATE INDEX idx_stocks_exchange ON stocks(exchange);
CREATE INDEX idx_stocks_sector ON stocks(sector);

CREATE INDEX idx_stock_prices_stock_id_date ON stock_prices(stock_id, price_date DESC);

CREATE INDEX idx_sentiment_data_stock_id_date ON sentiment_data(stock_id, analysis_date DESC);

CREATE INDEX idx_stock_mentions_stock_id_timestamp ON stock_mentions(stock_id, timestamp DESC);
CREATE INDEX idx_stock_mentions_source ON stock_mentions(source);

CREATE INDEX idx_user_watchlists_user_id ON user_watchlists(user_id);
CREATE INDEX idx_user_watchlists_stock_id ON user_watchlists(stock_id);

CREATE INDEX idx_user_alerts_user_id ON user_alerts(user_id);
CREATE INDEX idx_user_alerts_stock_id ON user_alerts(stock_id);

CREATE INDEX idx_user_sessions_token ON user_sessions(session_token);
CREATE INDEX idx_user_sessions_expires_at ON user_sessions(expires_at);

CREATE INDEX idx_audit_log_user_id ON audit_log(user_id);
CREATE INDEX idx_audit_log_created_at ON audit_log(created_at);
```

### 4.2 Alembic ë§ˆì´ê·¸ë ˆì´ì…˜

#### 4.2.1 Alembic ì„¤ì •
```python
# alembic/env.py
from logging.config import fileConfig
from sqlalchemy import engine_from_config
from sqlalchemy import pool
from alembic import context
from app.core.config import settings
from app.db.base import Base
from app.models import *  # ëª¨ë“  ëª¨ë¸ ì„í¬íŠ¸

# Alembic Config ê°ì²´
config = context.config

# ë°ì´í„°ë² ì´ìŠ¤ URL ì„¤ì •
config.set_main_option('sqlalchemy.url', settings.DATABASE_URL)

# í•´ì„ëœ ê°ì²´ ì„¤ì •
target_metadata = Base.metadata

def run_migrations_offline():
    """ì˜¤í”„ë¼ì¸ ëª¨ë“œì—ì„œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰"""
    url = config.get_main_option('sqlalchemy.url')
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={'paramstyle': 'named'},
    )

    with context.begin_transaction():
        context.run_migrations()

def run_migrations_online():
    """ì˜¨ë¼ì¸ ëª¨ë“œì—ì„œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰"""
    connectable = engine_from_config(
        config.get_section(config.config_ini_section),
        prefix='sqlalchemy.',
        poolclass=pool.NullPool,
    )

    with connectable.connect() as connection:
        context.configure(
            connection=connection,
            target_metadata=target_metadata
        )

        with context.begin_transaction():
            context.run_migrations()
```

## 5. CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

### 5.1 GitHub Actions ì›Œí¬í”Œë¡œìš°

#### 5.1.1 í”„ë¡ íŠ¸ì—”ë“œ CI/CD
```yaml
# .github/workflows/frontend-ci.yml
name: Frontend CI/CD

on:
  push:
    branches: [ main, develop ]
    paths: [ 'frontend/**' ]
  pull_request:
    branches: [ main ]
    paths: [ 'frontend/**' ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json
    
    - name: Install dependencies
      working-directory: ./frontend
      run: npm ci
    
    - name: Run linting
      working-directory: ./frontend
      run: |
        npm run lint
        npm run lint:style
    
    - name: Run type checking
      working-directory: ./frontend
      run: npm run type-check
    
    - name: Run unit tests
      working-directory: ./frontend
      run: npm run test:unit
    
    - name: Run integration tests
      working-directory: ./frontend
      run: npm run test:integration
    
    - name: Build application
      working-directory: ./frontend
      run: npm run build
    
    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./frontend/coverage/lcov.info
        flags: frontend
        name: frontend-coverage

  deploy-staging:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json
    
    - name: Install dependencies
      working-directory: ./frontend
      run: npm ci
    
    - name: Build application
      working-directory: ./frontend
      run: npm run build
    
    - name: Deploy to staging
      uses: appleboy/ssh-action@v0.1.5
      with:
        host: ${{ secrets.STAGING_HOST }}
        username: ${{ secrets.STAGING_USER }}
        key: ${{ secrets.STAGING_SSH_KEY }}
        script: |
          cd /var/www/insitechart-staging
          git pull origin develop
          npm ci
          npm run build
          pm2 restart insitechart-frontend

  deploy-production:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json
    
    - name: Install dependencies
      working-directory: ./frontend
      run: npm ci
    
    - name: Build application
      working-directory: ./frontend
      run: npm run build
    
    - name: Deploy to production
      uses: appleboy/ssh-action@v0.1.5
      with:
        host: ${{ secrets.PRODUCTION_HOST }}
        username: ${{ secrets.PRODUCTION_USER }}
        key: ${{ secrets.PRODUCTION_SSH_KEY }}
        script: |
          cd /var/www/insitechart
          git pull origin main
          npm ci
          npm run build
          pm2 restart insitechart-frontend
```

#### 5.1.2 ë°±ì—”ë“œ CI/CD
```yaml
# .github/workflows/backend-ci.yml
name: Backend CI/CD

on:
  push:
    branches: [ main, develop ]
    paths: [ 'backend/**' ]
  pull_request:
    branches: [ main ]
    paths: [ 'backend/**' ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: timescale/timescaledb:latest-pg14
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_insitechart
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      working-directory: ./backend
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
    
    - name: Run linting
      working-directory: ./backend
      run: |
        flake8 app tests
        black --check app tests
        isort --check-only app tests
    
    - name: Run type checking
      working-directory: ./backend
      run: mypy app
    
    - name: Run security checks
      working-directory: ./backend
      run: |
        bandit -r app
        safety check
    
    - name: Run unit tests
      working-directory: ./backend
      env:
        DATABASE_URL: postgresql+asyncpg://postgres:postgres@localhost:5432/test_insitechart
        REDIS_URL: redis://localhost:6379/1
        SECRET_KEY: test-secret-key
      run: |
        pytest tests/unit -v --cov=app --cov-report=xml --cov-report=html
    
    - name: Run integration tests
      working-directory: ./backend
      env:
        DATABASE_URL: postgresql+asyncpg://postgres:postgres@localhost:5432/test_insitechart
        REDIS_URL: redis://localhost:6379/1
        SECRET_KEY: test-secret-key
        YAHOO_API_KEY: ${{ secrets.YAHOO_API_KEY }}
        REDDIT_API_KEY: ${{ secrets.REDDIT_API_KEY }}
        TWITTER_API_KEY: ${{ secrets.TWITTER_API_KEY }}
      run: pytest tests/integration -v
    
    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./backend/coverage.xml
        flags: backend
        name: backend-coverage

  deploy-staging:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      working-directory: ./backend
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Deploy to staging
      uses: appleboy/ssh-action@v0.1.5
      with:
        host: ${{ secrets.STAGING_HOST }}
        username: ${{ secrets.STAGING_USER }}
        key: ${{ secrets.STAGING_SSH_KEY }}
        script: |
          cd /var/www/insitechart-staging
          git pull origin develop
          pip install -r requirements.txt
          alembic upgrade head
          pm2 restart insitechart-backend

  deploy-production:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      working-directory: ./backend
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Deploy to production
      uses: appleboy/ssh-action@v0.1.5
      with:
        host: ${{ secrets.PRODUCTION_HOST }}
        username: ${{ secrets.PRODUCTION_USER }}
        key: ${{ secrets.PRODUCTION_SSH_KEY }}
        script: |
          cd /var/www/insitechart
          git pull origin main
          pip install -r requirements.txt
          alembic upgrade head
          pm2 restart insitechart-backend
```

## 6. ëª¨ë‹ˆí„°ë§ ë° ìš´ì˜

### 6.1 ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•

#### 6.1.1 Prometheus + Grafana ì„¤ì •
```yaml
# monitoring/docker-compose.yml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - monitoring

  grafana:
    image: grafana/grafana:latest
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    ports:
      - "3000:3000"
    networks:
      - monitoring
    depends_on:
      - prometheus

  node-exporter:
    image: prom/node-exporter:latest
    ports:
      - "9100:9100"
    networks:
      - monitoring

  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    environment:
      - DATA_SOURCE_NAME=postgres
      - DATA_SOURCE_URI=postgresql://postgres:${POSTGRES_PASSWORD}@postgres:5432/insitechart?sslmode=disable
    ports:
      - "9187:9187"
    networks:
      - monitoring
    depends_on:
      - postgres

  redis-exporter:
    image: oliver006/redis_exporter:latest
    environment:
      - REDIS_ADDR=redis://redis:6379
    ports:
      - "9121:9121"
    networks:
      - monitoring
    depends_on:
      - redis

volumes:
  prometheus_data:
  grafana_data:

networks:
  monitoring:
    driver: bridge
```

### 6.2 ë¡œê¹… ì‹œìŠ¤í…œ

#### 6.2.1 ELK ìŠ¤íƒ ì„¤ì •
```yaml
# logging/docker-compose.yml
version: '3.8'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.5.0
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - logging

  logstash:
    image: docker.elastic.co/logstash/logstash:8.5.0
    ports:
      - "5044:5044"
      - "5000:5000/tcp"
      - "5000:5000/udp"
      - "9600:9600"
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro
      - ./logstash/config:/usr/share/logstash/config:ro
    networks:
      - logging
    depends_on:
      - elasticsearch

  kibana:
    image: docker.elastic.co/kibana/kibana:8.5.0
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    networks:
      - logging
    depends_on:
      - elasticsearch

  filebeat:
    image: docker.elastic.co/beats/filebeat:8.5.0
    user: root
    volumes:
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/log:/var/log:ro
    networks:
      - logging
    depends_on:
      - logstash

volumes:
  elasticsearch_data:

networks:
  logging:
    driver: bridge
```

## 7. Streamlit ê¸°ë°˜ ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ êµ¬í˜„ ì„¸ë¶€ì‚¬í•­

### 7.1 í˜„ì¬ ì•± ê°œì„ ì„ ìœ„í•œ êµ¬ì²´ì ì¸ ì½”ë“œ ì˜ˆì‹œ

#### 7.1.1 í–¥ìƒëœ ê²€ìƒ‰ ê¸°ëŠ¥ êµ¬í˜„
```python
# enhanced_search.py
import streamlit as st
import requests
import time
from dataclasses import dataclass
from typing import List, Optional, Dict, Any
from datetime import datetime
import pandas as pd

@dataclass
class StockSuggestion:
    symbol: str
    company_name: str
    stock_type: str
    exchange: str
    sector: str
    industry: str
    relevance_score: float
    current_price: Optional[float] = None
    market_cap: Optional[float] = None

class EnhancedSearchEngine:
    def __init__(self):
        self.cache = {}
        self.debounce_timer = None
        self.cache_ttl = 300  # 5ë¶„
        self.max_cache_size = 1000
    
    def _calculate_relevance_score(self, stock: Dict[str, Any], query: str) -> float:
        """ê´€ë ¨ë„ ì ìˆ˜ ê³„ì‚°"""
        query = query.lower()
        symbol = stock.get('symbol', '').lower()
        name = stock.get('shortname', '').lower()
        longname = stock.get('longname', '').lower()
        
        score = 0
        
        # ì‹¬ë³¼ ì •í™• ì¼ì¹˜
        if symbol == query:
            score += 100
        # ì‹¬ë³¼ ì‹œì‘ ì¼ì¹˜
        elif symbol.startswith(query):
            score += 80
        # íšŒì‚¬ëª… ì‹œì‘ ì¼ì¹˜
        elif name.startswith(query) or longname.startswith(query):
            score += 60
        # ì‹¬ë³¼ ë¶€ë¶„ ì¼ì¹˜
        elif query in symbol:
            score += 40
        # íšŒì‚¬ëª… ë¶€ë¶„ ì¼ì¹˜
        elif query in name or query in longname:
            score += 20
        
        return score
    
    async def get_suggestions(self, query: str, max_results: int = 10) -> List[StockSuggestion]:
        """ìë™ì™„ì„± ì œì•ˆ ìƒì„±"""
        if not query or len(query) < 2:
            return []
        
        # ìºì‹œ í™•ì¸
        cache_key = f"search_{query}_{max_results}"
        if cache_key in self.cache:
            cached_data, timestamp = self.cache[cache_key]
            if time.time() - timestamp < self.cache_ttl:
                return cached_data
        
        try:
            url = "https://query2.finance.yahoo.com/v1/finance/search"
            params = {
                "q": query,
                "quotes_count": max_results * 2,  # ë” ë§ì€ ê²°ê³¼ ê°€ì ¸ì™€ì„œ í•„í„°ë§
                "country": "United States"
            }
            
            response = requests.get(
                url=url,
                params=params,
                headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'},
                timeout=10
            )
            
            if response.status_code == 200:
                data = response.json()
                suggestions = []
                
                for quote in data.get('quotes', []):
                    # ê´€ë ¨ë„ ì ìˆ˜ ê³„ì‚°
                    relevance_score = self._calculate_relevance_score(quote, query)
                    
                    suggestion = StockSuggestion(
                        symbol=quote.get('symbol', ''),
                        company_name=quote.get('shortname') or quote.get('longname', ''),
                        stock_type=quote.get('quoteType', ''),
                        exchange=quote.get('exchange', ''),
                        sector=quote.get('sector', ''),
                        industry=quote.get('industry', ''),
                        relevance_score=relevance_score
                    )
                    suggestions.append(suggestion)
                
                # ê´€ë ¨ë„ ìˆœìœ¼ë¡œ ì •ë ¬
                suggestions.sort(key=lambda x: x.relevance_score, reverse=True)
                suggestions = suggestions[:max_results]
                
                # ìºì‹œ ì €ì¥
                self.cache[cache_key] = (suggestions, time.time())
                self._cleanup_cache()
                
                return suggestions
            else:
                return []
        except Exception as e:
            st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
            return []
    
    def _cleanup_cache(self):
        """ì˜¤ë˜ëœ ìºì‹œ ì •ë¦¬"""
        current_time = time.time()
        expired_keys = [
            key for key, (_, timestamp) in self.cache.items()
            if current_time - timestamp > self.cache_ttl
        ]
        for key in expired_keys:
            del self.cache[key]
        
        # ìºì‹œ í¬ê¸° ì œí•œ
        if len(self.cache) > self.max_cache_size:
            oldest_keys = sorted(
                self.cache.items(),
                key=lambda x: x[1][1]
            )[:len(self.cache) - self.max_cache_size]
            for key, _ in oldest_keys:
                del self.cache[key]

class FilterSystem:
    def __init__(self):
        self.active_filters = {}
    
    def add_filter(self, filter_type: str, value: Any):
        """í•„í„° ì¶”ê°€"""
        self.active_filters[filter_type] = value
    
    def remove_filter(self, filter_type: str):
        """í•„í„° ì œê±°"""
        if filter_type in self.active_filters:
            del self.active_filters[filter_type]
    
    def apply_filters(self, suggestions: List[StockSuggestion]) -> List[StockSuggestion]:
        """í•„í„° ì ìš©"""
        filtered = suggestions
        
        # ì£¼ì‹ ìœ í˜• í•„í„°
        if 'stock_type' in self.active_filters:
            filtered = [
                s for s in filtered
                if s.stock_type == self.active_filters['stock_type']
            ]
        
        # ê±°ë˜ì†Œ í•„í„°
        if 'exchange' in self.active_filters:
            filtered = [
                s for s in filtered
                if s.exchange == self.active_filters['exchange']
            ]
        
        # ì„¹í„° í•„í„°
        if 'sector' in self.active_filters:
            filtered = [
                s for s in filtered
                if self.active_filters['sector'].lower() in s.sector.lower()
            ]
        
        return filtered
    
    def get_available_filter_values(self, suggestions: List[StockSuggestion]) -> Dict[str, List[str]]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ í•„í„° ê°’ ëª©ë¡"""
        stock_types = list(set(s.stock_type for s in suggestions if s.stock_type))
        exchanges = list(set(s.exchange for s in suggestions if s.exchange))
        sectors = list(set(s.sector for s in suggestions if s.sector))
        
        return {
            'stock_type': sorted(stock_types),
            'exchange': sorted(exchanges),
            'sector': sorted(sectors)
        }

class SearchHistoryManager:
    def __init__(self, max_history: int = 20):
        self.max_history = max_history
        if 'search_history' not in st.session_state:
            st.session_state.search_history = []
    
    def add_to_history(self, symbol: str, company_name: str):
        """ê²€ìƒ‰ ê¸°ë¡ ì¶”ê°€"""
        history_item = {
            'symbol': symbol,
            'company_name': company_name,
            'search_time': datetime.now(),
            'search_count': 1
        }
        
        # ê¸°ì¡´ ê¸°ë¡ í™•ì¸
        history = st.session_state.search_history
        for i, item in enumerate(history):
            if item['symbol'] == symbol:
                history[i]['search_time'] = datetime.now()
                history[i]['search_count'] += 1
                # ìµœì‹  ìˆœìœ¼ë¡œ ì •ë ¬
                history.sort(key=lambda x: x['search_time'], reverse=True)
                return
        
        # ìƒˆ í•­ëª© ì¶”ê°€
        history.append(history_item)
        history.sort(key=lambda x: x['search_time'], reverse=True)
        
        # ìµœëŒ€ ê°œìˆ˜ ìœ ì§€
        if len(history) > self.max_history:
            st.session_state.search_history = history[:self.max_history]
        else:
            st.session_state.search_history = history
    
    def get_history(self) -> List[Dict[str, Any]]:
        """ê²€ìƒ‰ ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°"""
        return st.session_state.get('search_history', [])

# Streamlit UI í†µí•©
def enhanced_search_ui():
    """í–¥ìƒëœ ê²€ìƒ‰ UI"""
    st.markdown("### ğŸ” Enhanced Stock Search")
    
    # ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”
    if 'search_engine' not in st.session_state:
        st.session_state.search_engine = EnhancedSearchEngine()
        st.session_state.filter_system = FilterSystem()
        st.session_state.history_manager = SearchHistoryManager()
    
    search_engine = st.session_state.search_engine
    filter_system = st.session_state.filter_system
    history_manager = st.session_state.history_manager
    
    # ê²€ìƒ‰ ì…ë ¥
    col_search, col_clear = st.columns([4, 1])
    
    with col_search:
        search_query = st.text_input(
            "Search stocks...",
            placeholder="Enter symbol or company name...",
            key="enhanced_search_input"
        )
    
    with col_clear:
        st.write("")
        if st.button("Clear", key="clear_search"):
            st.session_state.search_suggestions = []
            st.session_state.search_query = ""
            st.rerun()
    
    # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
    if search_query and search_query != st.session_state.get('search_query', ''):
        with st.spinner("Searching..."):
            suggestions = await search_engine.get_suggestions(search_query)
            st.session_state.search_suggestions = suggestions
            st.session_state.search_query = search_query
    
    # í•„í„° UI
    if 'search_suggestions' in st.session_state and st.session_state.search_suggestions:
        suggestions = st.session_state.search_suggestions
        available_filters = filter_system.get_available_filter_values(suggestions)
        
        with st.expander("ğŸ”§ Filters", expanded=False):
            col1, col2, col3 = st.columns(3)
            
            with col1:
                stock_type = st.selectbox(
                    "Stock Type",
                    ["All"] + available_filters['stock_type'],
                    key="filter_stock_type"
                )
                if stock_type != "All":
                    filter_system.add_filter('stock_type', stock_type)
                else:
                    filter_system.remove_filter('stock_type')
            
            with col2:
                exchange = st.selectbox(
                    "Exchange",
                    ["All"] + available_filters['exchange'],
                    key="filter_exchange"
                )
                if exchange != "All":
                    filter_system.add_filter('exchange', exchange)
                else:
                    filter_system.remove_filter('exchange')
            
            with col3:
                sector = st.selectbox(
                    "Sector",
                    ["All"] + available_filters['sector'],
                    key="filter_sector"
                )
                if sector != "All":
                    filter_system.add_filter('sector', sector)
                else:
                    filter_system.remove_filter('sector')
        
        # í•„í„°ë§ëœ ê²°ê³¼
        filtered_suggestions = filter_system.apply_filters(suggestions)
        
        # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
        st.markdown("#### Search Results")
        
        if filtered_suggestions:
            for suggestion in filtered_suggestions:
                col_symbol, col_name, col_info, col_action = st.columns([1, 3, 2, 1])
                
                with col_symbol:
                    st.markdown(f"**{suggestion.symbol}**")
                
                with col_name:
                    st.markdown(suggestion.company_name)
                
                with col_info:
                    st.markdown(f"{suggestion.stock_type} â€¢ {suggestion.exchange}")
                
                with col_action:
                    if st.button("Select", key=f"select_{suggestion.symbol}"):
                        # ê²€ìƒ‰ ê¸°ë¡ ì¶”ê°€
                        history_manager.add_to_history(suggestion.symbol, suggestion.company_name)
                        # í˜„ì¬ ì„ íƒëœ ì£¼ì‹ ì„¤ì •
                        st.session_state.current_ticker = suggestion.symbol
                        # ê´€ì‹¬ì¢…ëª©ì— ì¶”ê°€ (ì„ íƒì )
                        if suggestion.symbol not in st.session_state.watchlist:
                            st.session_state.watchlist.append(suggestion.symbol)
                        st.rerun()
        else:
            st.info("No results match your filters.")
    
    # ê²€ìƒ‰ ê¸°ë¡ í‘œì‹œ
    history = history_manager.get_history()
    if history:
        st.markdown("#### Recent Searches")
        
        for item in history[:5]:  # ìµœê·¼ 5ê°œë§Œ í‘œì‹œ
            col_hist_symbol, col_hist_name, col_hist_action = st.columns([1, 3, 1])
            
            with col_hist_symbol:
                st.markdown(f"**{item['symbol']}**")
            
            with col_hist_name:
                st.markdown(item['company_name'])
            
            with col_hist_action:
                if st.button("View", key=f"history_{item['symbol']}"):
                    st.session_state.current_ticker = item['symbol']
                    st.rerun()
```

#### 7.1.2 í†µí•© ë°ì´í„° ëª¨ë¸ êµ¬í˜„
```python
# unified_data.py
from dataclasses import dataclass
from typing import Optional, List, Dict, Any
from datetime import datetime
import yfinance as yf
import requests

@dataclass
class UnifiedStockData:
    """í†µí•© ì£¼ì‹ ë°ì´í„° ëª¨ë¸"""
    # ê¸°ë³¸ ì •ë³´
    symbol: str
    company_name: str
    stock_type: str
    exchange: str
    sector: str
    industry: str
    
    # ê°€ê²© ì •ë³´
    current_price: Optional[float] = None
    previous_close: Optional[float] = None
    day_high: Optional[float] = None
    day_low: Optional[float] = None
    volume: Optional[int] = None
    market_cap: Optional[float] = None
    
    # ê²€ìƒ‰ ê´€ë ¨
    relevance_score: float = 0.0
    search_count: int = 0
    
    # ì„¼í‹°ë¨¼íŠ¸ ê´€ë ¨
    sentiment_score: Optional[float] = None
    mention_count_24h: int = 0
    trending_status: bool = False
    trend_score: Optional[float] = None
    
    # ê¸°ìˆ  ì§€í‘œ
    rsi: Optional[float] = None
    macd: Optional[float] = None
    bollinger_upper: Optional[float] = None
    bollinger_lower: Optional[float] = None
    
    # ë©”íƒ€ë°ì´í„°
    last_updated: datetime = None
    data_sources: List[str] = None
    
    def __post_init__(self):
        if self.last_updated is None:
            self.last_updated = datetime.now()
        if self.data_sources is None:
            self.data_sources = []

class UnifiedDataService:
    """í†µí•© ë°ì´í„° ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.cache = {}
        self.cache_ttl = 300  # 5ë¶„
    
    async def get_stock_with_all_data(self, symbol: str) -> UnifiedStockData:
        """ëª¨ë“  ë°ì´í„°ê°€ í†µí•©ëœ ì£¼ì‹ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        # ìºì‹œ í™•ì¸
        cache_key = f"unified_{symbol}"
        if cache_key in self.cache:
            cached_data, timestamp = self.cache[cache_key]
            if (datetime.now() - timestamp).seconds < self.cache_ttl:
                return cached_data
        
        try:
            # ë³‘ë ¬ë¡œ ë°ì´í„° ìˆ˜ì§‘
            stock_info, sentiment_data = await asyncio.gather(
                self._get_stock_info(symbol),
                self._get_sentiment_data(symbol)
            )
            
            # ë°ì´í„° í†µí•©
            unified_data = self._merge_data(stock_info, sentiment_data)
            
            # ìºì‹œ ì €ì¥
            self.cache[cache_key] = (unified_data, datetime.now())
            
            return unified_data
        except Exception as e:
            st.error(f"ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {str(e)}")
            return None
    
    async def _get_stock_info(self, symbol: str) -> Dict[str, Any]:
        """ì£¼ì‹ ê¸°ë³¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        try:
            ticker = yf.Ticker(symbol)
            info = ticker.info
            
            return {
                'symbol': symbol,
                'company_name': info.get('longName', ''),
                'stock_type': info.get('quoteType', ''),
                'exchange': info.get('exchange', ''),
                'sector': info.get('sector', ''),
                'industry': info.get('industry', ''),
                'current_price': info.get('currentPrice') or info.get('regularMarketPrice'),
                'previous_close': info.get('previousClose'),
                'day_high': info.get('dayHigh'),
                'day_low': info.get('dayLow'),
                'volume': info.get('volume'),
                'market_cap': info.get('marketCap'),
                'data_sources': ['yahoo_finance']
            }
        except Exception as e:
            st.error(f"ì£¼ì‹ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {str(e)}")
            return {}
    
    async def _get_sentiment_data(self, symbol: str) -> Dict[str, Any]:
        """ì„¼í‹°ë¨¼íŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ì˜ˆì‹œ)"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Reddit, Twitter API ë“±ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        try:
            # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œ ë°ì´í„° ë°˜í™˜
            return {
                'sentiment_score': 0.65,
                'mention_count_24h': 1247,
                'trending_status': True,
                'trend_score': 2.5,
                'data_sources': ['reddit', 'twitter']
            }
        except Exception as e:
            return {
                'sentiment_score': 0.0,
                'mention_count_24h': 0,
                'trending_status': False,
                'trend_score': 0.0,
                'data_sources': []
            }
    
    def _merge_data(self, stock_info: Dict[str, Any], sentiment_data: Dict[str, Any]) -> UnifiedStockData:
        """ë°ì´í„° í†µí•©"""
        return UnifiedStockData(
            symbol=stock_info.get('symbol', ''),
            company_name=stock_info.get('company_name', ''),
            stock_type=stock_info.get('stock_type', ''),
            exchange=stock_info.get('exchange', ''),
            sector=stock_info.get('sector', ''),
            industry=stock_info.get('industry', ''),
            current_price=stock_info.get('current_price'),
            previous_close=stock_info.get('previous_close'),
            day_high=stock_info.get('day_high'),
            day_low=stock_info.get('day_low'),
            volume=stock_info.get('volume'),
            market_cap=stock_info.get('market_cap'),
            sentiment_score=sentiment_data.get('sentiment_score'),
            mention_count_24h=sentiment_data.get('mention_count_24h'),
            trending_status=sentiment_data.get('trending_status'),
            trend_score=sentiment_data.get('trend_score'),
            data_sources=list(set(
                stock_info.get('data_sources', []) +
                sentiment_data.get('data_sources', [])
            ))
        )

# Streamlit UI í†µí•©
def unified_stock_display(symbol: str):
    """í†µí•© ì£¼ì‹ ì •ë³´ í‘œì‹œ"""
    if 'unified_service' not in st.session_state:
        st.session_state.unified_service = UnifiedDataService()
    
    unified_service = st.session_state.unified_service
    
    with st.spinner(f"Loading {symbol} data..."):
        unified_data = await unified_service.get_stock_with_all_data(symbol)
    
    if unified_data:
        # ê¸°ë³¸ ì •ë³´ í‘œì‹œ
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Current Price", f"${unified_data.current_price:.2f}")
        
        with col2:
            if unified_data.previous_close:
                change = unified_data.current_price - unified_data.previous_close
                change_pct = (change / unified_data.previous_close) * 100
                st.metric("Change", f"${change:.2f}", f"{change_pct:.2f}%")
        
        with col3:
            st.metric("Volume", f"{unified_data.volume:,}")
        
        with col4:
            if unified_data.market_cap:
                st.metric("Market Cap", f"${unified_data.market_cap/1e9:.1f}B")
        
        # ì„¼í‹°ë¨¼íŠ¸ ì •ë³´ í‘œì‹œ
        if unified_data.sentiment_score is not None:
            st.markdown("### Social Sentiment")
            
            sentiment_col1, sentiment_col2, sentiment_col3 = st.columns(3)
            
            with sentiment_col1:
                sentiment_color = "ğŸŸ¢" if unified_data.sentiment_score > 0.1 else "ğŸ”´" if unified_data.sentiment_score < -0.1 else "âšª"
                st.metric("Sentiment", f"{sentiment_color} {unified_data.sentiment_score:.2f}")
            
            with sentiment_col2:
                st.metric("Mentions (24h)", unified_data.mention_count_24h)
            
            with sentiment_col3:
                if unified_data.trending_status:
                    st.metric("Trending", "ğŸ”¥ Yes", delta=f"+{unified_data.trend_score:.1f}")
                else:
                    st.metric("Trending", "âŒ No")
        
        # ë°ì´í„° ì†ŒìŠ¤ í‘œì‹œ
        st.markdown("### Data Sources")
        sources = ", ".join(unified_data.data_sources)
        st.info(f"Data from: {sources}")
```

#### 7.1.3 í–¥ìƒëœ ê´€ì‹¬ì¢…ëª© ê´€ë¦¬
```python
# enhanced_watchlist.py
import streamlit as st
from dataclasses import dataclass
from typing import List, Optional, Dict, Any
from datetime import datetime
import json

@dataclass
class WatchlistItem:
    """ê´€ì‹¬ì¢…ëª© ì•„ì´í…œ"""
    symbol: str
    company_name: str
    category: str = "Default"
    note: str = ""
    added_date: datetime = None
    order_index: int = 0
    alert_enabled: bool = False
    alert_price_above: Optional[float] = None
    alert_price_below: Optional[float] = None
    
    def __post_init__(self):
        if self.added_date is None:
            self.added_date = datetime.now()

class EnhancedWatchlistManager:
    """í–¥ìƒëœ ê´€ì‹¬ì¢…ëª© ê´€ë¦¬ì"""
    
    def __init__(self):
        if 'enhanced_watchlist' not in st.session_state:
            st.session_state.enhanced_watchlist = []
        if 'watchlist_categories' not in st.session_state:
            st.session_state.watchlist_categories = ["Default", "Tech", "Finance", "Healthcare"]
    
    def add_to_watchlist(self, symbol: str, company_name: str, category: str = "Default"):
        """ê´€ì‹¬ì¢…ëª© ì¶”ê°€"""
        # ì¤‘ë³µ í™•ì¸
        for item in st.session_state.enhanced_watchlist:
            if item.symbol == symbol:
                st.warning(f"{symbol} is already in your watchlist.")
                return False
        
        # ìƒˆ ì•„ì´í…œ ìƒì„±
        new_item = WatchlistItem(
            symbol=symbol,
            company_name=company_name,
            category=category,
            order_index=len(st.session_state.enhanced_watchlist)
        )
        
        st.session_state.enhanced_watchlist.append(new_item)
        self._save_to_local_storage()
        return True
    
    def remove_from_watchlist(self, symbol: str):
        """ê´€ì‹¬ì¢…ëª© ì œê±°"""
        st.session_state.enhanced_watchlist = [
            item for item in st.session_state.enhanced_watchlist
            if item.symbol != symbol
        ]
        self._save_to_local_storage()
    
    def update_watchlist_item(self, symbol: str, **kwargs):
        """ê´€ì‹¬ì¢…ëª© ì•„ì´í…œ ì—…ë°ì´íŠ¸"""
        for item in st.session_state.enhanced_watchlist:
            if item.symbol == symbol:
                for key, value in kwargs.items():
                    if hasattr(item, key):
                        setattr(item, key, value)
                break
        self._save_to_local_storage()
    
    def get_watchlist(self, category: Optional[str] = None) -> List[WatchlistItem]:
        """ê´€ì‹¬ì¢…ëª© ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        watchlist = st.session_state.enhanced_watchlist
        
        if category and category != "All":
            watchlist = [item for item in watchlist if item.category == category]
        
        # ì •ë ¬
        return sorted(watchlist, key=lambda x: x.order_index)
    
    def get_categories(self) -> List[str]:
        """ì¹´í…Œê³ ë¦¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        return st.session_state.watchlist_categories
    
    def add_category(self, category: str):
        """ì¹´í…Œê³ ë¦¬ ì¶”ê°€"""
        if category not in st.session_state.watchlist_categories:
            st.session_state.watchlist_categories.append(category)
    
    def reorder_watchlist(self, symbols: List[str]):
        """ê´€ì‹¬ì¢…ëª© ìˆœì„œ ë³€ê²½"""
        for i, symbol in enumerate(symbols):
            self.update_watchlist_item(symbol, order_index=i)
    
    def _save_to_local_storage(self):
        """ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ì— ì €ì¥"""
        # Streamlitì—ì„œëŠ” íŒŒì¼ ê¸°ë°˜ ì €ì¥ ë˜ëŠ” ì„¸ì…˜ ìƒíƒœ í™œìš©
        watchlist_data = []
        for item in st.session_state.enhanced_watchlist:
            watchlist_data.append({
                'symbol': item.symbol,
                'company_name': item.company_name,
                'category': item.category,
                'note': item.note,
                'added_date': item.added_date.isoformat(),
                'order_index': item.order_index,
                'alert_enabled': item.alert_enabled,
                'alert_price_above': item.alert_price_above,
                'alert_price_below': item.alert_price_below
            })
        
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” íŒŒì¼ì´ë‚˜ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        # ì—¬ê¸°ì„œëŠ” ì„¸ì…˜ ìƒíƒœì—ë§Œ ì €ì¥
        st.session_state.watchlist_data = watchlist_data

# Streamlit UI í†µí•©
def enhanced_watchlist_ui():
    """í–¥ìƒëœ ê´€ì‹¬ì¢…ëª© UI"""
    st.markdown("### ğŸ“Š Enhanced Watchlist")
    
    if 'watchlist_manager' not in st.session_state:
        st.session_state.watchlist_manager = EnhancedWatchlistManager()
    
    manager = st.session_state.watchlist_manager
    
    # ì¹´í…Œê³ ë¦¬ ì„ íƒ
    categories = ["All"] + manager.get_categories()
    selected_category = st.selectbox("Category", categories, key="watchlist_category")
    
    # ê´€ì‹¬ì¢…ëª© ëª©ë¡ í‘œì‹œ
    watchlist = manager.get_watchlist(selected_category if selected_category != "All" else None)
    
    if watchlist:
        for item in watchlist:
            with st.expander(f"{item.symbol} - {item.company_name}", expanded=False):
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.markdown(f"**Category:** {item.category}")
                    st.markdown(f"**Added:** {item.added_date.strftime('%Y-%m-%d')}")
                
                with col2:
                    if item.note:
                        st.markdown(f"**Note:** {item.note}")
                    
                    # ì•Œë¦¼ ì„¤ì •
                    alert_enabled = st.checkbox(
                        "Enable Price Alert",
                        value=item.alert_enabled,
                        key=f"alert_{item.symbol}"
                    )
                    if alert_enabled != item.alert_enabled:
                        manager.update_watchlist_item(item.symbol, alert_enabled=alert_enabled)
                    
                    if alert_enabled:
                        col_alert1, col_alert2 = st.columns(2)
                        with col_alert1:
                            alert_above = st.number_input(
                                "Alert Above",
                                value=item.alert_price_above or 0.0,
                                key=f"alert_above_{item.symbol}"
                            )
                        with col_alert2:
                            alert_below = st.number_input(
                                "Alert Below",
                                value=item.alert_price_below or 0.0,
                                key=f"alert_below_{item.symbol}"
                            )
                        
                        manager.update_watchlist_item(
                            item.symbol,
                            alert_price_above=alert_above if alert_above > 0 else None,
                            alert_price_below=alert_below if alert_below > 0 else None
                        )
                
                with col3:
                    # ë©”ëª¨ ìˆ˜ì •
                    new_note = st.text_area(
                        "Note",
                        value=item.note,
                        key=f"note_{item.symbol}",
                        height=50
                    )
                    if new_note != item.note:
                        manager.update_watchlist_item(item.symbol, note=new_note)
                    
                    # ì‚­ì œ ë²„íŠ¼
                    if st.button("Remove", key=f"remove_{item.symbol}"):
                        manager.remove_from_watchlist(item.symbol)
                        st.rerun()
    else:
        st.info("No stocks in watchlist.")
    
    # ìƒˆ ì£¼ì‹ ì¶”ê°€
    st.markdown("#### Add New Stock")
    col_add1, col_add2, col_add3 = st.columns(3)
    
    with col_add1:
        new_symbol = st.text_input("Symbol", key="new_watchlist_symbol").upper()
    
    with col_add2:
        new_category = st.selectbox(
            "Category",
            manager.get_categories(),
            key="new_watchlist_category"
        )
    
    with col_add3:
        st.write("")
        st.write("")
        if st.button("Add to Watchlist", key="add_to_watchlist"):
            if new_symbol:
                # ì—¬ê¸°ì„œëŠ” íšŒì‚¬ëª…ì„ ê°„ë‹¨íˆ ì‹¬ë³¼ë¡œ ì„¤ì •
                # ì‹¤ì œë¡œëŠ” APIì—ì„œ íšŒì‚¬ëª… ê°€ì ¸ì˜¤ê¸°
                if manager.add_to_watchlist(new_symbol, new_symbol, new_category):
                    st.success(f"{new_symbol} added to watchlist!")
                    st.rerun()
            else:
                st.error("Please enter a symbol.")
```

### 7.2 í˜„ì¬ Streamlit ì•±ì— í†µí•©í•˜ëŠ” ë°©ë²•

#### 7.2.1 ê¸°ì¡´ app.pyì— í†µí•©
```python
# ê¸°ì¡´ app.py íŒŒì¼ì— ë‹¤ìŒ ì½”ë“œë¥¼ ì¶”ê°€

# íŒŒì¼ ìƒë‹¨ì— ì„í¬íŠ¸ ì¶”ê°€
import asyncio
from enhanced_search import enhanced_search_ui
from unified_data import unified_stock_display
from enhanced_watchlist import enhanced_watchlist_ui

# ê¸°ì¡´ íƒ­ êµ¬ì¡°ë¥¼ ìˆ˜ì •
tab1, tab2, tab3 = st.tabs(["ğŸ“Š Chart Analysis", "ğŸ“‰ Compare Stocks", "ğŸ” Enhanced Search"])

# ê¸°ì¡´ íƒ­ 1, 2ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€

# ìƒˆë¡œìš´ íƒ­ 3 ì¶”ê°€
with tab3:
    # í–¥ìƒëœ ê²€ìƒ‰ UI
    enhanced_search_ui()
    
    st.markdown("---")
    
    # ê´€ì‹¬ì¢…ëª© ê´€ë¦¬
    enhanced_watchlist_ui()
    
    st.markdown("---")
    
    # ì„ íƒëœ ì£¼ì‹ì´ ìˆìœ¼ë©´ í†µí•© ì •ë³´ í‘œì‹œ
    if 'current_ticker' in st.session_state:
        st.markdown("### Selected Stock Details")
        unified_stock_display(st.session_state.current_ticker)
```

#### 7.2.2 ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ìºì‹±
```python
# caching.py
import streamlit as st
import time
from functools import wraps
from typing import Any, Callable

def cached(ttl: int = 300, max_size: int = 100):
    """Streamlit ìºì‹± ë°ì½”ë ˆì´í„°"""
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            # ìºì‹œ í‚¤ ìƒì„±
            cache_key = f"{func.__name__}_{hash(str(args) + str(kwargs))}"
            
            # ìºì‹œ í™•ì¸
            if 'custom_cache' not in st.session_state:
                st.session_state.custom_cache = {}
            
            cache = st.session_state.custom_cache
            
            if cache_key in cache:
                data, timestamp = cache[cache_key]
                if time.time() - timestamp < ttl:
                    return data
            
            # í•¨ìˆ˜ ì‹¤í–‰
            result = func(*args, **kwargs)
            
            # ìºì‹œ ì €ì¥
            cache[cache_key] = (result, time.time())
            
            # ìºì‹œ í¬ê¸° ì œí•œ
            if len(cache) > max_size:
                oldest_key = min(
                    cache.items(),
                    key=lambda x: x[1][1]
                )[0]
                del cache[oldest_key]
            
            return result
        return wrapper
    return decorator

# ì‚¬ìš© ì˜ˆì‹œ
@cached(ttl=300, max_size=50)
def get_stock_data(symbol: str):
    """ì£¼ì‹ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ìºì‹± ì ìš©)"""
    # ê¸°ì¡´ get_stock_info í•¨ìˆ˜ ë¡œì§
    pass
```

### 7.3 ë‹¨ê³„ì  êµ¬í˜„ ê°€ì´ë“œ

#### 7.3.1 1ë‹¨ê³„: ê¸°ë³¸ ê¸°ëŠ¥ í†µí•©
1. **í–¥ìƒëœ ê²€ìƒ‰ ê¸°ëŠ¥ ì¶”ê°€**
   - `enhanced_search.py` íŒŒì¼ ìƒì„±
   - ê¸°ì¡´ ê²€ìƒ‰ UIë¥¼ í–¥ìƒëœ ê²€ìƒ‰ìœ¼ë¡œ êµì²´
   - ìë™ì™„ì„± ë° í•„í„°ë§ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸

2. **í†µí•© ë°ì´í„° ëª¨ë¸ ì ìš©**
   - `unified_data.py` íŒŒì¼ ìƒì„±
   - ê¸°ì¡´ ì£¼ì‹ ì •ë³´ í‘œì‹œë¥¼ í†µí•© ëª¨ë¸ë¡œ ë³€ê²½
   - ì„¼í‹°ë¨¼íŠ¸ ë°ì´í„° ê¸°ë³¸ í‘œì‹œ

#### 7.3.2 2ë‹¨ê³„: ê³ ê¸‰ ê¸°ëŠ¥ ì¶”ê°€
1. **ê´€ì‹¬ì¢…ëª© ê´€ë¦¬ ê°œì„ **
   - `enhanced_watchlist.py` íŒŒì¼ ìƒì„±
   - ì¹´í…Œê³ ë¦¬ë³„ ê´€ë¦¬, ë©”ëª¨, ì•Œë¦¼ ê¸°ëŠ¥ ì¶”ê°€

2. **ì„±ëŠ¥ ìµœì í™”**
   - ìºì‹± ì‹œìŠ¤í…œ ë„ì…
   - ë¹„ë™ê¸° ì²˜ë¦¬ ì ìš©

#### 7.3.3 3ë‹¨ê³„: ì†Œì…œ ì„¼í‹°ë¨¼íŠ¸ ì—°ë™
1. **ì†Œì…œ ë°ì´í„° ìˆ˜ì§‘**
   - Reddit, Twitter API ì—°ë™
   - ì‹¤ì‹œê°„ ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„

2. **ì°¨íŠ¸ í†µí•©**
   - ì„¼í‹°ë¨¼íŠ¸ ë°ì´í„° ì°¨íŠ¸ ì˜¤ë²„ë ˆì´
   - ìƒê´€ê´€ê³„ ë¶„ì„ í‘œì‹œ

## 8. ìƒì„¸ êµ¬í˜„ íƒœìŠ¤í¬ ëª©ë¡

### 8.1 Enhanced Stock Search êµ¬í˜„ íƒœìŠ¤í¬

#### 8.1.1 í”„ë¡œì íŠ¸ êµ¬ì¡° ì„¤ì • ë° í•µì‹¬ ì¸í„°í˜ì´ìŠ¤
```python
# tasks/enhanced_search_tasks.py
from enum import Enum
from dataclasses import dataclass
from typing import List, Dict, Optional

class TaskStatus(Enum):
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    BLOCKED = "blocked"

@dataclass
class ImplementationTask:
    id: str
    title: str
    description: str
    acceptance_criteria: List[str]
    story_points: int
    priority: str
    dependencies: List[str]
    status: TaskStatus = TaskStatus.PENDING
    assignee: Optional[str] = None

# Enhanced Stock Search íƒœìŠ¤í¬ ì •ì˜
ENHANCED_SEARCH_TASKS = [
    ImplementationTask(
        id="ES-001",
        title="í”„ë¡œì íŠ¸ êµ¬ì¡° ì„¤ì • ë° í•µì‹¬ ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„",
        description="ìƒˆë¡œìš´ ê²€ìƒ‰ ì‹œìŠ¤í…œì„ ìœ„í•œ ëª¨ë“ˆ êµ¬ì¡° ìƒì„± ë° í•µì‹¬ ë°ì´í„° ëª¨ë¸ ì •ì˜",
        acceptance_criteria=[
            "ê²€ìƒ‰ ì‹œìŠ¤í…œì„ ìœ„í•œ ëª¨ë“ˆ êµ¬ì¡° ìƒì„± ì™„ë£Œ",
            "StockResult, SearchHistoryItem, WatchlistItem ë°ì´í„°í´ë˜ìŠ¤ êµ¬í˜„",
            "íƒ€ì… íŒíŠ¸ ë° ê²€ì¦ ë¡œì§ í¬í•¨",
            "SearchController ê¸°ë³¸ í´ë˜ìŠ¤ êµ¬í˜„ ì™„ë£Œ"
        ],
        story_points=8,
        priority="critical",
        dependencies=[]
    ),
    ImplementationTask(
        id="ES-002",
        title="AutocompleteEngine êµ¬í˜„",
        description="ì‹¤ì‹œê°„ ìë™ì™„ì„± ê¸°ëŠ¥ì˜ í•µì‹¬ ë¡œì§ êµ¬í˜„",
        acceptance_criteria=[
            "Yahoo Finance APIë¥¼ í™œìš©í•œ ì£¼ì‹ ê²€ìƒ‰ í•¨ìˆ˜ ì‘ì„±",
            "ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­ ë° ê´€ë ¨ë„ ì ìˆ˜ ê³„ì‚° ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„",
            "300ms ë””ë°”ìš´ì‹±ìœ¼ë¡œ ë¶ˆí•„ìš”í•œ API í˜¸ì¶œ ë°©ì§€",
            "ë¹„ë™ê¸° ì²˜ë¦¬ ë° ì‘ë‹µ ì‹œê°„ ìµœì í™” (500ms ì´ë‚´)"
        ],
        story_points=13,
        priority="high",
        dependencies=["ES-001"]
    ),
    ImplementationTask(
        id="ES-003",
        title="SearchCache ì‹œìŠ¤í…œ êµ¬í˜„",
        description="ê²€ìƒ‰ ê²°ê³¼ ìºì‹±ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ ë° API í˜¸ì¶œ ìµœì†Œí™”",
        acceptance_criteria=[
            "ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ í‚¤ë¡œ í•˜ëŠ” ìºì‹œ ì‹œìŠ¤í…œ êµ¬í˜„",
            "TTL(5ë¶„) ë° ìµœëŒ€ í¬ê¸°(1000ê°œ) ì œí•œ ì ìš©",
            "ë§Œë£Œëœ ìºì‹œ í•­ëª© ìë™ ì •ë¦¬ ë©”ì»¤ë‹ˆì¦˜",
            "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”"
        ],
        story_points=8,
        priority="medium",
        dependencies=["ES-002"]
    ),
    ImplementationTask(
        id="ES-004",
        title="FilterSystem êµ¬í˜„",
        description="ë‹¤ì¤‘ ì¡°ê±´ í•„í„°ë§ ì‹œìŠ¤í…œ ê°œë°œ",
        acceptance_criteria=[
            "ì£¼ì‹ ìœ í˜•, ì„¹í„°, ê±°ë˜ì†Œë³„ í•„í„°ë§ í•¨ìˆ˜ ì‘ì„±",
            "ë‹¤ì¤‘ í•„í„° ì¡°í•© ì²˜ë¦¬ ë¡œì§ êµ¬í˜„",
            "ê²€ìƒ‰ ê²°ê³¼ì— ë”°ë¥¸ ì‚¬ìš©ê°€ëŠ¥í•œ í•„í„° ê°’ ë™ì  ìƒì„±",
            "í•„í„° ì ìš© ì‹œ ì‹¤ì‹œê°„ ê²°ê³¼ ì—…ë°ì´íŠ¸"
        ],
        story_points=13,
        priority="high",
        dependencies=["ES-001"]
    ),
    ImplementationTask(
        id="ES-005",
        title="SearchHistoryManager êµ¬í˜„",
        description="ì‚¬ìš©ì ê²€ìƒ‰ ê¸°ë¡ ì €ì¥ ë° ê´€ë¦¬ ì‹œìŠ¤í…œ",
        acceptance_criteria=[
            "ê²€ìƒ‰í•œ ì£¼ì‹ ì •ë³´ë¥¼ Session Stateì— ì €ì¥",
            "ì¤‘ë³µ ì œê±° ë° ìµœì‹  ì‹œê°„ ê¸°ì¤€ ì •ë ¬ ë¡œì§",
            "ìµœê·¼ 20ê°œ ê²€ìƒ‰ ê¸°ë¡ ìœ ì§€ ë° í‘œì‹œ",
            "ê²€ìƒ‰ ê¸°ë¡ì—ì„œ ì£¼ì‹ ì„ íƒ ì‹œ ì¦‰ì‹œ ë¡œë“œ ê¸°ëŠ¥"
        ],
        story_points=8,
        priority="medium",
        dependencies=["ES-001"]
    ),
    ImplementationTask(
        id="ES-006",
        title="Enhanced WatchlistManager êµ¬í˜„",
        description="ê¸°ì¡´ ê´€ì‹¬ì¢…ëª© ê¸°ëŠ¥ì„ í™•ì¥í•˜ì—¬ ì¹´í…Œê³ ë¦¬, ë©”ëª¨, ì •ë ¬ ê¸°ëŠ¥ ì¶”ê°€",
        acceptance_criteria=[
            "ê´€ì‹¬ì¢…ëª©ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”í•˜ëŠ” ê¸°ëŠ¥ êµ¬í˜„",
            "ì¹´í…Œê³ ë¦¬ ìƒì„±, ìˆ˜ì •, ì‚­ì œ ê¸°ëŠ¥ ê°œë°œ",
            "ê° ê´€ì‹¬ì¢…ëª©ì— ê°œì¸ ë©”ëª¨ ì¶”ê°€ ê¸°ëŠ¥",
            "ë²„íŠ¼ ê¸°ë°˜ ìˆœì„œ ë³€ê²½ ê¸°ëŠ¥ (Streamlit ì œì•½ ê³ ë ¤)",
            "Session Stateë¥¼ í™œìš©í•œ ê´€ì‹¬ì¢…ëª© ë°ì´í„° ì €ì¥",
            "ì¤‘ë³µ ì¶”ê°€ ë°©ì§€ ë° ìë™ ì €ì¥ ê¸°ëŠ¥"
        ],
        story_points=21,
        priority="high",
        dependencies=["ES-001"]
    ),
    ImplementationTask(
        id="ES-007",
        title="ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬ ì‹œìŠ¤í…œ êµ¬í˜„",
        description="API ì˜¤ë¥˜, ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ ë“±ì— ëŒ€í•œ ê²¬ê³ í•œ ì—ëŸ¬ ì²˜ë¦¬",
        acceptance_criteria=[
            "Yahoo Finance API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ (ìµœëŒ€ 3íšŒ)",
            "íƒ€ì„ì•„ì›ƒ ë° ì—°ê²° ì˜¤ë¥˜ì— ëŒ€í•œ ì ì ˆí•œ ì—ëŸ¬ ë©”ì‹œì§€",
            "ê²€ìƒ‰ì–´ ê¸¸ì´ ì œí•œ (50ì) ë° íŠ¹ìˆ˜ë¬¸ì í•„í„°ë§",
            "ë¹ˆ ê²€ìƒ‰ì–´ ì²˜ë¦¬ ë° ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ í‘œì‹œ"
        ],
        story_points=8,
        priority="medium",
        dependencies=["ES-002"]
    ),
    ImplementationTask(
        id="ES-008",
        title="í–¥ìƒëœ ê²€ìƒ‰ UI êµ¬í˜„",
        description="ìë™ì™„ì„±ì´ í¬í•¨ëœ ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤ ê°œë°œ",
        acceptance_criteria=[
            "ì‹¤ì‹œê°„ ìë™ì™„ì„± ì œì•ˆì„ í‘œì‹œí•˜ëŠ” ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤",
            "í‚¤ë³´ë“œ ë„¤ë¹„ê²Œì´ì…˜ ì§€ì› ë° ì„ íƒ ê¸°ëŠ¥",
            "ì£¼ì‹ ì •ë³´ë¥¼ ì¹´ë“œ í˜•íƒœë¡œ í‘œì‹œí•˜ëŠ” UI ì»´í¬ë„ŒíŠ¸",
            "ê´€ì‹¬ì¢…ëª© ì¶”ê°€ ë²„íŠ¼ ë° ì°¨íŠ¸ ë³´ê¸° ë²„íŠ¼ í¬í•¨",
            "ë‹¤ì¤‘ í•„í„° ì„ íƒì„ ìœ„í•œ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤",
            "ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ ë“œë¡­ë‹¤ìš´ ë° ì„ íƒ ê¸°ëŠ¥"
        ],
        story_points=21,
        priority="high",
        dependencies=["ES-002", "ES-004", "ES-005"]
    ),
    ImplementationTask(
        id="ES-009",
        title="í–¥ìƒëœ ê´€ì‹¬ì¢…ëª© íŒ¨ë„ UI êµ¬í˜„",
        description="ì¹´í…Œê³ ë¦¬ë³„ ê·¸ë£¹í™”ëœ ê´€ì‹¬ì¢…ëª© í‘œì‹œ",
        acceptance_criteria=[
            "ì ‘ì„ ìˆ˜ ìˆëŠ” ì¹´í…Œê³ ë¦¬ ì„¹ì…˜ìœ¼ë¡œ ê´€ì‹¬ì¢…ëª© ê·¸ë£¹í™”",
            "ì¹´í…Œê³ ë¦¬ ì¶”ê°€/í¸ì§‘/ì‚­ì œ ì¸í„°í˜ì´ìŠ¤",
            "ê° ê´€ì‹¬ì¢…ëª©ì˜ ë©”ëª¨ í¸ì§‘ ì¸í„°í˜ì´ìŠ¤",
            "ìˆœì„œ ë³€ê²½ì„ ìœ„í•œ ìœ„/ì•„ë˜ ì´ë™ ë²„íŠ¼"
        ],
        story_points=13,
        priority="medium",
        dependencies=["ES-006"]
    ),
    ImplementationTask(
        id="ES-010",
        title="ê¸°ì¡´ ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ì˜ í†µí•©",
        description="ìƒˆë¡œìš´ ê²€ìƒ‰ ì‹œìŠ¤í…œì„ ê¸°ì¡´ app.pyì— í†µí•©",
        acceptance_criteria=[
            "ê¸°ì¡´ì˜ search_stocks í•¨ìˆ˜ë¥¼ ìƒˆë¡œìš´ SearchControllerë¡œ êµì²´",
            "ê¸°ì¡´ ê´€ì‹¬ì¢…ëª© ì‹œìŠ¤í…œì„ Enhanced WatchlistManagerë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜",
            "ê¸°ì¡´ ì‚¬ì´ë“œë°” ê²€ìƒ‰ ì„¹ì…˜ì„ ìƒˆë¡œìš´ UIë¡œ êµì²´",
            "ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ ë°©ì‹ì„ ì¹´ë“œ í˜•íƒœë¡œ ë³€ê²½",
            "ì „ì²´ ê²€ìƒ‰ í”Œë¡œìš° end-to-end í…ŒìŠ¤íŠ¸",
            "ê¸°ì¡´ ê¸°ëŠ¥ê³¼ì˜ í˜¸í™˜ì„± ê²€ì¦"
        ],
        story_points=13,
        priority="high",
        dependencies=["ES-008", "ES-009"]
    ),
    ImplementationTask(
        id="ES-011",
        title="ì„±ëŠ¥ ìµœì í™” ë° ë§ˆë¬´ë¦¬",
        description="ì „ì²´ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ íŠœë‹ ë° ìµœì í™”",
        acceptance_criteria=[
            "ê²€ìƒ‰ ì‘ë‹µ ì‹œê°„ ì¸¡ì • ë° 500ms ì´ë‚´ ë‹¬ì„± í™•ì¸",
            "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”",
            "ì½”ë“œ ë¦¬íŒ©í† ë§ ë° ì£¼ì„ ì¶”ê°€",
            "ìƒˆë¡œìš´ ê¸°ëŠ¥ì— ëŒ€í•œ ì‚¬ìš©ì ê°€ì´ë“œ ì‘ì„±"
        ],
        story_points=8,
        priority="medium",
        dependencies=["ES-010"]
    )
]
```

### 8.2 Social Sentiment Tracker êµ¬í˜„ íƒœìŠ¤í¬

#### 8.2.1 ì†Œì…œ ì„¼í‹°ë¨¼íŠ¸ ì¶”ì  ì‹œìŠ¤í…œ
```python
# tasks/social_sentiment_tasks.py
SOCIAL_SENTIMENT_TASKS = [
    ImplementationTask(
        id="SS-001",
        title="í”„ë¡œì íŠ¸ êµ¬ì¡° ì„¤ì • ë° í•µì‹¬ ë°ì´í„° ëª¨ë¸ êµ¬í˜„",
        description="ì†Œì…œ ì„¼í‹°ë¨¼íŠ¸ ì¶”ì ì„ ìœ„í•œ ëª¨ë“ˆ êµ¬ì¡° ìƒì„± ë° í•µì‹¬ ë°ì´í„° ëª¨ë¸ ì •ì˜",
        acceptance_criteria=[
            "ì†Œì…œ ì„¼í‹°ë¨¼íŠ¸ ì¶”ì ì„ ìœ„í•œ ëª¨ë“ˆ êµ¬ì¡° ìƒì„±",
            "StockMention, TrendingStock, SentimentData ë°ì´í„°í´ë˜ìŠ¤ êµ¬í˜„",
            "íƒ€ì… íŒíŠ¸ ë° ê²€ì¦ ë¡œì§ í¬í•¨",
            "SentimentController ê¸°ë³¸ í´ë˜ìŠ¤ êµ¬í˜„",
            "PRAW (Reddit API), tweepy (Twitter API), VADER sentiment ë“± í•„ìš” íŒ¨í‚¤ì§€ ì¶”ê°€",
            "API í‚¤ ë° ì„¤ì • ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„"
        ],
        story_points=8,
        priority="critical",
        dependencies=[]
    ),
    ImplementationTask(
        id="SS-002",
        title="Reddit ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ êµ¬í˜„",
        description="Reddit APIë¥¼ í™œìš©í•œ ì£¼ì‹ ì–¸ê¸‰ ë°ì´í„° ìˆ˜ì§‘",
        acceptance_criteria=[
            "PRAWë¥¼ í™œìš©í•œ Reddit ë°ì´í„° ìˆ˜ì§‘ í´ë˜ìŠ¤ ì‘ì„±",
            "ì£¼ìš” ì„œë¸Œë ˆë”§ (wallstreetbets, investing, stocks ë“±) ì—°ë™",
            "í…ìŠ¤íŠ¸ì—ì„œ ì£¼ì‹ ì‹¬ë³¼ ($AAPL, TSLA ë“±) ì¶”ì¶œí•˜ëŠ” ì •ê·œì‹ ë° ë¡œì§",
            "ìœ íš¨í•œ ì£¼ì‹ ì‹¬ë³¼ ê²€ì¦ ì‹œìŠ¤í…œ",
            "ì‹¤ì‹œê°„ ê²Œì‹œë¬¼ ë° ëŒ“ê¸€ì—ì„œ ì£¼ì‹ ì–¸ê¸‰ ì¶”ì¶œ",
            "ë©”íƒ€ë°ì´í„° (ì—…ë³´íŠ¸, ì‘ì„±ì, ì‹œê°„ ë“±) í•¨ê»˜ ìˆ˜ì§‘"
        ],
        story_points=13,
        priority="high",
        dependencies=["SS-001"]
    ),
    ImplementationTask(
        id="SS-003",
        title="ì–¸ê¸‰ ì¹´ìš´íŒ… ë° ë­í‚¹ ì‹œìŠ¤í…œ êµ¬í˜„",
        description="ì‹œê°„ëŒ€ë³„ ì£¼ì‹ ì–¸ê¸‰ íšŸìˆ˜ ì§‘ê³„ ë° ë­í‚¹ ìƒì„±",
        acceptance_criteria=[
            "1ì‹œê°„, 24ì‹œê°„, 7ì¼ ë‹¨ìœ„ ì–¸ê¸‰ íšŸìˆ˜ ì§‘ê³„ ë¡œì§",
            "ì‹œê°„ ìœˆë„ìš°ë³„ ë°ì´í„° ê´€ë¦¬ ì‹œìŠ¤í…œ",
            "ìƒìœ„ 20ê°œ ì–¸ê¸‰ ì£¼ì‹ ë­í‚¹ ìƒì„± ë° ì—…ë°ì´íŠ¸",
            "ì–¸ê¸‰ íšŸìˆ˜ ë³€í™”ìœ¨ ê³„ì‚° ë¡œì§",
            "5ë¶„ ê°„ê²© ìë™ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ìºì‹± ë©”ì»¤ë‹ˆì¦˜",
            "TTL ê¸°ë°˜ ìºì‹œ ê´€ë¦¬ ë° ë©”ëª¨ë¦¬ ìµœì í™”"
        ],
        story_points=13,
        priority="high",
        dependencies=["SS-002"]
    ),
    ImplementationTask(
        id="SS-004",
        title="íŠ¸ë Œë”© ê°ì§€ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„",
        description="ì–¸ê¸‰ëŸ‰ ê¸‰ì¦ ì£¼ì‹ì„ ê°ì§€í•˜ëŠ” íŠ¸ë Œë”© ì•Œê³ ë¦¬ì¦˜",
        acceptance_criteria=[
            "ì§€ë‚œ 7ì¼ í‰ê·  ì–¸ê¸‰ëŸ‰ì„ ê¸°ì¤€ìœ¼ë¡œ í•œ ë² ì´ìŠ¤ë¼ì¸ ê³„ì‚°",
            "ì‹œê°„ëŒ€ë³„ ê°€ì¤‘ì¹˜ ì ìš© ë° ë…¸ì´ì¦ˆ í•„í„°ë§",
            "200% ì´ìƒ ì¦ê°€ ê°ì§€ ë° ì§€ì†ì„± í™•ì¸ (ìµœì†Œ 30ë¶„)",
            "íŠ¸ë Œë”© ì ìˆ˜ ê³„ì‚° ë° ìš°ì„ ìˆœìœ„ ì •ë ¬",
            "íŠ¸ë Œë”© ì£¼ì‹ ë³„ë„ ì„¹ì…˜ í‘œì‹œ ë° ì‹œê°ì  ì•Œë¦¼",
            "ì–¸ê¸‰ëŸ‰ ë³€í™” ê·¸ë˜í”„ ìƒì„± ë° í‘œì‹œ"
        ],
        story_points=21,
        priority="high",
        dependencies=["SS-003"]
    ),
    ImplementationTask(
        id="SS-005",
        title="ì»¤ë®¤ë‹ˆí‹° í•„í„°ë§ ì‹œìŠ¤í…œ êµ¬í˜„",
        description="íˆ¬ì ì„±í–¥ë³„ ì»¤ë®¤ë‹ˆí‹° ë¶„ë¥˜ ë° í•„í„°ë§ ê¸°ëŠ¥",
        acceptance_criteria=[
            "ë‹¨íƒ€, ê°€ì¹˜íˆ¬ì, ì„±ì¥íˆ¬ì ì¹´í…Œê³ ë¦¬ë³„ ì»¤ë®¤ë‹ˆí‹° ë§¤í•‘",
            "ì»¤ë®¤ë‹ˆí‹° í”„ë¡œí•„ ë° íŠ¹ì„± ì •ì˜ ì‹œìŠ¤í…œ",
            "ì‚¬ìš©ìê°€ íˆ¬ì ì„±í–¥ì„ ì„ íƒí•  ìˆ˜ ìˆëŠ” UI ì»´í¬ë„ŒíŠ¸",
            "ë‹¤ì¤‘ ì„ íƒ ì§€ì› ë° ì‹¤ì‹œê°„ í•„í„° ì ìš©",
            "ê° ì»¤ë®¤ë‹ˆí‹°ë³„ ì–¸ê¸‰ ë¹„ì¤‘ ê³„ì‚° ë° ì‹œê°í™”",
            "ì»¤ë®¤ë‹ˆí‹° íŠ¹ì„±ì— ë”°ë¥¸ ë°ì´í„° ê°€ì¤‘ì¹˜ ì ìš©"
        ],
        story_points=13,
        priority="medium",
        dependencies=["SS-002"]
    ),
    ImplementationTask(
        id="SS-006",
        title="ê°ì • ë¶„ì„ ì‹œìŠ¤í…œ êµ¬í˜„",
        description="VADER ê¸°ë°˜ í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„ ì—”ì§„",
        acceptance_criteria=[
            "VADER sentiment analyzerë¥¼ í™œìš©í•œ ê¸°ë³¸ ê°ì • ë¶„ì„",
            "ì†Œì…œ ë¯¸ë””ì–´ í…ìŠ¤íŠ¸ì— íŠ¹í™”ëœ ì „ì²˜ë¦¬ ë¡œì§",
            "'moon', 'diamond hands', 'paper hands' ë“± ì£¼ì‹ ì»¤ë®¤ë‹ˆí‹° ìš©ì–´ ì‚¬ì „",
            "ì£¼ì‹ ê´€ë ¨ ê°ì • í‘œí˜„ì˜ ê°€ì¤‘ì¹˜ ì¡°ì • ì‹œìŠ¤í…œ",
            "-100 ~ +100 ë²”ìœ„ë¡œ ì •ê·œí™”ëœ ê°ì • ì ìˆ˜ ê³„ì‚°",
            "ì‹œê°„ë³„ ê°ì • ë³€í™” ì¶”ì´ ì¶”ì  ë° ìƒ‰ìƒ ì‹œê°í™”"
        ],
        story_points=21,
        priority="high",
        dependencies=["SS-002"]
    ),
    ImplementationTask(
        id="SS-007",
        title="Twitter ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ êµ¬í˜„ (ì„ íƒì )",
        description="Twitter APIë¥¼ í™œìš©í•œ ì¶”ê°€ ë°ì´í„° ì†ŒìŠ¤ í™•ë³´",
        acceptance_criteria=[
            "tweepyë¥¼ í™œìš©í•œ Twitter ë°ì´í„° ìˆ˜ì§‘ í´ë˜ìŠ¤",
            "$TICKER í•´ì‹œíƒœê·¸ ë° í‚¤ì›Œë“œ ê¸°ë°˜ íŠ¸ìœ— ìˆ˜ì§‘",
            "Reddit ë°ì´í„°ì™€ Twitter ë°ì´í„°ì˜ í†µí•© ì²˜ë¦¬",
            "í”Œë«í¼ë³„ ê°€ì¤‘ì¹˜ ë° ì‹ ë¢°ë„ ì¡°ì •"
        ],
        story_points=13,
        priority="low",
        dependencies=["SS-001"]
    ),
    ImplementationTask(
        id="SS-008",
        title="ì†Œì…œ ì„¼í‹°ë¨¼íŠ¸ UI êµ¬í˜„",
        description="íŠ¸ë Œë”© ì£¼ì‹, ì–¸ê¸‰ ë­í‚¹, í•„í„° ë“±ì„ í¬í•¨í•œ ëŒ€ì‹œë³´ë“œ",
        acceptance_criteria=[
            "íŠ¸ë Œë”© ì£¼ì‹, ìƒìœ„ ì–¸ê¸‰ ì£¼ì‹, í•„í„° ì˜µì…˜ì„ í¬í•¨í•œ ë©”ì¸ ëŒ€ì‹œë³´ë“œ",
            "ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ë° ì¸í„°ë™í‹°ë¸Œ ìš”ì†Œ êµ¬í˜„",
            "ê°œë³„ ì£¼ì‹ì˜ ìƒì„¸ ì„¼í‹°ë¨¼íŠ¸ ì •ë³´ í‘œì‹œ í˜ì´ì§€",
            "ì»¤ë®¤ë‹ˆí‹°ë³„ ë¶„ì„ ë° ê°ì • ì ìˆ˜ ì‹œê°í™”",
            "ì»¤ë®¤ë‹ˆí‹° í•„í„°ë§ ë° ì‹œê°„ëŒ€ ì„ íƒ ì¸í„°í˜ì´ìŠ¤",
            "ì‚¬ìš©ì ë§ì¶¤ ì„¤ì • ë° ì•Œë¦¼ ì˜µì…˜"
        ],
        story_points=21,
        priority="high",
        dependencies=["SS-004", "SS-005", "SS-006"]
    ),
    ImplementationTask(
        id="SS-009",
        title="ì°¨íŠ¸ í†µí•© ì‹œìŠ¤í…œ êµ¬í˜„",
        description="ê¸°ì¡´ ì£¼ì‹ ì°¨íŠ¸ì— ì†Œì…œ ì„¼í‹°ë¨¼íŠ¸ ë°ì´í„° ì˜¤ë²„ë ˆì´",
        acceptance_criteria=[
            "ê¸°ì¡´ Plotly ì°¨íŠ¸ì— ì–¸ê¸‰ëŸ‰ ë°ì´í„°ë¥¼ ë°” ê·¸ë˜í”„ë¡œ ì˜¤ë²„ë ˆì´",
            "ê°ì • ì ìˆ˜ë¥¼ ë³„ë„ ì„œë¸Œí”Œë¡¯ìœ¼ë¡œ í‘œì‹œí•˜ëŠ” ì‹œìŠ¤í…œ",
            "ì°¨íŠ¸ íŠ¹ì • ì‹œì  í´ë¦­ ì‹œ í•´ë‹¹ ì‹œì ì˜ ì£¼ìš” ì–¸ê¸‰ ë‚´ìš© í‘œì‹œ",
            "ì–¸ê¸‰ëŸ‰ ê¸‰ì¦ ì‹œì ì— ë§ˆì»¤ ë° íˆ´íŒ í‘œì‹œ",
            "ì†Œì…œ ë°ì´í„°ì™€ ì£¼ê°€ ë°ì´í„°ì˜ ìƒê´€ê´€ê³„ ê³„ì‚°",
            "ìƒê´€ê³„ìˆ˜ ë° ì§€ì—° ìƒê´€ê´€ê³„ ì§€í‘œ í‘œì‹œ"
        ],
        story_points=21,
        priority="high",
        dependencies=["SS-006", "SS-008"]
    ),
    ImplementationTask(
        id="SS-010",
        title="ì—ëŸ¬ ì²˜ë¦¬ ë° ì„±ëŠ¥ ìµœì í™”",
        description="API ì œí•œ, ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë“±ì— ëŒ€í•œ ê²¬ê³ í•œ ì—ëŸ¬ ì²˜ë¦¬",
        acceptance_criteria=[
            "Reddit/Twitter API ì œí•œ ë° ì˜¤ë¥˜ì— ëŒ€í•œ ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜",
            "Fallback ë°ì´í„° ì†ŒìŠ¤ ë° Graceful degradation êµ¬í˜„",
            "ìŠ¤íŒ¸ í•„í„°ë§, ë´‡ ê³„ì • ì œê±°, ë¬´ê´€í•œ ì–¸ê¸‰ í•„í„°ë§",
            "ë°ì´í„° ì •ì œ ë° ê²€ì¦ íŒŒì´í”„ë¼ì¸ êµ¬í˜„",
            "ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ë°°ì¹˜ ì²˜ë¦¬ ë° ë¹„ë™ê¸° ì‘ì—…",
            "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” ë° ì˜¤ë˜ëœ ë°ì´í„° ìë™ ì •ë¦¬"
        ],
        story_points=13,
        priority="medium",
        dependencies=["SS-002", "SS-007"]
    ),
    ImplementationTask(
        id="SS-011",
        title="ê¸°ì¡´ ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ì˜ í†µí•©",
        description="ìƒˆë¡œìš´ ì†Œì…œ ì„¼í‹°ë¨¼íŠ¸ ê¸°ëŠ¥ì„ ê¸°ì¡´ app.pyì— í†µí•©",
        acceptance_criteria=[
            "ê¸°ì¡´ 'Chart Analysis', 'Compare Stocks' íƒ­ì— 'Social Sentiment' íƒ­ ì¶”ê°€",
            "íƒ­ ê°„ ë°ì´í„° ê³µìœ  ë° ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ",
            "ê¸°ì¡´ ê´€ì‹¬ì¢…ëª©ì—ì„œ ì†Œì…œ ì„¼í‹°ë¨¼íŠ¸ ë°ì´í„° ë¹ ë¥¸ ì¡°íšŒ",
            "ì„¼í‹°ë¨¼íŠ¸ ê¸°ë°˜ ê´€ì‹¬ì¢…ëª© ì¶”ì²œ ì‹œìŠ¤í…œ",
            "ê¸°ì¡´ ì£¼ì‹ ê²€ìƒ‰ì— ì†Œì…œ íŠ¸ë Œë”© ì •ë³´ ì¶”ê°€ í‘œì‹œ",
            "ì„¼í‹°ë¨¼íŠ¸ ì ìˆ˜ ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼ ì •ë ¬ ì˜µì…˜"
        ],
        story_points=13,
        priority="high",
        dependencies=["SS-008", "SS-009"]
    ),
    ImplementationTask(
        id="SS-012",
        title="í†µí•© í…ŒìŠ¤íŠ¸ ë° ê²€ì¦",
        description="ì „ì²´ ì†Œì…œ ì„¼í‹°ë¨¼íŠ¸ ì‹œìŠ¤í…œì˜ end-to-end í…ŒìŠ¤íŠ¸",
        acceptance_criteria=[
            "ë°ì´í„° ìˆ˜ì§‘ë¶€í„° UI í‘œì‹œê¹Œì§€ ì „ì²´ í”Œë¡œìš° í…ŒìŠ¤íŠ¸",
            "ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œì˜ ì‹œìŠ¤í…œ ë™ì‘ ê²€ì¦",
            "ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì„±ëŠ¥ ì¸¡ì • ë° ìµœì í™”",
            "ë™ì‹œ ì‚¬ìš©ì ë° ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸",
            "ìƒˆë¡œìš´ ì†Œì…œ ì„¼í‹°ë¨¼íŠ¸ ê¸°ëŠ¥ì— ëŒ€í•œ ì‚¬ìš©ì ê°€ì´ë“œ",
            "Reddit/Twitter API ì„¤ì • ë°©ë²• ë° í‚¤ ë°œê¸‰ ê°€ì´ë“œ",
            "ìƒˆë¡œìš´ ë°ì´í„° ì†ŒìŠ¤ ì¶”ê°€ ë°©ë²• ë¬¸ì„œí™”"
        ],
        story_points=13,
        priority="medium",
        dependencies=["SS-011"]
    )
]
```

### 8.3 í†µí•© ê°œì„  êµ¬í˜„ íƒœìŠ¤í¬

#### 8.3.1 ì‹œìŠ¤í…œ í†µí•© ë° ê°œì„ 
```python
# tasks/integration_improvements_tasks.py
INTEGRATION_IMPROVEMENTS_TASKS = [
    ImplementationTask(
        id="II-001",
        title="ë°ì´í„° ëª¨ë¸ í†µí•©",
        description="Enhanced Searchì™€ Social Sentimentì˜ ë°ì´í„° ëª¨ë¸ í†µí•©",
        acceptance_criteria=[
            "UnifiedStockData ëª¨ë¸ ì •ì˜",
            "ê¸°ì¡´ StockResultì™€ StockMention ë°ì´í„° í†µí•©",
            "ê²€ìƒ‰ ê´€ë ¨ í•„ë“œì™€ ì„¼í‹°ë¨¼íŠ¸ ê´€ë ¨ í•„ë“œ í†µí•©",
            "ë°ì´í„° ë³€í™˜ ë ˆì´ì–´ êµ¬í˜„",
            "í†µí•© ìºì‹± ì‹œìŠ¤í…œ êµ¬í˜„"
        ],
        story_points=13,
        priority="critical",
        dependencies=[]
    ),
    ImplementationTask(
        id="II-002",
        title="í†µí•© ê²€ìƒ‰ ê²°ê³¼ êµ¬í˜„",
        description="ê²€ìƒ‰ ì‹œ ì„¼í‹°ë¨¼íŠ¸ ì ìˆ˜ë„ í•¨ê»˜ í‘œì‹œ",
        acceptance_criteria=[
            "ê²€ìƒ‰ ê²°ê³¼ì— ì„¼í‹°ë¨¼íŠ¸ ì ìˆ˜ í‘œì‹œ",
            "ì„¼í‹°ë¨¼íŠ¸ ê¸°ë°˜ ì •ë ¬ ì˜µì…˜ ì¶”ê°€",
            "ì„¼í‹°ë¨¼íŠ¸ í•„í„°ë§ (ê¸ì •/ë¶€ì •) ê¸°ëŠ¥",
            "íŠ¸ë Œë”© ì£¼ì‹ì„ ê²€ìƒ‰ ì œì•ˆì— ìš°ì„  í‘œì‹œ",
            "ê´€ì‹¬ì¢…ëª©ì— ì‹¤ì‹œê°„ ì„¼í‹°ë¨¼íŠ¸ ìƒíƒœ í‘œì‹œ"
        ],
        story_points=8,
        priority="high",
        dependencies=["II-001"]
    ),
    ImplementationTask(
        id="II-003",
        title="í†µí•© ìºì‹± ì‹œìŠ¤í…œ êµ¬í˜„",
        description="ê²€ìƒ‰ê³¼ ì„¼í‹°ë¨¼íŠ¸ ë°ì´í„°ì˜ í†µí•© ìºì‹±",
        acceptance_criteria=[
            "UnifiedCache í´ë˜ìŠ¤ êµ¬í˜„",
            "ì£¼ì‹ ë°ì´í„°, ì„¼í‹°ë¨¼íŠ¸ ë°ì´í„°, ê²€ìƒ‰ ê²°ê³¼ í†µí•© ìºì‹œ",
            "ê´€ë ¨ ìºì‹œ ë¬´íš¨í™” ë©”ì»¤ë‹ˆì¦˜",
            "ìºì‹œ íš¨ìœ¨ì„± ìµœì í™”",
            "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê´€ë¦¬"
        ],
        story_points=8,
        priority="medium",
        dependencies=["II-001"]
    ),
    ImplementationTask(
        id="II-004",
        title="UI/UX í†µí•© ê°œì„ ",
        description="ê²€ìƒ‰ UIì™€ ì„¼í‹°ë¨¼íŠ¸ UIì˜ í†µí•©",
        acceptance_criteria=[
            "í†µí•© ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤ ë””ìì¸",
            "ê²€ìƒ‰ ê²°ê³¼ì— ì„¼í‹°ë¨¼íŠ¸ ì •ë³´ í‘œì‹œ",
            "ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ UI ê°œì„ ",
            "ì¼ê´€ëœ ë””ìì¸ íŒ¨í„´ ì ìš©",
            "ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜"
        ],
        story_points=13,
        priority="high",
        dependencies=["II-002"]
    ),
    ImplementationTask(
        id="II-005",
        title="ì„±ëŠ¥ ìµœì í™” í†µí•©",
        description="API í˜¸ì¶œ ìµœì í™” ë° ë³‘ë ¬ ì²˜ë¦¬",
        acceptance_criteria=[
            "UnifiedDataService êµ¬í˜„",
            "ë³‘ë ¬ ë°ì´í„° ìˆ˜ì§‘ ë¡œì§",
            "API í˜¸ì¶œ ìµœì†Œí™” ì „ëµ",
            "ì‘ë‹µ ì‹œê°„ ê°œì„ ",
            "ìì› ì‚¬ìš©ëŸ‰ ìµœì í™”"
        ],
        story_points=8,
        priority="medium",
        dependencies=["II-001", "II-003"]
    ),
    ImplementationTask(
        id="II-006",
        title="ì—ëŸ¬ ì²˜ë¦¬ í†µí•©",
        description="í†µí•©ëœ ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„",
        acceptance_criteria=[
            "UnifiedErrorHandler í´ë˜ìŠ¤ êµ¬í˜„",
            "ì¼ê´€ëœ ì—ëŸ¬ ë©”ì‹œì§€ ì‹œìŠ¤í…œ",
            "Fallback ë°ì´í„° ì œê³µ ë©”ì»¤ë‹ˆì¦˜",
            "ì‚¬ìš©ì ì¹œí™”ì  ì—ëŸ¬ í‘œì‹œ",
            "ì—ëŸ¬ ë³µêµ¬ ìë™í™”"
        ],
        story_points=8,
        priority="medium",
        dependencies=["II-001"]
    )
]
```

### 8.4 íƒœìŠ¤í¬ ê´€ë¦¬ ë° ì¶”ì  ì‹œìŠ¤í…œ

#### 8.4.1 íƒœìŠ¤í¬ ê´€ë¦¬ì êµ¬í˜„
```python
# tasks/task_manager.py
from typing import List, Dict, Optional
from datetime import datetime, timedelta
import json

class TaskManager:
    def __init__(self):
        self.tasks: Dict[str, ImplementationTask] = {}
        self.task_dependencies: Dict[str, List[str]] = {}
        self.completed_tasks: List[str] = []
        self.task_history: List[Dict] = []
    
    def add_task(self, task: ImplementationTask):
        """íƒœìŠ¤í¬ ì¶”ê°€"""
        self.tasks[task.id] = task
        self.task_dependencies[task.id] = task.dependencies
    
    def get_available_tasks(self) -> List[ImplementationTask]:
        """ì˜ì¡´ì„±ì´ ì¶©ì¡±ëœ íƒœìŠ¤í¬ ëª©ë¡ ë°˜í™˜"""
        available_tasks = []
        
        for task_id, task in self.tasks.items():
            if task.status == TaskStatus.PENDING:
                # ëª¨ë“  ì˜ì¡´ì„±ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
                dependencies_met = all(
                    dep_id in self.completed_tasks
                    for dep_id in task.dependencies
                )
                if dependencies_met:
                    available_tasks.append(task)
        
        # ìš°ì„ ìˆœìœ„ë³„ ì •ë ¬
        priority_order = {"critical": 0, "high": 1, "medium": 2, "low": 3}
        available_tasks.sort(key=lambda t: priority_order.get(t.priority, 4))
        
        return available_tasks
    
    def start_task(self, task_id: str, assignee: str):
        """íƒœìŠ¤í¬ ì‹œì‘"""
        if task_id in self.tasks:
            task = self.tasks[task_id]
            task.status = TaskStatus.IN_PROGRESS
            task.assignee = assignee
            
            # ê¸°ë¡ ì €ì¥
            self.task_history.append({
                "task_id": task_id,
                "action": "started",
                "timestamp": datetime.now(),
                "assignee": assignee
            })
    
    def complete_task(self, task_id: str):
        """íƒœìŠ¤í¬ ì™„ë£Œ"""
        if task_id in self.tasks:
            task = self.tasks[task_id]
            task.status = TaskStatus.COMPLETED
            self.completed_tasks.append(task_id)
            
            # ê¸°ë¡ ì €ì¥
            self.task_history.append({
                "task_id": task_id,
                "action": "completed",
                "timestamp": datetime.now(),
                "assignee": task.assignee
            })
    
    def get_task_progress(self) -> Dict[str, int]:
        """íƒœìŠ¤í¬ ì§„í–‰ë¥  ë°˜í™˜"""
        total_tasks = len(self.tasks)
        completed_tasks = len(self.completed_tasks)
        
        return {
            "total": total_tasks,
            "completed": completed_tasks,
            "in_progress": len([t for t in self.tasks.values()
                              if t.status == TaskStatus.IN_PROGRESS]),
            "pending": len([t for t in self.tasks.values()
                          if t.status == TaskStatus.PENDING]),
            "completion_rate": (completed_tasks / total_tasks * 100) if total_tasks > 0 else 0
        }
    
    def get_sprint_burndown(self, sprint_days: int = 14) -> Dict:
        """ìŠ¤í”„ë¦°íŠ¸ ë²ˆë‹¤ìš´ ì°¨íŠ¸ ë°ì´í„°"""
        completed_by_date = {}
        
        # ë‚ ì§œë³„ ì™„ë£Œ íƒœìŠ¤í¬ ì§‘ê³„
        for history_item in self.task_history:
            if history_item["action"] == "completed":
                date = history_item["timestamp"].date()
                completed_by_date[date] = completed_by_date.get(date, 0) + 1
        
        # ë²ˆë‹¤ìš´ ë°ì´í„° ìƒì„±
        burndown_data = []
        remaining_tasks = len(self.tasks)
        current_date = datetime.now().date()
        
        for day in range(sprint_days):
            check_date = current_date - timedelta(days=sprint_days - day - 1)
            completed_today = completed_by_date.get(check_date, 0)
            remaining_tasks -= completed_today
            
            burndown_data.append({
                "day": day + 1,
                "date": check_date,
                "remaining": remaining_tasks,
                "completed": len(self.tasks) - remaining_tasks
            })
        
        return {
            "ideal_burndown": [
                {"day": day + 1, "remaining": len(self.tasks) - (len(self.tasks) * day / sprint_days)}
                for day in range(sprint_days)
            ],
            "actual_burndown": burndown_data
        }
    
    def export_tasks(self, filepath: str):
        """íƒœìŠ¤í¬ ë‚´ë³´ë‚´ê¸°"""
        export_data = {
            "tasks": [
                {
                    "id": task.id,
                    "title": task.title,
                    "description": task.description,
                    "acceptance_criteria": task.acceptance_criteria,
                    "story_points": task.story_points,
                    "priority": task.priority,
                    "dependencies": task.dependencies,
                    "status": task.status.value,
                    "assignee": task.assignee
                }
                for task in self.tasks.values()
            ],
            "task_history": self.task_history,
            "export_date": datetime.now().isoformat()
        }
        
        with open(filepath, 'w') as f:
            json.dump(export_data, f, indent=2, default=str)
```

ì´ êµ¬í˜„ ê³„íšì€ InsiteChart í”„ë¡œì íŠ¸ì˜ ì„±ê³µì ì¸ ê°œë°œê³¼ ë°°í¬ë¥¼ ìœ„í•œ ìƒì„¸í•œ ë¡œë“œë§µ, íŒ€ êµ¬ì„±, ê¸°ìˆ  ìŠ¤íƒ, ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„, CI/CD íŒŒì´í”„ë¼ì¸, ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì„ í¬í•¨í•©ë‹ˆë‹¤. íŠ¹íˆ í˜„ì¬ Streamlit ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì¦‰ì‹œ ì ìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ì½”ë“œ ì˜ˆì‹œë“¤ê³¼ .kiro ìŠ¤í™ë¬¸ì„œì˜ ìƒì„¸í•œ êµ¬í˜„ íƒœìŠ¤í¬ ëª©ë¡ì„ ì¶”ê°€í•˜ì—¬ ì‹¤ìš©ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.